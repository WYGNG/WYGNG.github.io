<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>鱼缸屋</title>
  
  <subtitle>天空之境</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wyg1996.cn/"/>
  <updated>2019-09-20T14:49:52.926Z</updated>
  <id>https://wyg1996.cn/</id>
  
  <author>
    <name>ygwu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello World</title>
    <link href="https://wyg1996.cn/2019/09/20/hello-world/"/>
    <id>https://wyg1996.cn/2019/09/20/hello-world/</id>
    <published>2019-09-20T14:49:52.926Z</published>
    <updated>2019-09-20T14:49:52.926Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>《肖申克的救赎》影评：回顾经典，他依然是看不够的经典</title>
    <link href="https://wyg1996.cn/2019/09/20/%E8%AE%B0%E5%BD%95%E6%88%91%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%BC%80%E9%80%9A%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%EF%BC%88%E5%8D%9A%E5%AE%A2%EF%BC%89/"/>
    <id>https://wyg1996.cn/2019/09/20/记录我第一次开通个人网站（博客）/</id>
    <published>2019-09-20T12:34:14.565Z</published>
    <updated>2019-07-29T15:06:00.650Z</updated>
    
    <content type="html"><![CDATA[<p>对于这个电影来讲，他可以说的是电影中的王者，电影中的经典。虽然在角逐奥斯卡的时候失败了，但是随着时间的沉淀，人们越发的感觉这个电影的价值越来越高，成为无冕之王，这部电影确实也是我心中的无冕之王。</p><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><h3 id="一"><a href="#一" class="headerlink" title="一"></a>一</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最初看这个电影的时候</span><br></pre></td></tr></table></figure><p>最初看这个电影的时候，是老师在课上放的。可能对于教学来说，这个电影也具有教育意义吧！而里边主人公的品质也是让我不得不佩服，整个剧情又励志，有感动，而且故事情节丝毫没有拖沓的地方，只要是拍出来的地方全是经典。电影中的主要场地就是监狱。监狱对于观众来说是个既熟悉又陌生的地方，熟悉是因为，我们的生活中经常会谈及到它，陌生在，正常的老百姓都没有进去过，都不知道里边是什么的状况。</p><h3 id="二"><a href="#二" class="headerlink" title="二"></a>二</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">其实对于故事情节来说</span><br></pre></td></tr></table></figure><p>其实对于故事情节来说，我想每个人都看过这么的一两遍，而主人公的那种精神却不谁都可以拥有的。对于人物设定来说，年纪轻轻的人能当上银行的副行长，肯定是一个天资聪颖的不俗之人，而对于一个这么优秀的人来说，当他因为妻子的死而被误判到监狱时，他的表现是镇定的，对于在监狱待了很久的监狱徒都很震惊，他怎么可以如此的镇定。而对于男主来说，虽然他表现的很镇定，但是对于他的内心来说，他是不干的，他是不想在这里待上一辈子的。</p><h3 id="三"><a href="#三" class="headerlink" title="三"></a>三</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">或许是人的天生惯性</span><br></pre></td></tr></table></figure><p>或许是人的天生惯性，一旦在一个地方待久了，就再也不想换地方了，电影的许多地方都是我们平常思考不到但是又在我们的生活中出现的。对于电影中的普通囚徒来说，住了很多年的监狱，他们已经适应了监狱中的生活方式，一旦被放出去，反而适应不了真正的社会生活。因为在他们的内心中，他们就打算在监狱中待一辈子，所以在电影中的那个图书管理者才在最后选择自杀，因为他已经在监狱里待了大半辈子，突然出去各种的不适应，没有亲戚，年老，最后选择了自杀。</p><h3 id="四"><a href="#四" class="headerlink" title="四"></a>四</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">男主角因为没有证据</span><br></pre></td></tr></table></figure><p>男主角因为没有证据，所以一直在等待，他让自己的好友为自己在监狱外找了一个小锤头，但是好友的内心不解，因为想要靠这个小锤头砸出监狱是不可能的，可这么小的锤子也没有什么作用，男主告诉他这是他雕刻石头的，于是所有人都被这个正大光明的理由骗了。因为每个人都先入为主的认为，这么小的锤子是逃不出去的，但是斯蒂芬金就是要大跌你的眼睛，就是告诉你，男主就是靠着这把破小锤头逃出了监狱其实对于电影来说，增加了很多条线索。也给我们表现出了人性并不是那么的简单。靠着自己的聪明才智，为了在监狱中好好的生存，他开始帮监狱长洗黑钱，而对于洗黑钱的道理，是正常人无法理解的，而洗黑钱的步骤也只有他自己清楚。但是这样是有利有弊的。所以接下来就是当他得知自己的证人也在这座监狱，并愿意为他提供证词的时候，证人却被监狱长杀死了，因为作为一个正常人，监狱长怎么会让一个帮自己洗黑钱的人逃出监狱呢！所以电影的剧情开始了下一阶段。</p><p>男主角还是像往常一样的淡定，依然帮着监狱长洗着黑钱，因为他在等待时机，等待时机逃跑。或许聪明人的脑洞与我们正常人的脑洞是不一样的吧，想想正常人，肯定在监狱里被磨灭的没有了希望，但是男主依然拥有他的信仰。因为有着良好的人脉关系，他拥有了一张美丽女士的海报掩藏住了洞口，而洞口就是用着别人认为不可能凿开监狱的锤头，我们不敢相信，这是多么永恒的决心和信念啊，趁着下雨的夜色，他从下水道逃出了监狱。</p><p>逃出监狱的那晚下着雷雨交加的夜晚，在下水道出口的小坑旁，伴着暴雨的那声呐喊可以说是整部电影的高潮了，作为观众的我也在荧幕外边喘了一口大气。在监狱里憋屈了那么多年放在谁身上，谁都会这样大声的叫喊的。而作为正常人的价值观，没有什么所谓的以德报怨。都出了监狱当然是选择报仇，于是他把监狱长洗的黑钱全都取走，也曝光了局长的黑钱内幕。局长发现男主安迪带着重要的东西逃走的时候，基督教的惩罚的句子显得格外的大。当记者们蜂拥而至局长室，局长选择最后得自杀，以留下最后的尊严。</p><p>主人公一直拥有着别人没有的自由之心，他就像被关在笼子里的麻雀，他不是金丝雀，不属于笼子，他只属于天地间，如果被抓到笼子里，他只会想办法逃跑，找回自己的自由，最后男主逃到了墨西哥的海边，他就是该这样的生活的，对于他而言，他是没有犯过任何罪的，他就应该去过他想要的生活，他就应该去他想去的墨西哥的海边，拥有自己的小船还有小木屋去生活。</p><p>对于广大的观众来说，男主的至上确实比我们正常人的智商要高，但是更重要的是坚持，要有着被上帝所玩弄但是也要拥有与上帝斗争的心，不屈不挠，在困境中镇定下来，然后梳理一下自己应该如何生存。而男主作为好友，他也是称职的，在自己的好友重蹈覆辙要自杀的时候看到了自己的那封信，让他重拾了生活的希望，当最后在海边相遇是有一种说不出来的感觉，是感动，是释然，是怀念，是感激，五味杂陈，说不出来的感觉让观众感动。</p><p>这个电影当我第一次看完的时候，感觉剧情还有这种操作，拓宽了我的眼界，更让我知道了正能量的传播还可以通过这种方式。正义与黑暗并存，一种佩服从内心涌起，这个电影完全可以当做人生路上的指明灯，虽然灯光微弱，但却可以持久长明。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对于这个电影来讲，他可以说的是电影中的王者，电影中的经典。虽然在角逐奥斯卡的时候失败了，但是随着时间的沉淀，人们越发的感觉这个电影的价值越来越高，成为无冕之王，这部电影确实也是我心中的无冕之王。&lt;/p&gt;
&lt;h2 id=&quot;开始&quot;&gt;&lt;a href=&quot;#开始&quot; class=&quot;he
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>用Python自己写一个简单的矩阵运算类（只实现矩阵加法和乘法）</title>
    <link href="https://wyg1996.cn/2019/07/22/%E7%94%A8Python%E8%87%AA%E5%B7%B1%E5%86%99%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E7%B1%BB%EF%BC%88%E5%8F%AA%E5%AE%9E%E7%8E%B0%E7%9F%A9%E9%98%B5%E5%8A%A0%E6%B3%95%E5%92%8C%E4%B9%98%E6%B3%95%EF%BC%89/"/>
    <id>https://wyg1996.cn/2019/07/22/用Python自己写一个简单的矩阵运算类（只实现矩阵加法和乘法）/</id>
    <published>2019-07-22T11:02:18.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>这是一道面试时的编程题。我们要在Python中实现一个简单的二维矩阵运算类，该类可以将双层列表初始化为二维矩阵，并可以进行矩阵加法和矩阵乘法。<br>我们使用assert断言来判断初始化时输入的是否是列表，在进行矩阵加法和矩阵乘法时也使用断言来判断两个矩阵的维度是否满足要求。需要注意的是，为了使矩阵运算更具有通用性，矩阵加法和乘法的结果也应初始化为我们写的矩阵类，这样可以连续进行多次加法和乘法。</p><h1 id="Python代码实现"><a href="#Python代码实现" class="headerlink" title="Python代码实现"></a>Python代码实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Matrix</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, list_a)</span>:</span></span><br><span class="line"><span class="keyword">assert</span> isinstance(list_a, list), <span class="string">"输入格式不是列表"</span></span><br><span class="line"></span><br><span class="line">self.matrix = list_a</span><br><span class="line">self.shape = (len(list_a), len(list_a[<span class="number">0</span>]))</span><br><span class="line">self.row = self.shape[<span class="number">0</span>]</span><br><span class="line">self.column = self.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_zero_value_matrix</span><span class="params">(self, shape)</span>:</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">建立零值矩阵用来保存矩阵加法和乘法的结果</span></span><br><span class="line"><span class="string">:param shape: </span></span><br><span class="line"><span class="string">:return: </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">assert</span> isinstance(shape, tuple), <span class="string">"shape格式不是元组"</span></span><br><span class="line"></span><br><span class="line">zero_value_mat = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(shape[<span class="number">0</span>]):</span><br><span class="line">zero_value_mat.append([])</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(shape[<span class="number">1</span>]):</span><br><span class="line">zero_value_mat[i].append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">zero_value_matrix = Matrix(zero_value_mat)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> zero_value_matrix</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matrix_addition</span><span class="params">(self, the_second_mat)</span>:</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">矩阵加法</span></span><br><span class="line"><span class="string">:param the_second_mat: </span></span><br><span class="line"><span class="string">:return: </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">assert</span> isinstance(the_second_mat, Matrix), <span class="string">"输入的第二个矩阵不是矩阵类"</span></span><br><span class="line"><span class="keyword">assert</span> the_second_mat.shape == self.shape, <span class="string">"两个矩阵维度不匹配,不能相加"</span></span><br><span class="line"></span><br><span class="line">result_mat = self.build_zero_value_matrix(self.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(self.row):</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(self.column):</span><br><span class="line">result_mat.matrix[i][j] = self.matrix[i][j] + the_second_mat.matrix[i][j]</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> result_mat</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matrix_multiplication</span><span class="params">(self, the_second_mat)</span>:</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">矩阵乘法</span></span><br><span class="line"><span class="string">:param the_second_mat: </span></span><br><span class="line"><span class="string">:return: </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">assert</span> isinstance(the_second_mat, Matrix), <span class="string">"输入的不是矩阵类"</span></span><br><span class="line"><span class="keyword">assert</span> self.shape[<span class="number">1</span>] == the_second_mat.shape[<span class="number">0</span>], <span class="string">"第一个矩阵的列数与第二个矩阵的行数不匹配，不能相乘"</span></span><br><span class="line"></span><br><span class="line">shape = (self.shape[<span class="number">0</span>], the_second_mat.shape[<span class="number">1</span>])</span><br><span class="line">result_mat = self.build_zero_value_matrix(shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(self.shape[<span class="number">0</span>]):</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(the_second_mat.shape[<span class="number">1</span>]):</span><br><span class="line">number = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(self.shape[<span class="number">1</span>]):</span><br><span class="line">number += self.matrix[i][k] * the_second_mat.matrix[k][j]</span><br><span class="line">result_mat.matrix[i][j] = number</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> result_mat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">list_1 = [[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]]</span><br><span class="line">list_2 = [[<span class="number">2</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">3</span>]]</span><br><span class="line">list_3 = [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]]</span><br><span class="line"></span><br><span class="line">mat1 = Matrix(list_1)</span><br><span class="line">mat2 = Matrix(list_2)</span><br><span class="line">print(mat1.matrix, mat2.matrix)</span><br><span class="line">mat4 = mat1.matrix_addition(mat2)</span><br><span class="line">print(mat4.matrix)</span><br><span class="line"></span><br><span class="line">mat3 = Matrix(list_3)</span><br><span class="line">print(mat3.matrix)</span><br><span class="line">mat5 = mat1.matrix_multiplication(mat3)</span><br><span class="line">print(mat5.matrix)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;p&gt;这是一道面试时的编程题。我们要在Python中实现一个简单的二维矩阵运算类，该类可以将双层列表初始化为二维矩阵，并可以进行矩阵加法和矩阵乘法
      
    
    </summary>
    
    
      <category term="Python" scheme="https://wyg1996.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="https://wyg1996.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>构造二叉排序树与前序遍历、中序遍历、后序遍历的递归和非递归实现</title>
    <link href="https://wyg1996.cn/2019/06/28/%E6%9E%84%E9%80%A0%E4%BA%8C%E5%8F%89%E6%8E%92%E5%BA%8F%E6%A0%91%E4%B8%8E%E5%89%8D%E5%BA%8F%E9%81%8D%E5%8E%86%E3%80%81%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86%E3%80%81%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86%E7%9A%84%E9%80%92%E5%BD%92%E5%92%8C%E9%9D%9E%E9%80%92%E5%BD%92%E5%AE%9E%E7%8E%B0/"/>
    <id>https://wyg1996.cn/2019/06/28/构造二叉排序树与前序遍历、中序遍历、后序遍历的递归和非递归实现/</id>
    <published>2019-06-28T14:12:08.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前序遍历、中序遍历、后序遍历的递归和非递归实现"><a href="#前序遍历、中序遍历、后序遍历的递归和非递归实现" class="headerlink" title="前序遍历、中序遍历、后序遍历的递归和非递归实现"></a>前序遍历、中序遍历、后序遍历的递归和非递归实现</h1><p>前序遍历顺序:根-&gt;左-&gt;右。<br>中序遍历顺序:左-&gt;根-&gt;右。<br>后序遍历顺序:左-&gt;右-&gt;根。<br>前序和中序遍历都是先一路向下遍历节点至最左下角的节点，将这一路上的节点入栈。前序遍历入栈时就要打印节点的值；然后出栈一个节点，中序遍历此时才打印该节点的值，然后指针指向该节点的右孩子。这是转向最外层while循环的下一次循环，将右孩子所在的右子树一路向下遍历节点至最左下角的节点，将这一路上的节点入栈，后面的操作与前面相同。<br>因为前序遍历顺序是根-&gt;左-&gt;右，所以入栈时就要先打印节点的值（根节点的值）；中序遍历顺序是左-&gt;根-&gt;右，所以所有节点都入栈完成后，再出栈的节点就是最左孩子或根节点，这时才打印节点的值。<br>后序遍历需要两个栈，一个栈暂时存储遍历的节点，另一个栈存储最终后序遍历顺序的节点指针。初始暂存栈先存入根节点。然后暂存栈出栈根节点，根节点入结果栈。然后将右孩子节点出栈，右孩子节点入结果栈。将右孩子所在右子树入暂存栈，然后一一出栈将右子树节点入结果栈。然后将左孩子节点出栈，左孩子节点入结果栈。将左孩子所在左子树入暂存栈，然后一一出栈将左子树节点入结果栈。最终结果栈中节点按从栈顶往下分别是左子树节点、左孩子节点、右子树节点、右孩子节点、根节点。最后从结果栈中将节点一一出栈打印即可。</p><h1 id="C-C-实现"><a href="#C-C-实现" class="headerlink" title="C/C++实现"></a>C/C++实现</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">treenode</span> &#123;</span></span><br><span class="line"><span class="keyword">int</span> val;</span><br><span class="line">treenode *leftchild, *rightchild;</span><br><span class="line"></span><br><span class="line">treenode(<span class="keyword">int</span> x) : val(x), leftchild(<span class="literal">nullptr</span>), rightchild(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="function">treenode *<span class="title">build_binary_sort_tree</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;nums)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (nums.empty())</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">treenode *root = <span class="keyword">new</span> treenode(nums[<span class="number">0</span>]);</span><br><span class="line">treenode *temp;</span><br><span class="line"><span class="keyword">int</span> n = nums.size();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; i++) &#123;</span><br><span class="line">temp = root;</span><br><span class="line"><span class="keyword">while</span> (temp) &#123;</span><br><span class="line"><span class="keyword">if</span> (temp-&gt;val &gt;= nums[i] &amp;&amp; !temp-&gt;leftchild) &#123;</span><br><span class="line">treenode *newnode = <span class="keyword">new</span> treenode(nums[i]);</span><br><span class="line">temp-&gt;leftchild = newnode;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (temp-&gt;val &lt; nums[i] &amp;&amp; !temp-&gt;rightchild) &#123;</span><br><span class="line">treenode *newnode = <span class="keyword">new</span> treenode(nums[i]);</span><br><span class="line">temp-&gt;rightchild = newnode;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (temp-&gt;val &gt;= nums[i])</span><br><span class="line">temp = temp-&gt;leftchild;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (temp-&gt;val &lt; nums[i])</span><br><span class="line">temp = temp-&gt;rightchild;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> root;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">preorder_print_tree_recursive</span><span class="params">(treenode *root)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!root)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; root-&gt;val &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">preorder_print_tree_recursive(root-&gt;leftchild);</span><br><span class="line">preorder_print_tree_recursive(root-&gt;rightchild);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">inorder_print_tree_recursive</span><span class="params">(treenode *root)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!root)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">inorder_print_tree_recursive(root-&gt;leftchild);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; root-&gt;val &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">inorder_print_tree_recursive(root-&gt;rightchild);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">postorder_print_tree_recursive</span><span class="params">(treenode *root)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!root)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">postorder_print_tree_recursive(root-&gt;leftchild);</span><br><span class="line">postorder_print_tree_recursive(root-&gt;rightchild);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; root-&gt;val &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">preorder_print_tree</span><span class="params">(treenode *root)</span> </span>&#123;</span><br><span class="line"><span class="comment">//前序遍历是根-&gt;左-&gt;右</span></span><br><span class="line"><span class="keyword">if</span> (!root)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"><span class="built_in">stack</span>&lt;treenode *&gt; nodes;</span><br><span class="line">treenode *temp = root;</span><br><span class="line"><span class="keyword">while</span> (temp || !nodes.empty()) &#123;</span><br><span class="line"><span class="comment">//前序遍历是根左右,先打印根及其一系列左子树中的左孩子节点,并全部进栈</span></span><br><span class="line"><span class="keyword">while</span> (temp) &#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; temp-&gt;val &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">nodes.push(temp);</span><br><span class="line">temp = temp-&gt;leftchild;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 出栈节点要么是叶子节点(上一个节点的左孩子)要么是根</span></span><br><span class="line"><span class="comment">// 由于根和左孩子已经打印过,现在就看有无右子树,有的话内层while再循环一次将右孩子的子树上所有左孩子和左子树的根节点全部进栈,进栈时就打印</span></span><br><span class="line"><span class="keyword">if</span> (!nodes.empty()) &#123;</span><br><span class="line">temp = nodes.top();</span><br><span class="line">nodes.pop();</span><br><span class="line">temp = temp-&gt;rightchild;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">inorder_print_tree</span><span class="params">(treenode *root)</span> </span>&#123;</span><br><span class="line"><span class="comment">//中序遍历是左-&gt;根-&gt;右</span></span><br><span class="line"><span class="keyword">if</span> (!root)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"><span class="built_in">stack</span>&lt;treenode *&gt; nodes;</span><br><span class="line">treenode *temp = root;</span><br><span class="line"><span class="keyword">while</span> (temp || !nodes.empty()) &#123;</span><br><span class="line"><span class="comment">// 开始第一个循环时root的左子树的所有左孩子和左子树的根节点全部进栈</span></span><br><span class="line"><span class="keyword">while</span> (temp) &#123;</span><br><span class="line">nodes.push(temp);</span><br><span class="line">temp = temp-&gt;leftchild;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 出栈,出栈的节点要么是叶子节点(上一个节点的左孩子)要么是根</span></span><br><span class="line"><span class="comment">// 所以先打印,然后看有无右孩子,有的话内层while再次将右孩子的子树上所有左孩子和左子树的根节点全部进栈</span></span><br><span class="line"><span class="keyword">if</span> (!nodes.empty()) &#123;</span><br><span class="line">temp = nodes.top();</span><br><span class="line">nodes.pop();</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; temp-&gt;val &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">temp = temp-&gt;rightchild;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">postorder_print_tree</span><span class="params">(treenode *root)</span> </span>&#123;</span><br><span class="line"><span class="built_in">stack</span>&lt;treenode *&gt; nodes, results;</span><br><span class="line"><span class="keyword">if</span> (!root)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">nodes.push(root);</span><br><span class="line"><span class="keyword">while</span> (!nodes.empty()) &#123;</span><br><span class="line"><span class="comment">// 根节点先入result栈,然后左孩子和右孩子入nodes栈,下一次循环,右孩子入result栈,右子树节点全部入nodes栈</span></span><br><span class="line"><span class="comment">// 右子树节点入栈完后,左孩子入result栈,然后左子树节点全部入nodes栈</span></span><br><span class="line"><span class="comment">// 最后result栈中从顶到下依次为左子树、左孩子、右子树、右孩子、根</span></span><br><span class="line">treenode *temp = nodes.top();</span><br><span class="line">nodes.pop();</span><br><span class="line">results.push(temp);</span><br><span class="line"><span class="keyword">if</span> (temp-&gt;leftchild)</span><br><span class="line">nodes.push(temp-&gt;leftchild);</span><br><span class="line"><span class="keyword">if</span> (temp-&gt;rightchild)</span><br><span class="line">nodes.push(temp-&gt;rightchild);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// result栈保存最后后序遍历顺序的节点,依次取出打印即可</span></span><br><span class="line"><span class="keyword">while</span> (!results.empty()) &#123;</span><br><span class="line">treenode *temp2 = results.top();</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; temp2-&gt;val &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">results.pop();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; a = &#123;<span class="number">5</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">8</span>&#125;;</span><br><span class="line"><span class="comment">//前序结果:5324768</span></span><br><span class="line"><span class="comment">//中序结果:2345678</span></span><br><span class="line"><span class="comment">//后序结果:2436875</span></span><br><span class="line">Solution s;</span><br><span class="line">treenode *root = s.build_binary_sort_tree(a);</span><br><span class="line">s.preorder_print_tree(root);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">s.preorder_print_tree_recursive(root);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">s.inorder_print_tree(root);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">s.inorder_print_tree_recursive(root);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">s.postorder_print_tree(root);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">s.postorder_print_tree_recursive(root);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前序遍历、中序遍历、后序遍历的递归和非递归实现&quot;&gt;&lt;a href=&quot;#前序遍历、中序遍历、后序遍历的递归和非递归实现&quot; class=&quot;headerlink&quot; title=&quot;前序遍历、中序遍历、后序遍历的递归和非递归实现&quot;&gt;&lt;/a&gt;前序遍历、中序遍历、后序遍历的递归
      
    
    </summary>
    
    
      <category term="经典算法实现系列" scheme="https://wyg1996.cn/categories/%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="经典算法实现系列" scheme="https://wyg1996.cn/tags/%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E7%B3%BB%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>尾插法创建链表、打印链表、合并两个有序链表</title>
    <link href="https://wyg1996.cn/2019/06/28/%E5%B0%BE%E6%8F%92%E6%B3%95%E5%88%9B%E5%BB%BA%E9%93%BE%E8%A1%A8%E3%80%81%E6%89%93%E5%8D%B0%E9%93%BE%E8%A1%A8%E3%80%81%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/"/>
    <id>https://wyg1996.cn/2019/06/28/尾插法创建链表、打印链表、合并两个有序链表/</id>
    <published>2019-06-28T06:57:32.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>注意:</strong><br>链表默认没有头节点，第一个节点就有值。</p><h1 id="C-C-代码"><a href="#C-C-代码" class="headerlink" title="C/C++代码"></a>C/C++代码</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">listnode</span> &#123;</span></span><br><span class="line"><span class="keyword">int</span> val;</span><br><span class="line">listnode *next;</span><br><span class="line"></span><br><span class="line">listnode(<span class="keyword">int</span> x) : val(x), next(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="function">listnode *<span class="title">build_linklist</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;nums)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (nums.empty())</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line"><span class="keyword">int</span> n = nums.size();</span><br><span class="line">listnode *head = <span class="keyword">new</span> listnode(nums[<span class="number">0</span>]);</span><br><span class="line">listnode *pre = head;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; i++) &#123;</span><br><span class="line">listnode *temp = <span class="keyword">new</span> listnode(nums[i]);</span><br><span class="line">pre-&gt;next = temp;</span><br><span class="line">pre = pre-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> head;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print_linklist</span><span class="params">(listnode *head)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!head)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"><span class="keyword">while</span> (head) &#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; head-&gt;val &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">head = head-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">listnode *<span class="title">merge_linklist</span><span class="params">(listnode *a, listnode *b)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!a)</span><br><span class="line"><span class="keyword">return</span> b;</span><br><span class="line"><span class="keyword">if</span> (!b)</span><br><span class="line"><span class="keyword">return</span> a;</span><br><span class="line">listnode *head, *temp;</span><br><span class="line"><span class="keyword">if</span> (a-&gt;val &lt;= b-&gt;val) &#123;</span><br><span class="line">head = a;</span><br><span class="line">a = a-&gt;next;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">head = b;</span><br><span class="line">b = b-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">listnode *p = head;</span><br><span class="line"><span class="keyword">while</span> (a &amp;&amp; b) &#123;</span><br><span class="line"><span class="keyword">if</span> (a-&gt;val &lt;= b-&gt;val) &#123;</span><br><span class="line">temp = a;</span><br><span class="line">a = a-&gt;next;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">temp = b;</span><br><span class="line">b = b-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">p-&gt;next = temp;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (a)</span><br><span class="line">p-&gt;next = a;</span><br><span class="line"><span class="keyword">if</span> (b)</span><br><span class="line">p-&gt;next = b;</span><br><span class="line"><span class="keyword">return</span> head;</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; a = &#123;<span class="number">1</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">9</span>&#125;;</span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; b = &#123;<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>&#125;;</span><br><span class="line">Solution s;</span><br><span class="line">listnode *head_a = s.build_linklist(a);</span><br><span class="line">listnode *head_b = s.build_linklist(b);</span><br><span class="line">s.print_linklist(head_a);</span><br><span class="line">s.print_linklist(head_b);</span><br><span class="line">listnode *head_merge = s.merge_linklist(head_a, head_b);</span><br><span class="line">s.print_linklist(head_merge);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;注意:&lt;/strong&gt;&lt;br&gt;链表默认没有头节点，第一个节点就有值。&lt;/p&gt;
&lt;h1 id=&quot;C-C-代码&quot;&gt;&lt;a href=&quot;#C-C-代码&quot; class=&quot;headerlink&quot; title=&quot;C/C++代码&quot;&gt;&lt;/a&gt;C/C++代码&lt;/h1&gt;&lt;fig
      
    
    </summary>
    
    
      <category term="经典算法实现系列" scheme="https://wyg1996.cn/categories/%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="经典算法实现系列" scheme="https://wyg1996.cn/tags/%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E7%B3%BB%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>ER图详解及实例</title>
    <link href="https://wyg1996.cn/2019/06/23/ER%E5%9B%BE%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%AE%9E%E4%BE%8B/"/>
    <id>https://wyg1996.cn/2019/06/23/ER图详解及实例/</id>
    <published>2019-06-23T10:25:21.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ER图基本概念"><a href="#ER图基本概念" class="headerlink" title="ER图基本概念"></a>ER图基本概念</h1><p>ER图分为实体、属性、关系三个核心部分。在ER图中，实体是长方形，属性是椭圆形，关系为菱形。<br><strong>实体（entity）：</strong><br>即数据模型中的数据对象（即数据表），用长方体来表示，每个实体都有自己的实体成员（entity member）或者说实体对象（entity instance），例如学生实体里包括张三、李四等。<br>实体还会细分为弱实体和复合实体，一个实体必须依赖于另一个实体存在，那么前者是弱实体，后者是强实体，弱实体必须依赖强实体存在，例如上图的学生实体和成绩单实体，成绩单依赖于学生实体而存在，因此学生是强实体，而成绩单是弱实体。<br>弱实体和强实体的联系必然只有1：N或者1：1，这是由于弱实体完全依赖于强实体，强实体不存在，那么弱实体就不存在，所以弱实体是完全参与联系的，因此弱实体与联系之间的联系也是用的双线菱形。<br>复合实体也称联合实体或桥接实体，常常用于实现两个或多个实体间的M：N联系，它由每个关联实体的主码组成，用长方体内加一个菱形来表示。</p><p><strong>属性（attribute）：</strong><br>即实体所具有的属性，例如学生具有姓名、学号、年级等属性，用椭圆形表示，属性分为唯一属性（ unique attribute）和非唯一属性，唯一属性指的是唯一可用来标识该实体实例或者成员的属性，用下划线表示，一般来讲实体都至少有一个唯一属性。<br>ER图的属性还细分为复合属性、多值属性和派生属性、可选属性，同时还有用来表示联系的属性，称为联系属性。</p><ul><li>复合属性是指具有多个属性的组合，例如名字属性，它可以包含姓氏属性和名字属性。复合属性也有唯一属性，例如学生的所在班级属性，由于多个年级都有班级，所以单单班级属性是不唯一的，但是和年级组成的复合属性后则可以匹配成唯一属性。</li><li>多值属性：一个实体的某个属性可以有多个不同的取值，称为多值属性。例如一本书的分类属性，这本书有多个分类。</li><li>派生属性：是非永久性存于数据库的属性。派生属性的值可以从别的属性值或其他数据（如当前日期）派生出来，用虚线椭圆表示。</li><li>可选属性：并不是所有的属性都必须有值，有些属性的可以没有值，这就是可选属性，在椭圆的文字后用（O）来表示。</li><li>联系属性：联系属于用户表示多个实体之间联系所具有的属性，一般来讲M:N的两个实体的联系具有联系属性，在1:1和1:M的实体联系中联系属性并不必要。</li></ul><p><strong>关系（relationship）：</strong><br>用来表现数据对象与数据对象之间的联系，例如学生的实体和成绩表的实体之间有一定的联系，每个学生都有自己的成绩表，这就是一种关系，关系用菱形来表示。<br>关联关系有三种：</p><ul><li>1对1（1:1）：指对于实体集A与实体集B，A中的每一个实体至多与B中一个实体有关系；反之，在实体集B中的每个实体至多与实体集A中一个实体有关系。</li><li>1对多（1:N）：1对多关系是指实体集A与实体集B中至少有N（N&gt;0）个实体有关系；并且实体集B中每一个实体至多与实体集A中一个实体有关系。</li><li>多对多（M:N）：多对多关系是指实体集A中的每一个实体与实体集B中至少有M（M&gt;0）个实体有关系，并且实体集B中的每一个实体与实体集A中的至少N（N&gt;0）个实体有关系。</li></ul><h1 id="ER图实例"><a href="#ER图实例" class="headerlink" title="ER图实例"></a>ER图实例</h1><p>假设教学管理规定：<br>一个学生可选修多门课，一门课有若干学生选修；<br>一个教师可讲授多门课，一门课只有一个教师讲授；<br>一个学生选修一门课，仅有一个成绩。<br>学生的属性有学号、学生姓名；教师的属性有教师编号，教师姓名；课程的属性有课程号、课程名。</p><p>要求：根据上述语义画出ER 图，要求在图中画出实体的属性并注明联系的类型。<br><img src="https://img-blog.csdnimg.cn/20190623182046496.png" alt="在这里插入图片描述"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ER图基本概念&quot;&gt;&lt;a href=&quot;#ER图基本概念&quot; class=&quot;headerlink&quot; title=&quot;ER图基本概念&quot;&gt;&lt;/a&gt;ER图基本概念&lt;/h1&gt;&lt;p&gt;ER图分为实体、属性、关系三个核心部分。在ER图中，实体是长方形，属性是椭圆形，关系为菱形。&lt;br&gt;
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://wyg1996.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="https://wyg1996.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>数据库六种范式详解（1NF/2NF/3NF/BCNF/4NF/5NF）</title>
    <link href="https://wyg1996.cn/2019/06/23/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%AD%E7%A7%8D%E8%8C%83%E5%BC%8F%E8%AF%A6%E8%A7%A3%EF%BC%881NF-2NF-3NF-BCNF-4NF-5NF%EF%BC%89/"/>
    <id>https://wyg1996.cn/2019/06/23/数据库六种范式详解（1NF-2NF-3NF-BCNF-4NF-5NF）/</id>
    <published>2019-06-23T10:03:38.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据库的基本概念"><a href="#数据库的基本概念" class="headerlink" title="数据库的基本概念"></a>数据库的基本概念</h1><p><strong>范式:</strong><br><strong>设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同的范式。</strong><br>各种范式呈递次规范，越高的范式数据库冗余越小。有冗余的数据库未必是最好的数据库， 有时为了提高运行效率，就必须降低范式标准，适当保留冗余数据。<br>目前关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式(4NF）和第五范式（5NF）。一般说来，数据库只需满足第三范式(3NF）就行了。<br>满足最低要求的范式是第一范式（1NF）。在第一范式的基础上进一步满足更多规范要求的称为第二范式（2NF），其余范式以次类推。一个数据库设计如果符合第二范式，一定也符合第一范式。如果符合第三范式，一定也符合第二范式。<br><strong>实体:</strong><br>在数据库中往往是一个数据表。<br><strong>属性:</strong><br>在关系数据库中，属性可以看作是“表的一列”。<br><strong>元组:</strong><br>表中的一行就是一个元组。<br><strong>分量:</strong><br>即元组的某个属性值。在一个关系数据库中，属性是一个操作原子，即关系数据库在做任何操作的时候，属性是“不可分的”。否则就不是关系数据库了。<br><strong>候选码和主码:</strong><br>表中可以唯一确定一个元组的某个属性（或者属性组）叫候选码，我们从许多个候选码中挑一个就叫主码。<br><strong>全码:</strong><br>如果一个码包含了所有的属性，这个码就是全码。<br><strong>主属性:</strong><br>一个属性只要在任何一个候选码中出现过，这个属性就是主属性。<br><strong>非主属性:</strong><br>与上面相反，没有在任何候选码中出现过，这个属性就是非主属性。<br><strong>外码:</strong><br>一个属性（或属性组），它不是码，但是它别的表的码，它就是外码。</p><h1 id="函数依赖"><a href="#函数依赖" class="headerlink" title="函数依赖"></a>函数依赖</h1><h2 id="函数依赖的定义"><a href="#函数依赖的定义" class="headerlink" title="函数依赖的定义"></a>函数依赖的定义</h2><p>设R(U)是一个属性集U上的一个关系模式，X和Y是U的子集。若对于R(U)的任意两个可能的具体关系r1、r2，若r1[x]等于r2[x]则r1[y]等于r2[y]，或者若r1[x] != r2[x]则r1[y] != r2[y]，称X决定Y，或者Y函数依赖于X，记作X→Y。即像函数一样，给一个确定的输入（属性集X），有一个确定的输出（属性集Y）。<br><strong>抽象的“关系模式”和具体存在的“关系”，下文统称“关系”。下面是几种函数依赖的定义:</strong></p><ul><li>如果X→Y，但Y为X的子集, 则称X→Y是平凡函数依赖。<br>举例:<br>关系R(Sno, Cno)，依赖关系(Sno, Cno)→Sno，(Sno, Cno)→Cno都是平凡函数依赖。</li><li>如果X→Y，但Y不为X的子集，则称X→Y是非平凡的函数依赖。<br>举例:<br>关系R(Sno, Cno, Grade)，依赖关系(Sno, Cno)→Grade是非平凡函数依赖。</li><li>如果X→Y，存在X的真子集X1，使得X1→Y，则称Y部分依赖于X。也就是Y依赖于部分的X。<br>举例:<br>学生表(学号, 姓名, 性别, 班级, 年龄)，(学号, 姓名)→性别，学号→性别，所以(学号, 姓名)→性别是部分函数依赖。</li><li>如果X→Y，但任何X的真子集X1都不存在X1→Y则称Y完全依赖于X。<br>举例:<br>成绩表(学号, 课程号, 成绩)，(学号, 课程号)→成绩，学号!→成绩，课程号!→成绩，所以(学号, 课程号)→成绩是完全函数依赖。</li><li>如果X→Y，Y→Z，X⊄Y，Y!→X，(X∪Y)∩Z=∅，则称Z传递依赖于X。<br>举例:<br>关系S(学号, 系名, 系主任)，学号→系名，系名→系主任，系名!→学号，所以学号→系主任为传递函数依赖。</li></ul><h2 id="函数依赖与属性的关系"><a href="#函数依赖与属性的关系" class="headerlink" title="函数依赖与属性的关系"></a>函数依赖与属性的关系</h2><p>设R(U)是属性集U上的关系模式，X、Y是U的子集。</p><p>如果X和Y之间是一对一（1:1）关系，如学校和校长，则存在函数依赖X→Y和Y→X。<br>如果X和Y之间是一对多（1:n）关系，如年龄和姓名，则存在函数依赖Y→X。<br>如果X和Y之间是多对多（m:n）关系，如学生和课程，则X和Y之间不存在函数依赖。</p><h1 id="六种范式"><a href="#六种范式" class="headerlink" title="六种范式"></a>六种范式</h1><h2 id="第一范式（1NF）"><a href="#第一范式（1NF）" class="headerlink" title="第一范式（1NF）"></a>第一范式（1NF）</h2><p>简单来说就是属性不可分（1NF是对属性的原子性约束，要求属性具有原子性，不可再分解）。数据库表的每一列（也称为属性）都是不可分割的原子数据项，不能是集合，数组，记录等非原子数据项。实体中的某个属性有多个值时，必须拆分为不同的属性。在符合第一范式（1NF）表中的每个域值只能是实体的一个属性或一个属性的一部分。简而言之，第一范式就是无重复的域。</p><h2 id="第二范式（2NF）"><a href="#第二范式（2NF）" class="headerlink" title="第二范式（2NF）"></a>第二范式（2NF）</h2><p>在满足第一范式（1NF）的基础上，每一个非码属性（不在主键中的列）都必须完全函数依赖于候选码。（2NF是对记录的惟一性约束，要求记录有惟一标识，即实体的惟一性，更通俗的说法就是一个表必须有主键ID）。</p><h2 id="第三范式（3NF）"><a href="#第三范式（3NF）" class="headerlink" title="第三范式（3NF）"></a>第三范式（3NF）</h2><p>在满足第二范式（2NF）的基础上，每个非主属性不依赖于其它非主属性（即在2NF基础上，消除非码属性对候选码的传递函数依赖。3NF是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余）。<br>也就是说，任何非主属性都直接依赖于主属性，不能传递依赖于主属性。即表中的每一列只与主键直接相关，而不是间接相关（表中的每一列只能依赖于主键）。每一个非码属性既不部分依赖于码，也不传递依赖于码。</p><h2 id="巴斯-科德范式（BCNF，Boyce-Codd-Normal-Form）"><a href="#巴斯-科德范式（BCNF，Boyce-Codd-Normal-Form）" class="headerlink" title="巴斯-科德范式（BCNF，Boyce-Codd Normal Form）"></a>巴斯-科德范式（BCNF，Boyce-Codd Normal Form）</h2><p>某些特殊情况下，即使关系模式符合3NF的要求，仍然存在着插入异常，修改异常与删除异常的问题。BCNF由Boyce与Codd提出，通常被认为是修正的第三范式。<br>巴斯-科德范式即在满足第三范式（3NF）基础上，任何非主属性不能对主键子集依赖（即在3NF基础上，消除主属性对候选码的部分函数依赖和传递函数依赖）。<br>BC范式既检查非主属性，又检查主属性。当只检查非主属性时，就成了第三范式。满足BC范式的关系都必然满足第三范式。或者还可以换一种说法：若一个关系达到了第三范式，并且它只有一个候选码，或者它的每个候选码都是单属性，则该关系自然达到BC范式。<br>一般来说，一个数据库设计符合3NF或BCNF就可以了。</p><h2 id="第四范式（4NF）"><a href="#第四范式（4NF）" class="headerlink" title="第四范式（4NF）"></a>第四范式（4NF）</h2><p><strong>多值依赖的概念:</strong><br>多值依赖即属性之间的一对多关系，记为K→→A。<br>函数依赖事实上是单值依赖，所以不能表达属性值之间的一对多关系。<br>平凡的多值依赖：全集U=K+A，一个K可以对应于多个A，即K→→A。此时整个表就是一组一对多关系。<br>非平凡的多值依赖：全集U=K+A+B，一个K可以对应于多个A，也可以对应于多个B，A与B互相独立，即K→→A，K→→B。整个表有多组一对多关系，且有：“一”部分是相同的属性集合，“多”部分是互相独立的属性集合。</p><p>第四范式即在满足巴斯-科德范式（BCNF）的基础上，消除非平凡且非函数依赖的多值依赖（即把同一表内的多对多关系删除）。</p><h2 id="第五范式（5NF）"><a href="#第五范式（5NF）" class="headerlink" title="第五范式（5NF）"></a>第五范式（5NF）</h2><p>即在满足第四范式（4NF）的基础上，消除不是由候选码所蕴含的连接依赖。如果关系模式R中的每一个连接依赖均由R的候选码所隐含，则称此关系模式符合第五范式。<br>函数依赖是多值依赖的一种特殊的情况，而多值依赖实际上是连接依赖的一种特殊情况。但连接依赖不像函数依赖和多值依赖可以由语义直接导出，而是在关系连接运算时才反映出来。存在连接依赖的关系模式仍可能遇到数据冗余及插入、修改、删除异常等问题。</p><h1 id="范式规范化路线"><a href="#范式规范化路线" class="headerlink" title="范式规范化路线"></a>范式规范化路线</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">第一范式(1NF)</span><br><span class="line">非码的非平凡 | ↓ 消除非主属性对码的部分函数依赖</span><br><span class="line">第二范式(2NF)</span><br><span class="line">↓ 消除非主属性对码的传递函数依赖</span><br><span class="line">第三范式(3NF)</span><br><span class="line">↓ 消除主属性对码的部分和传递函数依赖</span><br><span class="line">BC范式(BCNF)</span><br><span class="line">↓ 消除非平凡且非函数依赖的多值依赖</span><br><span class="line">第四范式(4NF)</span><br><span class="line">↓消除不是由候选码所蕴含的连接依赖</span><br><span class="line">第五范式(5NF)</span><br></pre></td></tr></table></figure><h1 id="范式规范化实例"><a href="#范式规范化实例" class="headerlink" title="范式规范化实例"></a>范式规范化实例</h1><p>以一个学校的学生系统为例分析说明，这几个范式的应用。首先我们确定一下要设计的内容包括那些。学号、学生姓名、年龄、性别、课程、课程学分、系别、学科成绩，系办地址、系办电话等信息。为了简单我们暂时只考虑这些字段信息。我们对于这些信息，关心的问题有如下几个方面:<br>学生有那些基本信息；<br>学生选了那些课，成绩是什么；<br>每个课的学分是多少；<br>学生属于那个系，系的基本信息是什么。<br><strong>第一范式:</strong><br>满足第一范式（1NF）的数据库表中的字段都是单一属性的，不可再分。这个单一属性由基本类型构成，包括整型、实数、字符型、逻辑型、日期型等。在当前的任何关系数据库管理系统（ DBMS ）中，傻瓜也不可能做出不符合第一范式的数据库，因为这些DBMS不允许你把数据库表的一列再分成二列或多列。因此，你想在现有的DBMS中设计出不符合第一范式的数据库都是不可能的。<br><strong>第二范式:</strong><br>首先我们考虑把所有这些信息放到一个表中（学号，学生姓名、年龄、性别、课程、课程学分、系别、学科成绩，系办地址、系办电话 ) ，表中存在如下的依赖关系:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(学号, 课程名称) → (姓名, 年龄, 成绩, 学分)</span><br></pre></td></tr></table></figure><p>姓名和年龄不依赖于课程，即不完全依赖于主属性，因此不满足第二范式的要求，会产生如下问题:</p><ul><li>数据冗余：同一门课程由n个学生选修， “ 学分 “ 就重复n-1次；同一个学生选修了m门课程，姓名和年龄就重复了m-1次。</li><li>更新异常：若调整了某门课程的学分，数据表中所有行的”学分”值都要更新，否则会出现同一门课程学分不同的情况；假设要开设一门新的课程，暂时还没有人选修。这样，由于还没有”学号”关键字，课程名称和学分也无法记录入数据库。</li><li>删除异常 ：假设一批学生已经完成课程的选修，这些选修记录就应该从数据库表中删除。但是，与此同时，课程名称和学分信息也被删除了。很显然，这也会导致插入异常。</li></ul><p>解决方案：把选课关系表SelectCourse改为如下三个表:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">学生：Student（学号，姓名，年龄，性别，系别，系办地址、系办电话）</span><br><span class="line">课程：Course（课程名称,学分）</span><br><span class="line">选课关系：SelectCourse（学号，课程名称，成绩）</span><br></pre></td></tr></table></figure><p><strong>第三范式:</strong><br>接着看上面的学生表Student（学号，姓名，年龄，性别，系别，系办地址、系办电话），关键字为单一关键字”学号”，因为存在如下决定关系:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">（学号）→ （姓名，年龄，性别，系别，系办地址、系办电话）</span><br></pre></td></tr></table></figure><p>但是还存在下面的决定关系：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">（学号） → (系别）→（系办地点，系办电话）</span><br></pre></td></tr></table></figure><p>即存在非关键字段”系办地点”、”系办电话”对关键字段”学号”的传递函数依赖。它也会存在数据冗余、更新异常、插入异常和删除异常的情况。<br>解决方案：根据第三范式把学生关系表分为如下两个表就可以满足第三范式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">学生：（学号，姓名，年龄，性别，系别）；</span><br><span class="line">系别：（系别，系办地址、系办电话）。</span><br></pre></td></tr></table></figure><p>上面的数据库表就是符合1NF、2NF、3NF的数据库，消除了数据冗余、更新异常、插入异常和删除异常。<br><strong>BC范式:</strong><br>假设有如下条件:<br>某公司有若干个仓库；<br>每个仓库只能有一名管理员，一名管理员只能在一个仓库中工作；<br>一个仓库中可以存放多种物品，一种物品也可以存放在不同的仓库中。每种物品在每个仓库中都有对应的数量。<br>那么关系模式仓库（仓库名，管理员，物品名，数量） 属于哪一级范式？<br>已知:<br>函数依赖集：仓库名 → 管理员，管理员 → 仓库名，（仓库名，物品名）→ 数量<br>码：（管理员，物品名），（仓库名，物品名）<br>主属性：仓库名、管理员、物品名<br>非主属性：数量</p><p>因为不存在非主属性对码的部分函数依赖和传递函数依赖，所以此关系模式属于3NF。</p><p>既然此关系模式已经属于3NF，那么这个关系模式是否存在问题呢？<br>我们来看以下几种操作：</p><ul><li>先新增加一个仓库，但尚未存放任何物品，是否可以为该仓库指派管理员？——不可以，因为物品名也是主属性，根据实体完整性的要求，主属性不能为空。</li><li>某仓库被清空后，需要删除所有与这个仓库相关的物品存放记录，会带来什么问题？——仓库本身与管理员的信息也被随之删除了。</li><li>如果某仓库更换了管理员，会带来什么问题？——这个仓库有几条物品存放记录，就要修改多少次管理员信息。</li></ul><p>从这里我们可以得出结论，在某些特殊情况下，即使关系模式符合3NF的要求，仍然存在着插入异常，修改异常与删除异常的问题，仍然不是”好”的设计。造成此问题的原因是存在着主属性对于码的部分函数依赖与传递函数依赖。（在此例中就是存在主属性【仓库名】对于码【（管理员，物品名）】的部分函数依赖。</p><p>解决方案：将表拆分成两个表，在3NF的基础上，消除主属性【仓库名】对于码【（管理员，物品名）】的部分与传递函数依赖。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">将原来的仓库（仓库名，管理员，物品名，数量）</span><br><span class="line">修改为：</span><br><span class="line">仓库（仓库名，管理员）</span><br><span class="line">库存（仓库名，物品名，数量）</span><br></pre></td></tr></table></figure><p>这样，之前的插入异常，修改异常与删除异常的问题就被解决了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数据库的基本概念&quot;&gt;&lt;a href=&quot;#数据库的基本概念&quot; class=&quot;headerlink&quot; title=&quot;数据库的基本概念&quot;&gt;&lt;/a&gt;数据库的基本概念&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;范式:&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;设计关系数据库时，遵从不同的
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://wyg1996.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="https://wyg1996.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>MySQL基础知识介绍</title>
    <link href="https://wyg1996.cn/2019/06/21/MySQL%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E4%BB%8B%E7%BB%8D/"/>
    <id>https://wyg1996.cn/2019/06/21/MySQL基础知识介绍/</id>
    <published>2019-06-21T12:32:11.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL5-7使用命令行登陆"><a href="#MySQL5-7使用命令行登陆" class="headerlink" title="MySQL5.7使用命令行登陆"></a>MySQL5.7使用命令行登陆</h1><p>首先将MySQL的安装文件夹\bin路径添加到环境变量中，否则在cmd.exe中我们无法打开mysql。</p><h2 id="本地登录MySQL数据库"><a href="#本地登录MySQL数据库" class="headerlink" title="本地登录MySQL数据库"></a>本地登录MySQL数据库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p   </span><br><span class="line">//root是用户名，输入这条命令按回车键后系统会提示你输入密码</span><br><span class="line">//然后你输入正确的密码，再按一下回车键就可以登录MySQL数据库了</span><br></pre></td></tr></table></figure><h2 id="指定端口号登录MySQL数据库"><a href="#指定端口号登录MySQL数据库" class="headerlink" title="指定端口号登录MySQL数据库"></a>指定端口号登录MySQL数据库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p  -P 3306  </span><br><span class="line">//注意指定端口的字母P为大写，而标识密码的p为小写。MySQL默认端口号为3306</span><br></pre></td></tr></table></figure><h2 id="指定IP地址和端口号登录MySQL数据库"><a href="#指定IP地址和端口号登录MySQL数据库" class="headerlink" title="指定IP地址和端口号登录MySQL数据库"></a>指定IP地址和端口号登录MySQL数据库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql -h ip -u root -p -P 3306 </span><br><span class="line">//ip即这个root账号指定的ip地址，只有从该ip地址登陆root账号才能登陆，3306为端口号</span><br><span class="line">//如：mysql -h 127.0.0.1 -u root -p -P 3306</span><br></pre></td></tr></table></figure><h1 id="MySQL5-7基本SQL语句"><a href="#MySQL5-7基本SQL语句" class="headerlink" title="MySQL5.7基本SQL语句"></a>MySQL5.7基本SQL语句</h1><h2 id="基本名词和知识"><a href="#基本名词和知识" class="headerlink" title="基本名词和知识"></a>基本名词和知识</h2><p>实例：instance；数据库：database；模式：schema；表：table；视图：view；索引：index。<br>一个关系数据库管理系统的实例（Instance）中可以建立多个数据库（database）；一个数据库中可以建立多个模式（schema）；一个模式下通常包括多个表（table）、视图（view）和索引（index）等数据库对象。<br>但是在MySQL中，schema和database是同义词。CREATE SCHEMA和CREATE DATABASE是等效的。在其他的数据库中有所不同。在oracle数据库产品中,schema是database的一部分。</p><h2 id="启动和停止Mysql服务"><a href="#启动和停止Mysql服务" class="headerlink" title="启动和停止Mysql服务"></a>启动和停止Mysql服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//cmd.exe中输入</span><br><span class="line">net start 你的mysql服务名 //回车即可启动Mysql服务</span><br><span class="line">net stop 你的mysql服务名 //回车即可关闭Mysql服务</span><br></pre></td></tr></table></figure><h2 id="用户管理"><a href="#用户管理" class="headerlink" title="用户管理"></a>用户管理</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">create user &apos;用户名&apos;@&apos;localhost&apos;identified by&apos;密码&apos;; //新建用户</span><br><span class="line">//&apos;用户名&apos;@&apos;localhost&apos;意思即为用户名@主机地址，表示该用户名的账号可以在哪些主机地址上登录</span><br><span class="line">//mysql的用户都必须先进行授权，localhost即代表127.0.0.1默认本地地址，如果用%则意味着“任何主机”，说明这个账号可以在所有主机上登录。在对用户账号进行操作时如果只用用户名，那么默认都是用户名@%。</span><br><span class="line"></span><br><span class="line">set password for &apos;用户名&apos;@&apos;localhost&apos; =&apos;密码&apos;; //更改密码</span><br><span class="line"></span><br><span class="line">show grants for &apos;用户名&apos;@&apos;主机地址&apos;; //查看该用户名的权限</span><br><span class="line">grant all privileges on *.* to &apos;name&apos;@&apos;localhost&apos;; //给位于localhost地址上的name用户所有数据库的所有权限</span><br><span class="line">grant all privileges on test.* to &apos;name&apos;@&apos;localhost&apos;; //给位于localhost地址上的name用户名为test的数据库的所有权限</span><br><span class="line">//privileges可以省略，all也可以改为select，update等具体权限</span><br><span class="line"></span><br><span class="line">flush privileges; //每当调整权限后，需要执行该语句刷新权限</span><br><span class="line"></span><br><span class="line">revoke all privileges on test.* from &apos;zgcr&apos;@&apos;localhost&apos;; //revoke是grant的反操作，去除权限</span><br></pre></td></tr></table></figure><h2 id="数据库查看、创建、删除"><a href="#数据库查看、创建、删除" class="headerlink" title="数据库查看、创建、删除"></a>数据库查看、创建、删除</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">show databases; //查看数据库</span><br><span class="line">create database if not exists test2; //创建数据库,test2为数据库名</span><br><span class="line">use test1; //使用名为test1的数据库</span><br><span class="line">drop database test1; //删除名为test1的数据库</span><br></pre></td></tr></table></figure><h2 id="创建-删除表、列、索引、视图"><a href="#创建-删除表、列、索引、视图" class="headerlink" title="创建/删除表、列、索引、视图"></a>创建/删除表、列、索引、视图</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">create table tabname(col1 type1 [not null] [primary key],col2 type2 [not null],..) //直接创建新表</span><br><span class="line">//如在cos数据库中创建Patron表：</span><br><span class="line">use cos;</span><br><span class="line">create table Patron(</span><br><span class="line">   Patron_id INT NOT NULL AUTO_INCREMENT,</span><br><span class="line">   password VARCHAR(100) NOT NULL,</span><br><span class="line">   address VARCHAR(50) NOT NULL,</span><br><span class="line">   phone_number VARCHAR(50),</span><br><span class="line">   PRIMARY KEY ( Patron_id) </span><br><span class="line">)ENGINE=InnoDB DEFAULT CHARSET=utf8;</span><br><span class="line">//如果你不想字段为NULL可以设置字段的属性为NOT NULL，在操作数据库时如果输入该字段的数据为NULL ，就会报错。</span><br><span class="line">//AUTO_INCREMENT定义列为自增的属性，一般用于主键，数值会自动加1。</span><br><span class="line">//PRIMARY KEY关键字用于定义列为主键。您可以使用多列来定义主键，列间以逗号分隔。</span><br><span class="line">//ENGINE 设置存储引擎，CHARSET 设置编码。</span><br><span class="line"></span><br><span class="line">use cos;//使用名为cos的数据库</span><br><span class="line">create table Patron2 like Patron;//根据旧表创建新表。第一种方法。Patron2为新表名，Patron为旧表名</span><br><span class="line">use cos; //使用名为cos的数据库</span><br><span class="line">create table Patron3 select * from Patron;//根据旧表创建新表。第二种方法。Patron3为新表名，Patron为旧表名</span><br><span class="line">drop table Patron3; //删除表。Patron3为表名</span><br><span class="line"></span><br><span class="line">alter table test_table add phone_number varchar(15) NOT NULL; //增加一个列。test_table为表名，phone_number为要增加的列名，后面是属性</span><br><span class="line"></span><br><span class="line">use test; //使用名为cos的数据库</span><br><span class="line">create unique index index1 on test_table(test_id); //创建索引。unique表示唯一索引，index1为索引名，test_table为表名，test_id为要创建索引的列名</span><br><span class="line">use test; //使用名为cos的数据库</span><br><span class="line">drop index index1 on test_table; //删除索引。index1索引名，test_table为索引所在的表名。索引是不可更改的，想更改必须删除重新建。</span><br><span class="line"></span><br><span class="line">create view view1 as select test_id from test_table; //创建视图，view1为创建的视图名，test_id为列明，test_table为列所在的表名</span><br><span class="line">drop view view1; //删除view1，view1为列名</span><br></pre></td></tr></table></figure><h2 id="其他基本SQL语句"><a href="#其他基本SQL语句" class="headerlink" title="其他基本SQL语句"></a>其他基本SQL语句</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">选择：select * from table1 where 范围</span><br><span class="line">插入：insert into table1(field1,field2) values(value1,value2)</span><br><span class="line">删除：delete from table1 where 范围</span><br><span class="line">更新：update table1 set field1=value1 where 范围</span><br><span class="line">查找：select * from table1 where field1 like ’%value1%’ （所有包含‘value1’这个模式的字符串）</span><br><span class="line">排序：select * from table1 order by field1,field2 [desc]</span><br><span class="line">总数：select count(*) as totalcount from table1</span><br><span class="line">求和：select sum(field1) as sumvalue from table1</span><br><span class="line">平均：select avg(field1) as avgvalue from table1</span><br><span class="line">最大：select max(field1) as maxvalue from table1</span><br><span class="line">最小：select min(field1) as minvalue from table1[separator]</span><br></pre></td></tr></table></figure><h1 id="MySQL主键、外键、索引、唯一索引的区别"><a href="#MySQL主键、外键、索引、唯一索引的区别" class="headerlink" title="MySQL主键、外键、索引、唯一索引的区别"></a>MySQL主键、外键、索引、唯一索引的区别</h1><h2 id="主键-primary-key"><a href="#主键-primary-key" class="headerlink" title="主键(primary key)"></a>主键(primary key)</h2><p>是能够唯一标识表中某一行的属性或属性组。如，一条记录包括身份正号，姓名，年龄。身份证号是唯一能确定你这个人的，其他都可能有重复，所以，身份证号是主键。<br>一个表只能有一个主键，但可以有多个候选索引。主键常与外键构成参照完整性约束，防止出现数据不一致。主键可以保证记录的唯一和主键域非空,数据库管理系统对于主键自动生成唯一索引。<br><strong>主键一定是唯一性索引，唯一性索引并不一定就是主键。 一个表中可以有多个唯一性索引，但只能有一个主键。 主键列不允许空值，而唯一性索引列允许空值。</strong><br>事实上，主键和索引都是键，不过主键是逻辑键，索引是物理键，也就是说主键不实际存在，而索引实际存在在数据库中，主键一般都要建，主要是用来避免一张表中有相同的记录，索引一般可以不建，但如果需要对该表进行查询操作，则最好建，这样可以加快检索的速度。 </p><h2 id="外键（foreign-key）"><a href="#外键（foreign-key）" class="headerlink" title="外键（foreign key）"></a>外键（foreign key）</h2><p>是用于建立和加强两个表数据之间的链接的一列或多列。用于与另一张表的关联。是能确定另一张表记录的字段，用来维护两个表之间数据的一致性。如，A表中的一个字段，是B表的主键，那他就可以是A表的外键。<br>如，某个电脑生产商，它的数据库中保存着整机和配件的产品信息。用来保存整机产品信息的表叫做PC；用来保存配件供货信息的表叫做Parts。在PC表中有一个字段，用来描述这款电脑所使用的CPU型号；在Parts 表中相应有一个字段，描述的正是CPU的型号，我们可以把它想成是全部CPU的型号列表。显然，这个厂家生产的电脑，其使用的CPU一定是供货信息表(parts)中存在的型号。这时，两个表中就存在一种约束关系(constraint)——PC表中的CPU型号受到Parts表中型号的约束。若要设置外键，在参照表(referencing table，即PC表) 和被参照表 (referencedtable，即parts表) 中，相对应的两个字段必须都设置索引(index)。<br>简言之，表的外键就是另一表的主键，外键将两表联系起来。一般情况下，要删除一张表中的主键必须首先要确保其它表中的没有相同外键（即该表中的主键没有一个外键和它相关联）。</p><h2 id="索引-index"><a href="#索引-index" class="headerlink" title="索引(index)"></a>索引(index)</h2><p>索引是对表中一个或多个列的值进行排序的结构，用来快速地寻找那些具有特定值的记录。所有MySQL索引都以B-树的形式保存。如果没有索引，执行查询时MySQL必须从第一个记录开始扫描整个表的所有记录，直至找到符合要求的记录。表里面的记录数量越多，这个操作的代价就越高。如果作为搜索条件的列上已经创建了索引，MySQL无需扫描任何记录即可迅速得到目标记录所在的位置。</p><h2 id="唯一索引"><a href="#唯一索引" class="headerlink" title="唯一索引"></a>唯一索引</h2><p><strong>所谓唯一性索引，这种索引和前面的“普通索引”基本相同，但有一个区别：索引列的所有值都只能出现一次，即必须唯一。</strong></p><h2 id="主键和索引的区别"><a href="#主键和索引的区别" class="headerlink" title="主键和索引的区别"></a>主键和索引的区别</h2><p>主键一定是唯一性索引，唯一性索引并不一定就是主键；<br> 一个表中可以有多个唯一性索引，但只能有一个主键；<br>主键列不允许空值，而唯一性索引列允许空值；<br>主键可以被其他字段作外键引用，而索引不能作为外键引用。</p><h1 id="MySQL表级锁、行级锁、页级锁、死锁、乐观锁、悲观锁、共享锁、排他锁的概念"><a href="#MySQL表级锁、行级锁、页级锁、死锁、乐观锁、悲观锁、共享锁、排他锁的概念" class="headerlink" title="MySQL表级锁、行级锁、页级锁、死锁、乐观锁、悲观锁、共享锁、排他锁的概念"></a>MySQL表级锁、行级锁、页级锁、死锁、乐观锁、悲观锁、共享锁、排他锁的概念</h1><p><strong>锁:</strong><br>锁是在执行多线程时用于强行限制资源访问的同步机制，即用于在并发控制中保证对互斥要求的满足。在DBMS中，可以按照锁的粒度把数据库锁分为行级锁（INNODB引擎）、表级锁（MYISAM引擎）和页级锁（BDB引擎）。<br><strong>在MySQL中常用存储引擎的锁机制:</strong><br>MySQL在5.5之前默认使用MyISAM存储引擎，之后使用InnoDB存储引擎。<br>MyISAM和MEMORY采用表级锁（table-level locking）；<br>InnoDB支持行级锁（row-level locking）和表级锁,默认为行级锁；<br>BDB采用页面锁（page-level locking）或表级锁，默认为页面锁；<br><strong>MySQL中各种锁之间的关系:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">                            MySQL</span><br><span class="line">                         /         \</span><br><span class="line">                  存储引擎MyISAM 存储引擎InnoDB</span><br><span class="line">                        |       /           \ </span><br><span class="line">    采用表级锁 支持事务     采用行级锁</span><br><span class="line">   /        \           /         \</span><br><span class="line">表共享锁   表独占锁     共享锁      排他锁</span><br><span class="line">                        \         /</span><br><span class="line">                      悲观锁(mysql自带)</span><br><span class="line">乐观锁需要自己实现</span><br></pre></td></tr></table></figure><p><strong>查看当前存储引擎:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &apos;%storage_engine%&apos;;</span><br></pre></td></tr></table></figure><p><strong>MyISAM引擎与InnoDB引擎的不同点:</strong><br>MyISAM操作数据都是使用表级锁，MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待。所以不会产生死锁，但是由于每操作一条记录就要锁定整个表，导致性能较低，并发不高。<br>InnoDB与MyISAM的最大不同有两点：一是 InnoDB 支持事务；二是 InnoDB 采用了行级锁。也就是你需要修改哪行，就可以只锁定哪行。在Mysql中，行级锁并不是直接锁记录，而是锁索引。InnoDB 行锁是通过给索引项加锁实现的，索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，Mysql就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。如果没有索引，InnoDB会通过隐藏的聚簇索引来对记录加锁。也就是说：如果不通过索引条件检索数据，那么InnoDB将对表中所有数据加锁，实际效果跟表级锁一样。</p><h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h2><p>表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。特点是开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。</p><h2 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h2><p>行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁和排他锁。特点是开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</p><h2 id="页级锁"><a href="#页级锁" class="headerlink" title="页级锁"></a>页级锁</h2><p>表级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁。特点是开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。</p><h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><p>指两个事务或者多个事务在同一资源上相互占用，并请求对方所占用的资源，从而造成恶性循环的现象。<br><strong>出现死锁的原因:</strong><br>系统资源不足；<br>进程运行推进的顺序不当；<br>资源分配不当。<br><strong>产生死锁的四个必要条件:</strong><br>互斥条件： 一个资源只能被一个进程使用；<br>请求和保持条件：进行获得一定资源，又对其他资源发起了请求，但是其他资源被其他线程占用，请求阻塞，但是也不会释放自己占用的资源；<br>不可剥夺条件： 指进程所获得的资源，不可能被其他进程剥夺，只能自己释放；<br>环路等待条件： 进程发生死锁，必然存在着进程-资源之间的环形链。<br><strong>常见的三种避免死锁的方法:</strong><br>如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会；<br>在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；<br>对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率。</p><p><strong>数据库也会发生死锁的现象，数据库系统实现了各种死锁检测和死锁超时机制来解除死锁，锁监视器进行死锁检测，MySQL的InnoDB处理死锁的方式是将持有最少行级排它锁的事务进行回滚。</strong></p><h2 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h2><p>乐观锁和悲观锁都是为了解决并发控制问题， 乐观锁可以认为是一种在最后提交的时候检测冲突的手段，而悲观锁则是一种避免冲突的手段。<br>乐观锁应用系统层面和数据的业务逻辑层次上的（实际上并没有加锁，只不过大家一直这样叫而已），利用程序处理并发， 它假定当某一个用户去读取某一个数据的时候，其他的用户不会来访问修改这个数据，但是在最后进行事务的提交的时候会进行版本的检查，以判断在该用户的操作过程中，没有其他用户修改了这个数据。<br>乐观锁不是数据库自带的，需要我们自己去实现。乐观锁的实现大部分都是基于版本控制实现的，级别高低是：脏读 &lt; 不可重复读 &lt; 幻读（级别介绍详细见数据库的事务隔离级别）。 除此之外，还可以通过时间戳的方式，通过提前读取，事后对比的方式实现。</p><h2 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h2><p>乐观锁和悲观锁都是为了解决并发控制问题， 乐观锁可以认为是一种在最后提交的时候检测冲突的手段，而悲观锁则是一种避免冲突的手段。<br>每次拿数据的时候都认为别的线程会修改数据，所以在每次拿的时候都会给数据上锁。上锁之后，当别的线程想要拿数据时，就会阻塞，直到给数据上锁的线程将事务提交或者回滚。传统的关系型数据库里就用到了很多这种锁机制，比如行锁，表锁，共享锁，排他锁等，都是在做操作之前先上锁。与乐观锁相对应的，悲观锁是由数据库自己实现，要用的时候，我们直接调用数据库的相关语句就可以。<br><strong>共享锁和排它锁是悲观锁的不同的实现，它俩都属于悲观锁的范畴。</strong><br><strong>共享锁:</strong><br>共享锁又称为读锁，简称S锁，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。<br>比如事务T对数据对象A加上S锁，则事务T只能读A；其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这就保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。<br><strong>排他锁:</strong><br>排他锁又称为写锁，简称X锁，排他锁就是不能与其他所并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据就行读取和修改。<br>比如事物T对数据对象A加上X锁，则只允许T读取和修改A，其它任何事务都不能再对A加任何类型的锁，直到T释放A上的锁。它防止任何其它事务获取资源上的锁，直到在事务的末尾将资源上的原始锁释放为止。</p><p><strong>注意:</strong><br>mysql InnoDB引擎默认的修改数据语句，update,delete,insert都会自动给涉及到的数据加上排他锁，select语句默认不会加任何锁类型，如果加排他锁可以使用select …for update语句，加共享锁可以使用select … lock in share mode语句。所以加过排他锁的数据行在其他事务种是不能修改数据的，也不能通过for update和lock in share mode锁的方式查询数据，但可以直接通过select …from…查询数据，因为普通查询没有任何锁机制。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;MySQL5-7使用命令行登陆&quot;&gt;&lt;a href=&quot;#MySQL5-7使用命令行登陆&quot; class=&quot;headerlink&quot; title=&quot;MySQL5.7使用命令行登陆&quot;&gt;&lt;/a&gt;MySQL5.7使用命令行登陆&lt;/h1&gt;&lt;p&gt;首先将MySQL的安装文件夹\bin
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://wyg1996.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="https://wyg1996.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>数据库基本概念介绍</title>
    <link href="https://wyg1996.cn/2019/06/21/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%BB%8B%E7%BB%8D/"/>
    <id>https://wyg1996.cn/2019/06/21/数据库基本概念介绍/</id>
    <published>2019-06-21T08:54:43.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="database和schema的区别"><a href="#database和schema的区别" class="headerlink" title="database和schema的区别"></a>database和schema的区别</h1><p><strong>模式（schema）是表、视图等数据库中对象的集合，而数据库（database）是模式的集合。</strong><br>一个关系数据库管理系统的实例（Instance）中可以建立多个数据库（database）；一个数据库中可以建立多个模式（schema）；一个模式下通常包括多个表（table）、视图（view）和索引（index）等数据库对象。<br>在一个数据库中可以有多个应用的数据表，这些不同应用的表可以放在不同的schema之中。每一个schema对应一个用户，不同的应用可以以不同的用户连接数据库，这样，一个大数据库就可以根据应用把其表分开来管理。不同的schema之间它们没有直接的关系，不同的shcema之间的表可以同名，也可以互相引用（但必须有权限），在没有操作别的schema的操作根权 下，每个用户只能操作它自己的schema下的所有的表。不同的schema下的同名的表，可以存入不同的数据（即schema用户自己的数据）。<br><strong>对schema我们还要注意以下几点:</strong><br>可以在不同模式下创建相同表名；<br>DB2系统访问表对象时使用模式名.表对象的格式；<br>对于不指明模式的表对象 以当前登录用户模式作为隐含模式访问；<br><strong>注意:</strong><br>Oracle数据库中不能新创建一个SCHEMA，要想创建一个SCHEMA，只能通过创建一个用户的方法解决。<br>而在MySQL 5.0.2及更高版本中，CREATE SCHEMA就是CREATE DATABASE的同义词。<br>在SQL Server中模式（schema）这个概念是在2005的版本里才提出来的，因此SQL Server2000不支持模式这个概念。在sql server2000中，用户和模式是不分离的。换个角度来说SQL2000中的用户和模式的概念就是为用户分配固定的模式。在SQL Server2000中，假如我们在某一个数据库中创建了用户Bosco，按么此时后台也为我们默认地创建了默认Schema （Bosco）。Schema的名字和User的名字相同。<br>而在SQL Server2005中，当我们用Create User创建数据库用户时，我们可以为该用户指定一个已经存在的Schema作为默认Schema，如果我们不指定，则该用户所默认的Schema即为dbo Schema，dbo 房间（Schema）好比一个大的公共房间，在当前登录用户没有默认Schema的前提下，如果你在大仓库中进行一些操作，比如Create Tabe，如果没有指定特定的房间（Schema），那么你的物品就只好放进公共的dbo房间（Schema）了。但是如果当前登录用户有默认的Schema，那么所做的一切操作都是在默认Schema上进行（比如当前登录用户为login1，该用户的默认Schema为login1，那么所做的所有操作都是在这个login1默认Schema上进行的）。注意dbo是一个Schema，但是dbo同时也是一个user。<br>在SQL Server2005中创建一个数据库的时候，会包括必须的4个Schema：dbo，INFORMATION_SCHEMA, guest，sys。</p><h1 id="数据库的三级模式与两级映像"><a href="#数据库的三级模式与两级映像" class="headerlink" title="数据库的三级模式与两级映像"></a>数据库的三级模式与两级映像</h1><p>三级模式与两级映像之间的关系如下所示:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">数据库管理系统</span><br><span class="line">     |</span><br><span class="line">    os</span><br><span class="line">     |</span><br><span class="line">     |-----------------&gt;  数据库</span><br><span class="line">     |                      |</span><br><span class="line">     |-----------------&gt;  内模式</span><br><span class="line">     |                      |</span><br><span class="line">     |-----------------&gt;内模式映像</span><br><span class="line">     |                      |</span><br><span class="line">     |-----------------&gt; 概念模式</span><br><span class="line">     |                  /       \</span><br><span class="line">     |-----------&gt; 外模式映像A 外模式映像B</span><br><span class="line">     |            /                    \</span><br><span class="line">     |-------&gt; 外模式A                外模式B</span><br><span class="line">     |        /      \              /      \</span><br><span class="line">     |----&gt;用户A1   用户A2         用户B1   用户B2</span><br></pre></td></tr></table></figure><h2 id="三级模式-外模式、概念模式、内模式"><a href="#三级模式-外模式、概念模式、内模式" class="headerlink" title="三级模式:外模式、概念模式、内模式"></a>三级模式:外模式、概念模式、内模式</h2><p><strong>外模式:</strong><br>外模式又称子模式或用户模式，对应于用户级。它是某个或某几个用户所看到的数据库的数据视图，是与某一应用有关的数据的逻辑表示。外模式是从模式导出的一个子集，包含模式中允许特定用户使用的那部分数据。用户可以通过外模式描述语言来描述、定义对应于用户的数据记录(外模式)，也可以利用数据操纵语言(Data Manipulation Language，DML)对这些数据记录进行。外模式反映了数据库的用户观。<br><strong>概念模式（也叫模式）:</strong><br>模式又称概念模式或逻辑模式，对应于概念级。它是由数据库设计者综合所有用户的数据，按照统一的观点构造的全局逻辑结构，是对数据库中全部数据的逻辑结构和特征的总体描述，是所有用户的公共数据视图(全局视图)。它是由数据库管理系统提供的数据模式描述语言(Data Description Language，DDL)来描述、定义的，体现、反映了数据库系统的整体观。<br><strong>内模式:</strong><br>内模式又称存储模式，对应于物理级。它是数据库中全体数据的内部表示或底层描述，是数据库最低一级的逻辑描述，它描述了数据在存储介质上的存储方式和物理结构，对应着实际存储在外存储介质上的数据库。内模式由内模式描述语言来描述、定义。它是数据库的存储观。</p><p><strong>注意:</strong><br>在一个数据库系统中只有唯一的数据库，因而作为定义、描述数据库存储结构的内模式和定义、描述数据库逻辑结构的概念模式，也是唯一的。但是建立在数据库之上的应用则是广泛的、多样的，所以对应的外模式不是唯一的，也不可能是唯一的。</p><h2 id="两级映像-外模式映像、内模式映像"><a href="#两级映像-外模式映像、内模式映像" class="headerlink" title="两级映像:外模式映像、内模式映像"></a>两级映像:外模式映像、内模式映像</h2><p><strong>外模式映像:</strong><br>一个DB只有一个概念模式，但可以有多个外模式。 对于每一个外模式，数据库系统都有一个外模式/模式映像，它定义了这个外模式与模式的对应关系。外模式的描述中通常包含了这些映像的定义。<br>当模式改变时（增加新的关系、新的属性、改变属性的数据类型等），由数据库管理员对各个外模式/模式映像作相应的改变，可以使得外模式保持不变。而又由于应用程序应该是依据外模式编写的，从而应用程序不必修改，这就保证了数据与程序的逻辑独立性。<br>外模式/模式映像保证了当模式改变时，外模式不用变，这就是逻辑独立性。<br><strong>内模式映像:</strong><br>一个DB只有一个模式，也只有一个内模式。所有模式/内模式映像是唯一的，它定义了数据全局逻辑结构与存储结构之间的对应关系。<br>当数据库的存储结构改变时（例如选用了另一个存储结构），由数据库管理员对模式/内模式映像作出相应的改变，可以使得模式保持不变，从而应用程序也不必改变。这就保证了数据和程序的物理独立性。<br>模式/内模式映像保证了当内模式改变时，模式不用变，这就是物理独立性。</p><h1 id="数据库事务的四大特性（ACID）"><a href="#数据库事务的四大特性（ACID）" class="headerlink" title="数据库事务的四大特性（ACID）"></a>数据库事务的四大特性（ACID）</h1><h2 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h2><p>事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行，在操作失败后不能对数据库中的数据有任何影响。</p><h2 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h2><p>在事务开始和完成时，数据必须保持一致状态，这意味着所有相关的数据规则都必须应用于事务的修改，以保持数据的完整性；事务结束时，所有的内部数据结构也必须是正确的。</p><h2 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h2><p>数据库系统提供一定的隔离级别，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然（注意：事务的隔离性是相对于两个事务而说的，两个事务独立执行互补干扰）。</p><h2 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h2><p>事务完成后，它对数据的修改是永久的，即使出现系统故障也能保持的正确性。</p><h1 id="内连接、外连接、交叉连接"><a href="#内连接、外连接、交叉连接" class="headerlink" title="内连接、外连接、交叉连接"></a>内连接、外连接、交叉连接</h1><h2 id="内连接"><a href="#内连接" class="headerlink" title="内连接"></a>内连接</h2><p>使用比较运算符根据每个表共有的列的值匹配两个表中的行。利用内连接可获取两表的公共部分的记录。有点类似数学中集合的交集。<br><strong>可细分为三种:</strong></p><ul><li>等值连接。在连接条件中使用等于号(=)运算符比较被连接列的列值，其查询结果中列出被连接表中的所有列，包括其中的重复列。</li><li>不等值连接。在连接条件使用除等于运算符以外的其它比较运算符比较被连接的列的列值。这些运算符包括&gt;、&gt;=、&lt;=、&lt;、!&gt;、!&lt;和&lt;&gt;。</li><li>自然连接。在连接条件中使用等于(=)运算符比较被连接列的列值，但它使用选择列表指出查询结果集合中所包括的列，并删除连接表中的重复列。<h2 id="外连接"><a href="#外连接" class="headerlink" title="外连接"></a>外连接</h2>外链接（outer join）与内连接是相反的，就是说，如果某张表中的数据在另一张中找不到对应的条目并不影响它依然出现在查询的结果中，这对于两张表都是满足的，两边都有出现null的可能，有点像数学中的并集。</li><li><em>可细分为三种:*</em></li><li>左（外）连接。左连接（left join）即为两张表进行连接时,是以处于left join语句左侧的表为基准去匹配left join语句右边的表，如果左表中的一条数据在右表中能找到与之对应的一条数据，那么就会出现在以虚表形式存在的结果表中，如果没有找到，那么会以null来代替右表中的数据去匹配左表。左连接时左边的表是全部数据，右边的只有符合条件的才有数据。</li><li>右（外）连接。右连接（right join）本质上是相当于将上述的左连接的这个过程反过来，以连接语句right join右侧的表为基准去匹配左边的表，右连接是处于right join右边的表是全部数据，左边的符合条件的有数据。</li><li>全（外）连接。全连接（full join）完整外部联接返回左表和右表中的所有行。当某行在另一个表中没有匹配行时，则另一个表的选择列表列包含空值。如果表之间有匹配行，则整个结果集行包含基表的数据值。   </li></ul><p><strong>注意:</strong><br>MySQL中没有全（外）连接。</p><h2 id="交叉连接"><a href="#交叉连接" class="headerlink" title="交叉连接"></a>交叉连接</h2><p>左表中的每一行与右表中的所有行组合。交叉联接也称作笛卡尔积。</p><h1 id="DDL、DML、DQL、DCL、TCL语句的概念"><a href="#DDL、DML、DQL、DCL、TCL语句的概念" class="headerlink" title="DDL、DML、DQL、DCL、TCL语句的概念"></a>DDL、DML、DQL、DCL、TCL语句的概念</h1><h2 id="DDL（Data-Definition-Language，数据定义语言）"><a href="#DDL（Data-Definition-Language，数据定义语言）" class="headerlink" title="DDL（Data Definition Language，数据定义语言）"></a>DDL（Data Definition Language，数据定义语言）</h2><p>数据定义语言DDL用来创建数据库中的各种对象—–表、视图、索引、同义词、聚簇等。<br><strong>常见DDL操作:</strong>       </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">show  databases;                           # 显示所有数据库</span><br><span class="line">use  数据库名;                              # 使用该数据库</span><br><span class="line">show  create  database  数据库名;           # 显示创建该数据库的SQL语句</span><br><span class="line">create  database  数据库名;                 # 创建数据库</span><br><span class="line">create  database  数据库名   character  set  utf8;        # 创建指定字符编码的数据库</span><br><span class="line">drop  databse  数据库名;                                  # 删除数据库</span><br><span class="line">create  table  表名(id int ,name char(10),age int );     # 创建表</span><br><span class="line">show  tables;                                           # 显示所有表</span><br><span class="line">show  create  table  表名;                              # 显示创建该表的SQL语句</span><br><span class="line">alter  table  表名  add  id  int ;                      # 表中新增列</span><br><span class="line">alter table 表名  modify  id  double;                   # 修改表中列的属性</span><br><span class="line">alter table 表名  change  id  id2  int;                 # 修改表中列的名字和属性</span><br><span class="line">alter table 表名  drop  id;                             # 删除表中的列</span><br><span class="line">rename  table  表名  to  新表名;                         # 修改表格的名字</span><br><span class="line">alter  table  表名  character  set  utf8;               # 修改表的字符编码格式</span><br></pre></td></tr></table></figure><h2 id="DML（-Data-Manipulation-Language，数据操纵语言）"><a href="#DML（-Data-Manipulation-Language，数据操纵语言）" class="headerlink" title="DML（ Data Manipulation Language，数据操纵语言）"></a>DML（ Data Manipulation Language，数据操纵语言）</h2><p>使用户能够查询数据库以及操作已有数据库中的数据的计算机语言。主要有三种形式：插入（insert）；更新（update）；删除（delete）。<br><strong>常见DML操作:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">insert  into  表名  (字段1,字段2,字段3)   values  (值1,值2,值3)       # 新增值到表中</span><br><span class="line">update  表名  set  name = &apos;xx&apos;  where  id  =3;                     # 更新表中数据</span><br><span class="line">delete  from  表名  where  id  =  2;                               # 删除表中的数据</span><br></pre></td></tr></table></figure><h2 id="DQL（Data-Query-Language-SELECT，数据查询语言）"><a href="#DQL（Data-Query-Language-SELECT，数据查询语言）" class="headerlink" title="DQL（Data Query Language SELECT，数据查询语言）"></a>DQL（Data Query Language SELECT，数据查询语言）</h2><p>主要用来查看表中的数据，也是平时使用最多的操作。<br>数据查询语言DQL基本结构是由SELECT子句，FROM子句，WHERE子句组成的查询块：<br>select &lt;字段名表&gt; from &lt;表或视图名&gt; where &lt;查询条件&gt;<br><strong>常见DQL操作:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">select  *  from  表名  where  id  =3;                                 # 查询表中数据</span><br><span class="line">select  *  from  表名  order  by  id  desc | asc;                     # 排序查询</span><br><span class="line">select  *  from  表名  group  by  字段;                               # 分组查询</span><br><span class="line">select  *  from  表名  where  name  like  &apos;%aa%&apos;;                     # 模糊查询</span><br><span class="line">select  *  from  表名  limit  (2,5);                                  # 分页查询</span><br><span class="line">select  *  from  表名  where  age  between  20  and  30;              # 范围查询</span><br><span class="line">select  *  from  表名  where  id  in (1,3,5);                         # 部分查询</span><br></pre></td></tr></table></figure><h2 id="DCL（Data-Control-Language，数据控制语言）"><a href="#DCL（Data-Control-Language，数据控制语言）" class="headerlink" title="DCL（Data Control Language，数据控制语言）"></a>DCL（Data Control Language，数据控制语言）</h2><p>用来授予或回收访问数据库的某种特权，并控制数据库操纵事务发生的时间及效果。主要有：授权（grant）；取消权限（revoke）。<br><strong>常见DCL操作:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 给用户jerry授予对test_db数据库的增删改查权限，允许该用户从IP为&apos;192.168.0.10&apos;的网络登录</span><br><span class="line">GRANT INSERT,SELECT,UPDATE,DELETE ON test_db.* TO &apos;jerry&apos;@&apos;192.168.0.10&apos; IDENTIFIED BY &apos;password&apos; WITH GRANT OPTION;</span><br><span class="line">或</span><br><span class="line">CREATE USER &apos;jerry&apos;@&apos;192.168.0.10&apos; IDENTIFIED BY &apos;password&apos;;</span><br><span class="line">GRANT INSERT,SELECT,UPDATE,DELETE ON test_db.* TO &apos;jerry&apos;@&apos;192.168.0.10&apos;;</span><br><span class="line"># 收回用户对test_db库的删除权限</span><br><span class="line">REVOKE DELETE ON test_db.* FROM &apos;jerry&apos;@&apos;192.168.0.10&apos;;</span><br><span class="line"># 查询给&apos;jerry&apos;@&apos;192.168.0.10&apos;所授予的所有权限：</span><br><span class="line">SHOW GRANTS FOR &apos;jerry&apos;@&apos;192.168.0.10&apos;;</span><br></pre></td></tr></table></figure><h2 id="TCL（Transaction-Control-Language，事物控制语言）"><a href="#TCL（Transaction-Control-Language，事物控制语言）" class="headerlink" title="TCL（Transaction Control Language，事物控制语言）"></a>TCL（Transaction Control Language，事物控制语言）</h2><p>用来对事务进行管理。 主要有：保存已完成事务动作结果 （COMMIT）；保存事务相关数据和状态用以可能的回滚操作（SAVEPOINT）；恢复事务相关数据至上一次COMMIT操作之后（ROLLBACK）；设置事务选项（SET TRANSACTION）。<br>DML语句对表数据进行操作的时候都会加上行级锁，确认完成后，必须加上事物处理结束的命令COMMIT才能正式生效，否则改变不一定写入数据库里。如果想撤回这些操作, 可以用命令 ROLLBACK 复原。</p><p><strong>注意:</strong><br>在运行INSERT，DELETE和UPDATE语句前最好估算一下可能操作的记录范围，应该把它限定在较小范围内，例如一万条记录，否则ORACLE处理这个事物用到很大的回退段。程序响应慢甚至失去响应。如果记录数上十万以上这些操作。可以把这些SQL语句分段分次完成。其间加上COMMIT确认事物处理。</p><p><strong>数据的提交:</strong></p><ul><li>显式提交:用COMMIT命令直接完成的提交为显式提交。其格式为：<br>SQL&gt;COMMIT；</li><li>隐式提交:用SQL命令间接完成的提交为隐式提交。这些命令是：<br>ALTER，AUDIT，COMMENT，CONNECT，CREATE，DISCONNECT，DROP，EXIT，GRANT，NOAUDIT，QUIT，REVOKE，RENAME。</li><li>自动提交:若把AUTOCOMMIT设置为ON，则在插入、修改、删除语句执行后，系统将自动进行提交，这就是自动提交。其格式为：<br>SQL&gt;SET AUTOCOMMIT ON；</li></ul><h1 id="数据库的传统集合运算（并、差、交、笛卡尔积）和专门的关系运算（选择、投影、连接、除）"><a href="#数据库的传统集合运算（并、差、交、笛卡尔积）和专门的关系运算（选择、投影、连接、除）" class="headerlink" title="数据库的传统集合运算（并、差、交、笛卡尔积）和专门的关系运算（选择、投影、连接、除）"></a>数据库的传统集合运算（并、差、交、笛卡尔积）和专门的关系运算（选择、投影、连接、除）</h1><p><strong>集合运算符:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">∪ 并</span><br><span class="line">∩ 交</span><br><span class="line">-  差</span><br></pre></td></tr></table></figure><p><strong>专门的关系运算符:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">σ 选择</span><br><span class="line">∏ 投影</span><br><span class="line">+ 连接</span><br><span class="line">÷ 除</span><br></pre></td></tr></table></figure><p><strong>在数据库中每行就是一个元组，每列就是一个属性。</strong></p><h2 id="传统集合运算（并、差、交、笛卡尔积）"><a href="#传统集合运算（并、差、交、笛卡尔积）" class="headerlink" title="传统集合运算（并、差、交、笛卡尔积）"></a>传统集合运算（并、差、交、笛卡尔积）</h2><p><strong>并:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">     R                  S                                                   </span><br><span class="line">A    B    C        A    B    C       </span><br><span class="line">a1   b1   c1       a1   b2   c2       </span><br><span class="line">a1   b2   c2       a1   b3   c2      </span><br><span class="line">a2   b2   c1       a2   b2   c1       </span><br><span class="line">    R∪S                                         </span><br><span class="line">A    B    C</span><br><span class="line">a1   b1   c1</span><br><span class="line">a1   b2   c2</span><br><span class="line">a1   b3   c2</span><br><span class="line">a2   b2   c1</span><br></pre></td></tr></table></figure><p><strong>差:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">     R                  S                                                   </span><br><span class="line">A    B    C        A    B    C       </span><br><span class="line">a1   b1   c1       a1   b2   c2       </span><br><span class="line">a1   b2   c2       a1   b3   c2      </span><br><span class="line">a2   b2   c1       a2   b2   c1       </span><br><span class="line">    R-S                                         </span><br><span class="line">A    B    C</span><br><span class="line">a1   b1   c1</span><br></pre></td></tr></table></figure><p><strong>交:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">     R                  S                                                   </span><br><span class="line">A    B    C        A    B    C       </span><br><span class="line">a1   b1   c1       a1   b2   c2       </span><br><span class="line">a1   b2   c2       a1   b3   c2      </span><br><span class="line">a2   b2   c1       a2   b2   c1       </span><br><span class="line">    R∩S                                         </span><br><span class="line">A    B    C</span><br><span class="line">a1   b2   c2</span><br><span class="line">a2   b2   c1</span><br></pre></td></tr></table></figure><p><strong>笛卡尔积:</strong><br>简单来说，就是把R表的第一行与S表第一行组合写在一起，作为一行。然后把R表的第一行与S表第二行依此写在一起，作为新一行。以此类推。当S表的每一行都与R表的第一行组合过一次以后，换R表的第二行与S表第一行组合，以此类推，直到R表与S表的每一行都组合过一次，则运算完毕。如果R表有N行，S表有M行，那么笛卡尔积R×S有N×M行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">     R                  S                                                   </span><br><span class="line">A    B    C        A    B    C       </span><br><span class="line">a1   b1   c1       a1   b2   c2       </span><br><span class="line">a1   b2   c2       a1   b3   c2      </span><br><span class="line">a2   b2   c1       a2   b2   c1       </span><br><span class="line">    RxS                                         </span><br><span class="line">A    B    C    A    B    C</span><br><span class="line">a1   b1   c1   a1   b2   c2</span><br><span class="line">a1   b1   c1   a1   b3   c2</span><br><span class="line">a1   b1   c1   a2   b2   c1</span><br><span class="line">a1   b2   c2   a1   b2   c2</span><br><span class="line">a1   b2   c2   a1   b3   c2 </span><br><span class="line">a1   b2   c2   a2   b2   c1</span><br><span class="line">a2   b2   c1   a1   b2   c2</span><br><span class="line">a2   b2   c1   a1   b3   c2</span><br><span class="line">a2   b2   c1   a2   b2   c1</span><br></pre></td></tr></table></figure><h2 id="专门的关系运算（选择、投影、连接、除）"><a href="#专门的关系运算（选择、投影、连接、除）" class="headerlink" title="专门的关系运算（选择、投影、连接、除）"></a>专门的关系运算（选择、投影、连接、除）</h2><p>数据库的专门关系运算有：选择（对关系进行水平分割）、投影（对关系进行垂直分割）、连接、自然连接（关系的结合）、除运算等。<br><strong>选择（selection）:</strong><br>选择就是”筛选行”。选择一般要对一张表选择符合条件的行（但包含所有列）。<br><strong>举例:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">     R</span><br><span class="line">A    B    C</span><br><span class="line">a    b    c</span><br><span class="line">d    a    f</span><br><span class="line">c    b    d</span><br><span class="line">  σ(B=b)(R)</span><br><span class="line">A    B    C</span><br><span class="line">a    b    c</span><br><span class="line">c    b    d</span><br></pre></td></tr></table></figure><p><strong>投影（projection）:</strong><br>投影就是”筛选列”。一个数据库表，如仅希望得到其一部分的列的内容（但全部行），就是投影。<br><strong>举例:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">     R</span><br><span class="line">A    B    C</span><br><span class="line">a    b    c</span><br><span class="line">d    a    f</span><br><span class="line">c    b    d</span><br><span class="line">  ∏A,C(R)</span><br><span class="line">A    C</span><br><span class="line">a    c</span><br><span class="line">d    f</span><br><span class="line">c    d</span><br></pre></td></tr></table></figure><p><strong>除（division）:</strong><br>除是笛卡尔积的逆运算。设关系R和S分别有r列和s列（r&gt;s，且s≠0），那么R÷S的结果有（r-s）个列，并且是满足下列条件的最大的表：其中每行与S中的每行组合成的新行都在R中。注意有时关系之间的除法也有”余数”，可能S×T的结果为R的一部分（最大的一部分），R中的多余部分为”余数”。<br><strong>举例:</strong><br>C、D是关系S中的两个属性，故在R集合中对除了C, D之外的属性即A、B两属性进行投影, 得到a  b; b  c; e  d;这三组，然后用这个结果与关系S进行笛卡尔积运算，发现b  c  c  d这组在关系R中没有, 其余a  b; e  d;做的运算在R中存在。因此最后结果为a  b; e  d。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">       R</span><br><span class="line">A    B    C    D</span><br><span class="line">a    b    c    d</span><br><span class="line">a    b    e    f</span><br><span class="line">b    c    e    f</span><br><span class="line">e    d    c    d</span><br><span class="line">e    d    e    f</span><br><span class="line">a    b    d    e</span><br><span class="line">  S</span><br><span class="line">C    D</span><br><span class="line">c    d</span><br><span class="line">e    f</span><br><span class="line"> R÷S</span><br><span class="line">A    B</span><br><span class="line">a    b</span><br><span class="line">e    d</span><br></pre></td></tr></table></figure><p><strong>连接（join）:</strong><br>两表笛卡尔积的结果比较庞大，实际应用中一般仅选取其中一部分的行，选取两表列之间满足一定条件的行，这就是关系之间的连接。<br><strong>根据连接条件的种类不同，关系之间的连接分为等值连接、大于连接、小于连接、自然连接:</strong></p><ul><li>条件是类似于”B列=D列”的”某列=某列”的条件，就是等值连接；</li><li>条件是”某列&gt;某列”的，就是大于连接；</li><li>条件是”某列&lt;某列”的，就是小于连接。</li><li>自然连接是不提出明确的连接条件，但”暗含”着一个条件，就是”列名相同的值也相同”。在自然连接的结果表中，往往还要合并相同列名的列。当对关系R和S进行自然连接时，要求R和S含有一个或者多个共有的属性。</li></ul><p><strong>举例:</strong><br>等值连接:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">     R</span><br><span class="line">A    B    C</span><br><span class="line">a1   b1   5</span><br><span class="line">a1   b2   6</span><br><span class="line">a2   b3   8</span><br><span class="line">a2   b4   12</span><br><span class="line">   S</span><br><span class="line">B    E</span><br><span class="line">b1   3</span><br><span class="line">b2   7</span><br><span class="line">b3   10</span><br><span class="line">b3   2</span><br><span class="line">b5   2</span><br><span class="line">R.B=S.B的等值连接:</span><br><span class="line">A    R.B    C    S.B    E</span><br><span class="line">a1   b1     5     b1    3</span><br><span class="line">a1   b2     6     b2    7</span><br><span class="line">a2   b3     8     b3    10</span><br><span class="line">a2   b3     8     b3    2</span><br></pre></td></tr></table></figure><p>小于连接:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">     R</span><br><span class="line">A    B    C</span><br><span class="line">1    2    3</span><br><span class="line">4    5    6</span><br><span class="line">7    8    9</span><br><span class="line">  S</span><br><span class="line">D    E</span><br><span class="line">3    1</span><br><span class="line">6    2</span><br><span class="line">B&lt;D的小于连接</span><br><span class="line">A    B    C    D    E</span><br><span class="line">1    2    3    3    1</span><br><span class="line">1    2    3    6    2</span><br><span class="line">4    5    6    6    2</span><br></pre></td></tr></table></figure><p>自然连接:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">     R</span><br><span class="line">A    B    C</span><br><span class="line">a    b    c</span><br><span class="line">d    b    c</span><br><span class="line">b    b    f</span><br><span class="line">c    a    d</span><br><span class="line">     S</span><br><span class="line">B    C    D</span><br><span class="line">b    c    d</span><br><span class="line">b    c    e</span><br><span class="line">a    d    b</span><br><span class="line">R与S的自然连接暗含的条件是R.B=S.B且R.C=S.C，因为R、S中有同名的2列B、C</span><br><span class="line">A    B    C    D</span><br><span class="line">a    b    c    d</span><br><span class="line">a    b    c    e</span><br><span class="line">d    b    c    d</span><br><span class="line">d    b    c    e</span><br><span class="line">c    a    d    b</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;database和schema的区别&quot;&gt;&lt;a href=&quot;#database和schema的区别&quot; class=&quot;headerlink&quot; title=&quot;database和schema的区别&quot;&gt;&lt;/a&gt;database和schema的区别&lt;/h1&gt;&lt;p&gt;&lt;stron
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://wyg1996.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="https://wyg1996.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle Lending Club Loan Data数据可视化分析与不良贷款预测</title>
    <link href="https://wyg1996.cn/2019/06/21/Kaggle%20Lending%20Club%20Loan%20Data%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90%E4%B8%8E%E4%B8%8D%E8%89%AF%E8%B4%B7%E6%AC%BE%E9%A2%84%E6%B5%8B/"/>
    <id>https://wyg1996.cn/2019/06/21/Kaggle Lending Club Loan Data数据可视化分析与不良贷款预测/</id>
    <published>2019-06-21T06:14:07.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h1><p>该数据集地址: <a href="https://www.kaggle.com/wendykan/lending-club-loan-data" target="_blank" rel="noopener">https://www.kaggle.com/wendykan/lending-club-loan-data</a> 。<br>该数据集是一个单一的CSV文件（loan.csv），解压后总大小1.22G，共有2260668笔Lending Club平台2012-2018年的贷款数据，文件的每一行就是一条贷款数据，每一行中包含了145个特征。<br>另外，数据集中有一个LCDataDictionary.xlsx文件，专门介绍每个特征的含义。<br><strong>我的完整分析代码已经上传到我的kaggle kernel中:</strong><br><a href="https://www.kaggle.com/zgcr654321/data-analysis-visualization-and-loan-prediction" target="_blank" rel="noopener">https://www.kaggle.com/zgcr654321/data-analysis-visualization-and-loan-prediction</a> 。</p><h1 id="数据可视化分析前的数据预处理"><a href="#数据可视化分析前的数据预处理" class="headerlink" title="数据可视化分析前的数据预处理"></a>数据可视化分析前的数据预处理</h1><h2 id="引入包和数据集"><a href="#引入包和数据集" class="headerlink" title="引入包和数据集"></a>引入包和数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> plotly</span><br><span class="line"><span class="keyword">import</span> plotly.plotly <span class="keyword">as</span> py</span><br><span class="line"><span class="keyword">import</span> plotly.graph_objs <span class="keyword">as</span> go</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Bar3D, Line3D</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.simplefilter(action=<span class="string">"ignore"</span>, category=FutureWarning)</span><br><span class="line">warnings.simplefilter(action=<span class="string">"ignore"</span>, category=DeprecationWarning)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data preprocessing before Data analysis visualization</span></span><br><span class="line">loan_data = pd.read_csv(<span class="string">"loan.csv"</span>, low_memory=<span class="literal">False</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># (2260668, 145)</span></span><br></pre></td></tr></table></figure><h2 id="对特征缺失值的处理"><a href="#对特征缺失值的处理" class="headerlink" title="对特征缺失值的处理"></a>对特征缺失值的处理</h2><p>计算特征缺失值比例的函数:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># calculate the missing value percent of features</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_missing_data_table</span><span class="params">(data)</span>:</span></span><br><span class="line">    total = data.isnull().sum().sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">    percent = (data.isnull().sum() / data.shape[<span class="number">0</span>]).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">    missing_data = pd.concat([total, percent], axis=<span class="number">1</span>, keys=[<span class="string">"Total"</span>, <span class="string">"Percent"</span>])</span><br><span class="line">    missing_data.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line">    missing_data.rename(columns=&#123;<span class="string">"index"</span>: <span class="string">"feature_name"</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> missing_data</span><br></pre></td></tr></table></figure><p>保存所有特征缺失值比例的计算结果:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save missing value percent of features</span></span><br><span class="line">missing_data_count = draw_missing_data_table(loan_data)</span><br><span class="line">missing_data_count.to_csv(<span class="string">"missing_data_count.csv"</span>)</span><br><span class="line">missing_data_count = pd.read_csv(<span class="string">"missing_data_count.csv"</span>, header=<span class="number">0</span>, index_col=<span class="number">0</span>)</span><br><span class="line">missing_data_count = missing_data_count[missing_data_count[<span class="string">"Percent"</span>] &gt; <span class="number">0.0</span>]</span><br><span class="line">print(missing_data_count.head())</span><br><span class="line"><span class="comment">#                                  feature_name    Total   Percent</span></span><br><span class="line"><span class="comment"># 0                                          id  2260668  1.000000</span></span><br><span class="line"><span class="comment"># 1                                   member_id  2260668  1.000000</span></span><br><span class="line"><span class="comment"># 2                                         url  2260668  1.000000</span></span><br><span class="line"><span class="comment"># 3  orig_projected_additional_accrued_interest  2252242  0.996273</span></span><br><span class="line"><span class="comment"># 4                         hardship_start_date  2250055  0.995305</span></span><br></pre></td></tr></table></figure><p>画缺失值比例图，只画出缺失值比例大于0.03的特征:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># draw a graph of missing value percent of features(percent&gt;0.03)</span></span><br><span class="line">missing_data_count_show = missing_data_count[missing_data_count[<span class="string">"Percent"</span>] &gt; <span class="number">0.03</span>]</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f, ax = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.barplot(x=missing_data_count_show[<span class="string">"Percent"</span>], y=missing_data_count_show[<span class="string">"feature_name"</span>], ax=ax)</span><br><span class="line">ax.set_title(<span class="string">"Missing value percent for each feature"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">"missing percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">"feature name"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f.savefig(<span class="string">"./pictures/Missing value percent for each feature.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><p>删除缺失值比例大于0.15的特征:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># delete features that missing value percent more than 0.15</span></span><br><span class="line"><span class="keyword">for</span> index, feature_count_null <span class="keyword">in</span> missing_data_count.iterrows():</span><br><span class="line"><span class="keyword">if</span> feature_count_null[<span class="string">"Percent"</span>] &gt; <span class="number">0.15</span>:</span><br><span class="line">drop_feature_name = feature_count_null[<span class="string">"feature_name"</span>]</span><br><span class="line">loan_data.drop([drop_feature_name], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">missing_data_count = missing_data_count[missing_data_count[<span class="string">"Percent"</span>] &lt;= <span class="number">0.15</span>]</span><br><span class="line">print(missing_data_count.head())</span><br><span class="line"><span class="comment">#              feature_name   Total   Percent</span></span><br><span class="line"><span class="comment"># 58  mths_since_recent_inq  295435  0.130685</span></span><br><span class="line"><span class="comment"># 59              emp_title  166969  0.073858</span></span><br><span class="line"><span class="comment"># 60       num_tl_120dpd_2m  153657  0.067970</span></span><br><span class="line"><span class="comment"># 61             emp_length  146907  0.064984</span></span><br><span class="line"><span class="comment"># 62     mo_sin_old_il_acct  139071  0.061518</span></span><br></pre></td></tr></table></figure><p>对于缺失值比例小于0.04的特征，删除含有这些特征的缺失值的行数据:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># delete rows which contain missing value for features that  missing value precent less than 0.04</span></span><br><span class="line"><span class="keyword">for</span> index, feature_count_null <span class="keyword">in</span> missing_data_count.iterrows():</span><br><span class="line"><span class="keyword">if</span> feature_count_null[<span class="string">"Percent"</span>] &lt; <span class="number">0.04</span>:</span><br><span class="line">drop_feature_name = feature_count_null[<span class="string">"feature_name"</span>]</span><br><span class="line">drop_index = loan_data[loan_data[drop_feature_name].isnull().values == <span class="literal">True</span>].index</span><br><span class="line">loan_data.drop(index=drop_index, axis=<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment"># (2137073, 87)</span></span><br></pre></td></tr></table></figure><p>再计算此时数据集特征的缺失值比例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># calculate the missing value percent of features again,save missing value percent of features</span></span><br><span class="line">missing_data_count_2 = draw_missing_data_table(loan_data)</span><br><span class="line">missing_data_count_2.to_csv(<span class="string">"missing_data_count_2.csv"</span>)</span><br><span class="line">missing_data_count_2 = missing_data_count_2[missing_data_count_2[<span class="string">"Percent"</span>] &gt; <span class="number">0.0</span>]</span><br><span class="line">print(missing_data_count_2)</span><br><span class="line"><span class="comment">#             feature_name   Total   Percent</span></span><br><span class="line"><span class="comment"># 0  mths_since_recent_inq  235741  0.110310</span></span><br><span class="line"><span class="comment"># 1              emp_title  154722  0.072399</span></span><br><span class="line"><span class="comment"># 2             emp_length  137175  0.064188</span></span><br><span class="line"><span class="comment"># 3       num_tl_120dpd_2m   81243  0.038016</span></span><br><span class="line"><span class="comment"># 4     mo_sin_old_il_acct   66915  0.031312</span></span><br></pre></td></tr></table></figure><p>剩余5个有缺失值的特征，其中3个用0填充，有两个特征先不填充，等到模型训练前再处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fill missing value of mths_since_recent_inq/num_tl_120dpd_2m/mo_sin_old_il_acct by mean value of each feature</span></span><br><span class="line"><span class="comment"># don"t fill emp_title and emp_length</span></span><br><span class="line">loan_data[<span class="string">"mths_since_recent_inq"</span>].fillna(loan_data[<span class="string">"mths_since_recent_inq"</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line">loan_data[<span class="string">"num_tl_120dpd_2m"</span>].fillna(loan_data[<span class="string">"num_tl_120dpd_2m"</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line">loan_data[<span class="string">"mo_sin_old_il_acct"</span>].fillna(loan_data[<span class="string">"mo_sin_old_il_acct"</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Convert the value of feature:"term" from category to numeric</span></span><br><span class="line">term_dict = &#123;<span class="string">" 36 months"</span>: <span class="number">36</span>, <span class="string">" 60 months"</span>: <span class="number">60</span>&#125;</span><br><span class="line">loan_data[<span class="string">"term"</span>] = loan_data[<span class="string">"term"</span>].map(term_dict)</span><br><span class="line">loan_data[<span class="string">"term"</span>] = loan_data[<span class="string">"term"</span>].astype(<span class="string">"float"</span>)</span><br></pre></td></tr></table></figure><p>再计算此时数据集规模和数据集特征的缺失值比例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># calculate the missing value percent of features the three times,save missing value percent of features</span></span><br><span class="line">missing_data_count_3 = draw_missing_data_table(loan_data)</span><br><span class="line">missing_data_count_3.to_csv(<span class="string">"missing_data_count_3.csv"</span>)</span><br><span class="line">missing_data_count_3 = missing_data_count_3[missing_data_count_3[<span class="string">"Percent"</span>] &gt; <span class="number">0.0</span>]</span><br><span class="line">print(missing_data_count_3)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment">#   feature_name   Total   Percent</span></span><br><span class="line"><span class="comment"># 0    emp_title  154722  0.072399</span></span><br><span class="line"><span class="comment"># 1   emp_length  137175  0.064188</span></span><br><span class="line"><span class="comment"># (2137073, 87)</span></span><br></pre></td></tr></table></figure><h2 id="保存处理好的数据集"><a href="#保存处理好的数据集" class="headerlink" title="保存处理好的数据集"></a>保存处理好的数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save the dataset after all missing value operation</span></span><br><span class="line">loan_data.to_csv(<span class="string">"loan_clean_data.csv"</span>, index=<span class="literal">None</span>)</span><br><span class="line">loan_data = pd.read_csv(<span class="string">"loan_clean_data.csv"</span>, low_memory=<span class="literal">False</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment"># (2137073, 87)</span></span><br></pre></td></tr></table></figure><p><strong>注意:</strong><br>如果我们想直接进行模型训练和预测，那么在进行模型训练和预测前的数据集预处理前读入loan_clean_data.csv文件即可。</p><h1 id="数据可视化分析"><a href="#数据可视化分析" class="headerlink" title="数据可视化分析"></a>数据可视化分析</h1><h2 id="申请贷款金额和实际贷款金额的数据分布"><a href="#申请贷款金额和实际贷款金额的数据分布" class="headerlink" title="申请贷款金额和实际贷款金额的数据分布"></a>申请贷款金额和实际贷款金额的数据分布</h2><p>按照数据集中LCDataDictionary.xlsx文件给出的含义，特征loan_amnt和funded_amnt分别代表每笔贷款申请的贷款金额和实际贷款的金额。这两个特征的数值应当是一致的。为了验证一下这个设想是否正确，我们单独提取出这两个特征，分别画出每个特征的数据分布图。我们可以看到特征分布确实是一致的，说明这两个数据分布一致。后面在计算皮尔森相关系数矩阵时我们也发现这两个特征之间的相关系数为+1，这证明了我们之前的设想是正确的。我们注意到大部分贷款额度都在20000以下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Data distribution of the loan amount and actual loan amount</span></span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan, ax_loan = plt.subplots(<span class="number">2</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.distplot(loan_data[<span class="string">"loan_amnt"</span>], ax=ax_loan[<span class="number">0</span>, <span class="number">0</span>], color=<span class="string">"#F7522F"</span>)</span><br><span class="line">sns.violinplot(y=loan_data[<span class="string">"loan_amnt"</span>], ax=ax_loan[<span class="number">0</span>, <span class="number">1</span>], inner=<span class="string">"quartile"</span>, palette=<span class="string">"Reds"</span>)</span><br><span class="line">sns.distplot(loan_data[<span class="string">"funded_amnt"</span>], ax=ax_loan[<span class="number">1</span>, <span class="number">0</span>], color=<span class="string">"#2F8FF7"</span>)</span><br><span class="line">sns.violinplot(y=loan_data[<span class="string">"funded_amnt"</span>], ax=ax_loan[<span class="number">1</span>, <span class="number">1</span>], inner=<span class="string">"quartile"</span>, palette=<span class="string">"Blues"</span>)</span><br><span class="line">ax_loan[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">"Loan amount distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">"Loan amount distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">"Funded amount distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">1</span>, <span class="number">1</span>].set_title(<span class="string">"Funded amount distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">0</span>, <span class="number">0</span>].set_xlabel(<span class="string">"loan amount"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">1</span>, <span class="number">0</span>].set_xlabel(<span class="string">"loan amount"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">0</span>, <span class="number">1</span>].set_ylabel(<span class="string">"loan amount"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">1</span>, <span class="number">1</span>].set_ylabel(<span class="string">"loan amount"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_loan.savefig(<span class="string">"./pictures/Loan amount and funded amount distribution.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="每年贷款笔数直方图与每年贷款总金额直方图"><a href="#每年贷款笔数直方图与每年贷款总金额直方图" class="headerlink" title="每年贷款笔数直方图与每年贷款总金额直方图"></a>每年贷款笔数直方图与每年贷款总金额直方图</h2><p>issue_d是贷款发放的时间。这是一个年+月形式的时间特征。我们可以使用正则表达式，将其分解为年和月两个特征。然后我们按照年份统计每年放贷笔数和每年放贷的总金额，画成直方图。可以看到贷款笔数和贷款总金额在2012-2015年逐年攀升，而2015年-2018年上升幅度不大，这可能与公司放贷的经营策略有关。我们注意到两个图的分布十分相似，这说明每笔贷款的平均贷款金额波动不大。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># histogram of annual loan figures and histogram of total amount of annual loan lending</span></span><br><span class="line">loan_data[<span class="string">"year"</span>] = pd.to_datetime(loan_data[<span class="string">"issue_d"</span>]).dt.year</span><br><span class="line">loan_year_num = loan_data[<span class="string">"year"</span>].value_counts().to_dict()</span><br><span class="line">loan_year_num_pd = pd.DataFrame(list(loan_year_num.items()), columns=[<span class="string">"year"</span>, <span class="string">"loan times"</span>])</span><br><span class="line">loan_year_num_pd.sort_values(<span class="string">"year"</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(loan_year_num_pd)</span></span><br><span class="line">loan_data[<span class="string">"year"</span>] = pd.to_datetime(loan_data[<span class="string">"issue_d"</span>]).dt.year</span><br><span class="line">loan_money_count_per_year = loan_data.groupby(<span class="string">"year"</span>)[<span class="string">"loan_amnt"</span>].sum().to_dict()</span><br><span class="line">loan_money_count_per_year_pd = pd.DataFrame(list(loan_money_count_per_year.items()), columns=[<span class="string">"year"</span>, <span class="string">"loan_amnt"</span>])</span><br><span class="line">loan_money_count_per_year_pd.sort_values(<span class="string">"year"</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(loan_money_count_per_year_pd)</span></span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan_per_year, ax_loan_per_year = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.barplot(loan_year_num_pd[<span class="string">"year"</span>], loan_year_num_pd[<span class="string">"loan times"</span>], ax=ax_loan_per_year[<span class="number">0</span>],</span><br><span class="line">            palette=<span class="string">"tab10"</span>)</span><br><span class="line">sns.barplot(loan_money_count_per_year_pd[<span class="string">"year"</span>], loan_money_count_per_year_pd[<span class="string">"loan_amnt"</span>], ax=ax_loan_per_year[<span class="number">1</span>],</span><br><span class="line">            palette=<span class="string">"tab10"</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">0</span>].set_title(<span class="string">"loan times per year"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">1</span>].set_title(<span class="string">"Loan amount per year"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">0</span>].set_xlabel(<span class="string">"year"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">0</span>].set_ylabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">1</span>].set_xlabel(<span class="string">"year"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">1</span>].set_ylabel(<span class="string">"loan amount"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"year"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment"># (2137073, 87)</span></span><br><span class="line">f_loan_per_year.savefig(<span class="string">"./pictures/loan times and loan amount per year.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="各年各月每笔贷款平均贷款金额3D柱状图和3D折线图"><a href="#各年各月每笔贷款平均贷款金额3D柱状图和3D折线图" class="headerlink" title="各年各月每笔贷款平均贷款金额3D柱状图和3D折线图"></a>各年各月每笔贷款平均贷款金额3D柱状图和3D折线图</h2><p>上面我们猜测每笔贷款平均金额的变化不大。现在我们来验证一下。根据上面我们分解得到的年和月两个特征，我们将数据集先按年分组，再按月分组，然后计算每个月中每笔贷款的平均贷款金额，画出每年每月每笔贷款的平均贷款金额的3D柱状图和3D折线图，我们可以发现每笔贷款平均金额确实变化不大。对于2012年的那几个月每笔贷款平均金额偏低大概是由于2012年的前面几个月份没有数据导致的。<br>通过3D折线图我们可以清楚地看出每笔贷款的平均贷款金额一直变化不大。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 各年各月每笔贷款平均贷款金额3D柱状图和3D折线图</span></span><br><span class="line"><span class="comment"># loan_data["month"], loan_data["year"] = loan_data["issue_d"].str.split("-", 1).str</span></span><br><span class="line"><span class="comment"># months_list = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]</span></span><br><span class="line"><span class="comment"># years_list = ["2012", "2013", "2014", "2015", "2016", "2017", "2018"]</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_dict = loan_data.groupby(["month", "year"])["loan_amnt"].mean().to_dict()</span></span><br><span class="line"><span class="comment"># # print(loan_amnt_per_year_per_month_dict)</span></span><br><span class="line"><span class="comment"># max_value = max(mean_loan_amnt_per_year_per_month_dict.values())</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_list = []</span></span><br><span class="line"><span class="comment"># for key, value in mean_loan_amnt_per_year_per_month_dict.items():</span></span><br><span class="line"><span class="comment"># temp = [key[0], key[1], value]</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_list.append(temp)</span></span><br><span class="line"><span class="comment"># # print(loan_amnt_per_year_per_month_list)</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_bar3d = Bar3D("每月贷款金额3D柱状图", width=1500, height=1000)</span></span><br><span class="line"><span class="comment"># range_color = ["#313695", "#4575b4", "#74add1", "#abd9e9", "#e0f3f8", "#ffffbf", "#fee090", "#fdae61", "#f46d43",</span></span><br><span class="line"><span class="comment">#                "#d73027", "#a50026"]</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_bar3d.add("mean loan amnt per year per month bar3D", x_axis=months_list, y_axis=years_list,</span></span><br><span class="line"><span class="comment">#                                             data=mean_loan_amnt_per_year_per_month_list,</span></span><br><span class="line"><span class="comment">#                                             is_visualmap=True, visual_range=[0, max_value], visual_range_color=range_color,</span></span><br><span class="line"><span class="comment">#                                             grid3d_width=200, grid3d_height=100, grid3d_depth=80)</span></span><br><span class="line"><span class="comment"># # 3D图不能保存为png格式</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_bar3d.render(path="./pictures/mean loan amnt per year per month bar3D.html")</span></span><br><span class="line"><span class="comment"># months_to_num_dict = &#123;"Jan": 1, "Feb": 2, "Mar": 3, "Apr": 4, "May": 5, "Jun": 6, "Jul": 7, "Aug": 8, "Sep": 9,</span></span><br><span class="line"><span class="comment">#                       "Oct": 10, "Nov": 11, "Dec": 12&#125;</span></span><br><span class="line"><span class="comment"># for item in mean_loan_amnt_per_year_per_month_list:</span></span><br><span class="line"><span class="comment"># item[0], item[1] = months_to_num_dict[item[0]], int(item[1])</span></span><br><span class="line"><span class="comment"># # 画折线图时按照给定数据的输入顺序连线,所以我们要对列表先按月再按年从小到大排序</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_list.sort(key=lambda x: x[0])</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_list.sort(key=lambda x: x[1])</span></span><br><span class="line"><span class="comment"># colorscale = ["#9ecae1", "#85bcdb", "#6baed6", "#57a0ce", "#4292c6", "#3082be", "#2171b5", "#1361a9", "#08519c",</span></span><br><span class="line"><span class="comment">#               "#0b4083", "#08306b"]</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_line3d = Line3D("每月贷款金额变化3D折线图", width=1500, height=1000)</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_line3d.add("mean loan amnt per year per month line3D",</span></span><br><span class="line"><span class="comment">#                                              data=mean_loan_amnt_per_year_per_month_list,</span></span><br><span class="line"><span class="comment">#                                              yaxis3d_min=2012, yaxis3d_max=2018,</span></span><br><span class="line"><span class="comment">#                                              is_visualmap=True, visual_range=[0, max_value], visual_range_color=colorscale,</span></span><br><span class="line"><span class="comment">#                                              grid3d_width=200, grid3d_height=100, grid3d_depth=80)</span></span><br><span class="line"><span class="comment"># # 3D图不能保存为png格式</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_line3d.render(path="./pictures/mean loan amnt per year per month line3D.html")</span></span><br><span class="line"><span class="comment"># loan_data.drop(["month","year"], axis=1, inplace=True)</span></span><br><span class="line"><span class="comment"># print(loan_data.shape)</span></span><br></pre></td></tr></table></figure><h2 id="各年各月贷款笔数3D柱状图和3D折线图"><a href="#各年各月贷款笔数3D柱状图和3D折线图" class="headerlink" title="各年各月贷款笔数3D柱状图和3D折线图"></a>各年各月贷款笔数3D柱状图和3D折线图</h2><p>我们继续数据集先按年分组，再按月分组，然后统计2012-2018年各月的贷款笔数。可以发现自2015年起每月的贷款笔数比起2014年及以前猛然增加许多，另外2016年3月的贷款笔数远远高于其他月，推测是公司在该月有什么重大的举措导致。<br>我们再将上面的数据用3D折线图的形式画出。我们可以发现每月的放贷数量和月份有明显的相关性，比如每年的7月或8月和10月的放贷笔数较多。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 各年各月贷款笔数3D柱状图和3D折线图</span></span><br><span class="line"><span class="comment"># loan_data["month"], loan_data["year"] = loan_data["issue_d"].str.split("-", 1).str</span></span><br><span class="line"><span class="comment"># # print(loan_data["month"].value_counts())</span></span><br><span class="line"><span class="comment"># # print(loan_data["year"].value_counts())</span></span><br><span class="line"><span class="comment"># months_list = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]</span></span><br><span class="line"><span class="comment"># years_list = ["2012", "2013", "2014", "2015", "2016", "2017", "2018"]</span></span><br><span class="line"><span class="comment"># loan_times_per_year_num_dict = loan_data.groupby(["month"])["year"].value_counts().to_dict()</span></span><br><span class="line"><span class="comment"># max_value = max(loan_times_per_year_num_dict.values())</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_num_list = []</span></span><br><span class="line"><span class="comment"># for key, value in loan_times_per_year_num_dict.items():</span></span><br><span class="line"><span class="comment"># temp = [key[0], key[1], value]</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_num_list.append(temp)</span></span><br><span class="line"><span class="comment"># # print(loan_per_month_per_year_num_list)</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_bar3d = Bar3D("每月贷款笔数3D柱状图", width=1500, height=1000)</span></span><br><span class="line"><span class="comment"># range_color = ["#313695", "#4575b4", "#74add1", "#abd9e9", "#e0f3f8", "#ffffbf", "#fee090", "#fdae61", "#f46d43",</span></span><br><span class="line"><span class="comment">#                "#d73027", "#a50026"]</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_bar3d.add("loan times per month per year bar3D", x_axis=months_list, y_axis=years_list,</span></span><br><span class="line"><span class="comment">#                                         data=loan_times_per_month_per_year_num_list,</span></span><br><span class="line"><span class="comment">#                                         is_visualmap=True, visual_range=[0, max_value], visual_range_color=range_color,</span></span><br><span class="line"><span class="comment">#                                         grid3d_width=200, grid3d_height=100, grid3d_depth=80)</span></span><br><span class="line"><span class="comment"># # 3D图不能保存为png格式</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_bar3d.render(path="./pictures/loan times per month per year bar3D.html")</span></span><br><span class="line"><span class="comment"># months_to_num_dict = &#123;"Jan": 1, "Feb": 2, "Mar": 3, "Apr": 4, "May": 5, "Jun": 6, "Jul": 7, "Aug": 8, "Sep": 9,</span></span><br><span class="line"><span class="comment">#                       "Oct": 10, "Nov": 11, "Dec": 12&#125;</span></span><br><span class="line"><span class="comment"># for item in loan_times_per_month_per_year_num_list:</span></span><br><span class="line"><span class="comment"># item[0], item[1] = months_to_num_dict[item[0]], int(item[1])</span></span><br><span class="line"><span class="comment"># # 画折线图时按照给定数据的输入顺序连线,所以我们要对列表先按月再按年从小到大排序</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_num_list.sort(key=lambda x: x[0])</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_num_list.sort(key=lambda x: x[1])</span></span><br><span class="line"><span class="comment"># # print(loan_times_per_month_per_year_num_list)</span></span><br><span class="line"><span class="comment"># # loan_times_per_month_per_year_num_list=[[8, 2012, 894], [9, 2012, 5924], [10, 2012, 6192], [11, 2012, 6312], [12, 2012, 6006], [1, 2013, 6814], [2, 2013, 7506], [3, 2013, 8199], [4, 2013, 9354], [5, 2013, 10285], [6, 2013, 10815], [7, 2013, 11816], [8, 2013, 12562], [9, 2013, 12866], [10, 2013, 13858], [11, 2013, 14561], [12, 2013, 14854], [1, 2014, 15470], [2, 2014, 15111], [3, 2014, 16296], [4, 2014, 18829], [5, 2014, 18870], [6, 2014, 16996], [7, 2014, 28948], [8, 2014, 18632], [9, 2014, 10498], [10, 2014, 38244], [11, 2014, 24679], [12, 2014, 10173], [1, 2015, 34691], [2, 2015, 23474], [3, 2015, 25123], [4, 2015, 35052], [5, 2015, 31547], [6, 2015, 28170], [7, 2015, 45446], [8, 2015, 35469], [9, 2015, 28343], [10, 2015, 48064], [11, 2015, 37084], [12, 2015, 43702], [1, 2016, 29548], [2, 2016, 35778], [3, 2016, 56707], [4, 2016, 33093], [5, 2016, 25975], [6, 2016, 30512], [7, 2016, 32575], [8, 2016, 33488], [9, 2016, 26432], [10, 2016, 32318], [11, 2016, 34068], [12, 2016, 35618], [1, 2017, 31435], [2, 2017, 27418], [3, 2017, 36754], [4, 2017, 29270], [5, 2017, 37245], [6, 2017, 37548], [7, 2017, 38784], [8, 2017, 42765], [9, 2017, 38988], [10, 2017, 37434], [11, 2017, 41513], [12, 2017, 37376], [1, 2018, 35718], [2, 2018, 32126], [3, 2018, 38054], [4, 2018, 42177], [5, 2018, 45489], [6, 2018, 40821], [7, 2018, 42372], [8, 2018, 45298], [9, 2018, 38380], [10, 2018, 45540], [11, 2018, 41247], [12, 2018, 39480]]</span></span><br><span class="line"><span class="comment"># colorscale = ["#9ecae1", "#85bcdb", "#6baed6", "#57a0ce", "#4292c6", "#3082be", "#2171b5", "#1361a9", "#08519c",</span></span><br><span class="line"><span class="comment">#               "#0b4083", "#08306b"]</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_line3d = Line3D("每月贷款笔数变化3D折线图", width=1500, height=1000)</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_line3d.add("loan times per month per year line3D",</span></span><br><span class="line"><span class="comment">#                                          data=loan_times_per_month_per_year_num_list,</span></span><br><span class="line"><span class="comment">#                                          yaxis3d_min=2012, yaxis3d_max=2018,</span></span><br><span class="line"><span class="comment">#                                          is_visualmap=True, visual_range=[0, max_value], visual_range_color=colorscale,</span></span><br><span class="line"><span class="comment">#                                          grid3d_width=200, grid3d_height=100, grid3d_depth=80)</span></span><br><span class="line"><span class="comment"># # 3D图不能保存为png格式</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_line3d.render(path="./pictures/loan times per month per year line3D.html")</span></span><br><span class="line"><span class="comment"># loan_data.drop(["month","year"], axis=1, inplace=True)</span></span><br><span class="line"><span class="comment"># print(loan_data.shape)</span></span><br></pre></td></tr></table></figure><h2 id="各州贷款笔数地理坐标系图和直方图"><a href="#各州贷款笔数地理坐标系图和直方图" class="headerlink" title="各州贷款笔数地理坐标系图和直方图"></a>各州贷款笔数地理坐标系图和直方图</h2><p>该数据集中的贷款信息来自美国的各个州。特征addr_state表明了每笔贷款申请发生的地点(州)。我们以州为单位将数据集分组并统计每个州的贷款笔数，然后绘制各州贷款笔数的地理坐标系图。我们可以看到加州的贷款笔数是最多的（不愧是美国GDP最高的州）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># the map of geographical coordinates of each state"s loan figures</span></span><br><span class="line"><span class="comment"># addr_state即申请贷款的人的所属州,是两位代码,可以被plotly识别</span></span><br><span class="line">code_and_name_dict = &#123;<span class="string">"AL"</span>: <span class="string">"Alabama"</span>, <span class="string">"AK"</span>: <span class="string">"Alaska"</span>, <span class="string">"AZ"</span>: <span class="string">"Arizona"</span>, <span class="string">"AR"</span>: <span class="string">"Arkansas"</span>, <span class="string">"CA"</span>: <span class="string">"California"</span>,</span><br><span class="line">                      <span class="string">"CO"</span>: <span class="string">"Colorado"</span>, <span class="string">"CT"</span>: <span class="string">"Connecticut"</span>, <span class="string">"DC"</span>: <span class="string">"District of Columbia"</span>, <span class="string">"DE"</span>: <span class="string">"Delaware"</span>,</span><br><span class="line">                      <span class="string">"FL"</span>: <span class="string">"Florida"</span>, <span class="string">"GA"</span>: <span class="string">"Georgia"</span>, <span class="string">"HI"</span>: <span class="string">"Hawaii"</span>, <span class="string">"ID"</span>: <span class="string">"Idaho"</span>, <span class="string">"IL"</span>: <span class="string">"Illinois"</span>,</span><br><span class="line">                      <span class="string">"IN"</span>: <span class="string">"Indiana"</span>, <span class="string">"IA"</span>: <span class="string">"Iowa"</span>, <span class="string">"KS"</span>: <span class="string">"Kansas"</span>, <span class="string">"KY"</span>: <span class="string">"Kentucky"</span>, <span class="string">"LA"</span>: <span class="string">"Louisiana"</span>, <span class="string">"ME"</span>: <span class="string">"Maine"</span>,</span><br><span class="line">                      <span class="string">"MD"</span>: <span class="string">"Maryland"</span>, <span class="string">"MA"</span>: <span class="string">"Massachusetts"</span>, <span class="string">"MI"</span>: <span class="string">"Michigan"</span>, <span class="string">"MN"</span>: <span class="string">"Minnesota"</span>, <span class="string">"MS"</span>: <span class="string">"Mississippi"</span>,</span><br><span class="line">                      <span class="string">"MO"</span>: <span class="string">"Missouri"</span>, <span class="string">"MT"</span>: <span class="string">"Montana"</span>, <span class="string">"NE"</span>: <span class="string">"Nebraska"</span>, <span class="string">"NV"</span>: <span class="string">"Nevada"</span>, <span class="string">"NH"</span>: <span class="string">"New Hampshire"</span>,</span><br><span class="line">                      <span class="string">"NJ"</span>: <span class="string">"New Jersey"</span>, <span class="string">"NM"</span>: <span class="string">"New Mexico"</span>, <span class="string">"NY"</span>: <span class="string">"New York"</span>, <span class="string">"NC"</span>: <span class="string">"North Carolina"</span>,</span><br><span class="line">                      <span class="string">"ND"</span>: <span class="string">"North Dakota"</span>, <span class="string">"OH"</span>: <span class="string">"Ohio"</span>, <span class="string">"OK"</span>: <span class="string">"Oklahoma"</span>, <span class="string">"OR"</span>: <span class="string">"Oregon"</span>, <span class="string">"PA"</span>: <span class="string">"Pennsylvania"</span>,</span><br><span class="line">                      <span class="string">"RI"</span>: <span class="string">"Rhode Island"</span>, <span class="string">"SC"</span>: <span class="string">"South Carolina"</span>, <span class="string">"SD"</span>: <span class="string">"South Dakota"</span>, <span class="string">"TN"</span>: <span class="string">"Tennessee"</span>,</span><br><span class="line">                      <span class="string">"TX"</span>: <span class="string">"Texas"</span>, <span class="string">"UT"</span>: <span class="string">"Utah"</span>, <span class="string">"VT"</span>: <span class="string">"Vermont"</span>, <span class="string">"VA"</span>: <span class="string">"Virginia"</span>, <span class="string">"WA"</span>: <span class="string">"Washington"</span>,</span><br><span class="line">                      <span class="string">"WV"</span>: <span class="string">"West Virginia"</span>, <span class="string">"WI"</span>: <span class="string">"Wisconsin"</span>, <span class="string">"WY"</span>: <span class="string">"Wyoming"</span>&#125;</span><br><span class="line">loan_times_per_state = loan_data[<span class="string">"addr_state"</span>].value_counts().to_dict()</span><br><span class="line">loan_times_per_state_pd = pd.DataFrame(list(loan_times_per_state.items()), columns=[<span class="string">"state_code"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line">loan_times_per_state_pd[<span class="string">"state_name"</span>] = <span class="literal">None</span></span><br><span class="line"><span class="comment"># print(loan_times_per_state_pd)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(loan_times_per_state_pd.shape[<span class="number">0</span>]):</span><br><span class="line">state_name = code_and_name_dict[loan_times_per_state_pd.ix[i, <span class="string">"state_code"</span>]]</span><br><span class="line">loan_times_per_state_pd.ix[i, <span class="string">"state_name"</span>] = state_name</span><br><span class="line"><span class="comment"># print(loan_times_per_state_pd)</span></span><br><span class="line"><span class="comment"># 设立颜色条色彩渐变颜色</span></span><br><span class="line"><span class="comment"># colorscale可选项:["Greys", "YlGnBu", "Greens", "YlOrRd", "Bluered", "RdBu","Reds", "Blues", "Picnic", "Rainbow",</span></span><br><span class="line"><span class="comment"># "Portland", "Jet","Hot", "Blackbody", "Earth", "Electric", "Viridis", "Cividis"]</span></span><br><span class="line">colorscale = <span class="string">"Blues"</span></span><br><span class="line"><span class="comment"># colorbar为颜色条注释,位置由各州的编号，即缩写表示,z值越高颜色越深</span></span><br><span class="line">data = [dict(type=<span class="string">"choropleth"</span>, colorscale=colorscale, autocolorscale=<span class="literal">False</span>, reversescale=<span class="literal">True</span>,</span><br><span class="line">             locations=loan_times_per_state_pd[<span class="string">"state_code"</span>], z=loan_times_per_state_pd[<span class="string">"loan_times"</span>].astype(float),</span><br><span class="line">             locationmode=<span class="string">"USA-states"</span>, text=loan_times_per_state_pd[<span class="string">"state_name"</span>],</span><br><span class="line">             marker=dict(line=dict(color=<span class="string">"rgb(255,255,255)"</span>, width=<span class="number">2</span>)),</span><br><span class="line">             colorbar=dict(title=<span class="string">"loan times"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">32</span>)))]</span><br><span class="line">layout = dict(title=<span class="string">"loan times per state map"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">50</span>),</span><br><span class="line">              geo=dict(scope=<span class="string">"usa"</span>, projection=dict(type=<span class="string">"albers usa"</span>)))</span><br><span class="line">fig = dict(data=data, layout=layout)</span><br><span class="line"><span class="comment"># filename为网站上个人空间中保存的文件名</span></span><br><span class="line">py.plot(fig, filename=<span class="string">"loan times per state map"</span>, auto_open=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># filename为本地保存的文件名,plotly本地保存只支持png,svg,jpeg,pdf</span></span><br><span class="line">py.image.save_as(fig, filename=<span class="string">"./pictures/loan times per state map.png"</span>, width=<span class="number">2500</span>, height=<span class="number">1500</span>)</span><br></pre></td></tr></table></figure><p>我们再画出贷款笔数前30名的州。前四名依次为California、Texas、NewYork、Florida。其中California的贷款笔数远远高于其他州。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Histogram of each state"s loan figures (the top 30 states with the largest number of loans)</span></span><br><span class="line">code_and_name_dict = &#123;<span class="string">"AL"</span>: <span class="string">"Alabama"</span>, <span class="string">"AK"</span>: <span class="string">"Alaska"</span>, <span class="string">"AZ"</span>: <span class="string">"Arizona"</span>, <span class="string">"AR"</span>: <span class="string">"Arkansas"</span>, <span class="string">"CA"</span>: <span class="string">"California"</span>,</span><br><span class="line">                      <span class="string">"CO"</span>: <span class="string">"Colorado"</span>, <span class="string">"CT"</span>: <span class="string">"Connecticut"</span>, <span class="string">"DC"</span>: <span class="string">"District of Columbia"</span>, <span class="string">"DE"</span>: <span class="string">"Delaware"</span>,</span><br><span class="line">                      <span class="string">"FL"</span>: <span class="string">"Florida"</span>, <span class="string">"GA"</span>: <span class="string">"Georgia"</span>, <span class="string">"HI"</span>: <span class="string">"Hawaii"</span>, <span class="string">"ID"</span>: <span class="string">"Idaho"</span>, <span class="string">"IL"</span>: <span class="string">"Illinois"</span>,</span><br><span class="line">                      <span class="string">"IN"</span>: <span class="string">"Indiana"</span>, <span class="string">"IA"</span>: <span class="string">"Iowa"</span>, <span class="string">"KS"</span>: <span class="string">"Kansas"</span>, <span class="string">"KY"</span>: <span class="string">"Kentucky"</span>, <span class="string">"LA"</span>: <span class="string">"Louisiana"</span>, <span class="string">"ME"</span>: <span class="string">"Maine"</span>,</span><br><span class="line">                      <span class="string">"MD"</span>: <span class="string">"Maryland"</span>, <span class="string">"MA"</span>: <span class="string">"Massachusetts"</span>, <span class="string">"MI"</span>: <span class="string">"Michigan"</span>, <span class="string">"MN"</span>: <span class="string">"Minnesota"</span>, <span class="string">"MS"</span>: <span class="string">"Mississippi"</span>,</span><br><span class="line">                      <span class="string">"MO"</span>: <span class="string">"Missouri"</span>, <span class="string">"MT"</span>: <span class="string">"Montana"</span>, <span class="string">"NE"</span>: <span class="string">"Nebraska"</span>, <span class="string">"NV"</span>: <span class="string">"Nevada"</span>, <span class="string">"NH"</span>: <span class="string">"New Hampshire"</span>,</span><br><span class="line">                      <span class="string">"NJ"</span>: <span class="string">"New Jersey"</span>, <span class="string">"NM"</span>: <span class="string">"New Mexico"</span>, <span class="string">"NY"</span>: <span class="string">"New York"</span>, <span class="string">"NC"</span>: <span class="string">"North Carolina"</span>,</span><br><span class="line">                      <span class="string">"ND"</span>: <span class="string">"North Dakota"</span>, <span class="string">"OH"</span>: <span class="string">"Ohio"</span>, <span class="string">"OK"</span>: <span class="string">"Oklahoma"</span>, <span class="string">"OR"</span>: <span class="string">"Oregon"</span>, <span class="string">"PA"</span>: <span class="string">"Pennsylvania"</span>,</span><br><span class="line">                      <span class="string">"RI"</span>: <span class="string">"Rhode Island"</span>, <span class="string">"SC"</span>: <span class="string">"South Carolina"</span>, <span class="string">"SD"</span>: <span class="string">"South Dakota"</span>, <span class="string">"TN"</span>: <span class="string">"Tennessee"</span>,</span><br><span class="line">                      <span class="string">"TX"</span>: <span class="string">"Texas"</span>, <span class="string">"UT"</span>: <span class="string">"Utah"</span>, <span class="string">"VT"</span>: <span class="string">"Vermont"</span>, <span class="string">"VA"</span>: <span class="string">"Virginia"</span>, <span class="string">"WA"</span>: <span class="string">"Washington"</span>,</span><br><span class="line">                      <span class="string">"WV"</span>: <span class="string">"West Virginia"</span>, <span class="string">"WI"</span>: <span class="string">"Wisconsin"</span>, <span class="string">"WY"</span>: <span class="string">"Wyoming"</span>&#125;</span><br><span class="line">loan_times = loan_data[<span class="string">"addr_state"</span>].value_counts().to_dict()</span><br><span class="line">loan_times_pd = pd.DataFrame(list(loan_times.items()), columns=[<span class="string">"state_code"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line">loan_times_pd[<span class="string">"state_name"</span>] = <span class="literal">None</span></span><br><span class="line"><span class="comment"># print(loan_times_pd)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(loan_times_pd.shape[<span class="number">0</span>]):</span><br><span class="line">state_name = code_and_name_dict[loan_times_pd.ix[i, <span class="string">"state_code"</span>]]</span><br><span class="line">loan_times_pd.ix[i, <span class="string">"state_name"</span>] = state_name</span><br><span class="line"><span class="comment"># print(loan_times_pd)</span></span><br><span class="line">loan_times_pd_30 = loan_times_pd[<span class="number">0</span>:<span class="number">30</span>]</span><br><span class="line">loan_times_pd_30.drop([<span class="string">"state_code"</span>], axis=<span class="number">1</span>)</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan_times_per_state, ax_loan_times_per_state = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># # palette为调色板参数,可选项"muted"\"RdBu"\"RdBu_r"\"Blues_d"\"Set1"\"husl"</span></span><br><span class="line">sns.barplot(loan_times_pd_30[<span class="string">"loan_times"</span>], loan_times_pd_30[<span class="string">"state_name"</span>], ax=ax_loan_times_per_state,</span><br><span class="line">            palette=<span class="string">"tab10"</span>)</span><br><span class="line">ax_loan_times_per_state.set_title(<span class="string">"loan times per state"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_state.set_xlabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_state.set_ylabel(<span class="string">"state name"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_loan_times_per_state.savefig(<span class="string">"./pictures/loan times per state bar.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="贷款次数最多的前30种职业直方图"><a href="#贷款次数最多的前30种职业直方图" class="headerlink" title="贷款次数最多的前30种职业直方图"></a>贷款次数最多的前30种职业直方图</h2><p>特征emp_title为申请贷款时贷款人的职业，我们按该特征分组数据集，计算每个职业的贷款笔数，看看申请贷款最多的职业是哪几个。我们发现教师和经理人的申请贷款次数是最多的，远远超出其他职业。<br>我们注意到这个特征是个类别型特征，但特征的取值非常多，且每个取值的出现次数相对于总样本量很小，因此这个特征如果变为one_hot编码后其每一列one_hot编码特征的方差都会很小，这对于模型的预测不利。因此在后面模型预测前的预处理时我们删除了该特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># histogram of the top 30 profession of loan figures</span></span><br><span class="line">loan_times_title = loan_data[<span class="string">"emp_title"</span>].value_counts().to_dict()</span><br><span class="line">loan_times_title_pd = pd.DataFrame(list(loan_times_title.items()), columns=[<span class="string">"title"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line">loan_times_title_pd_30 = loan_times_title_pd[<span class="number">0</span>:<span class="number">30</span>]</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan_times_per_title, ax_loan_times_per_title = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># # palette为调色板参数,可选项"muted"\"RdBu"\"RdBu_r"\"Blues_d"\"Set1"\"husl"</span></span><br><span class="line">sns.barplot(loan_times_title_pd_30[<span class="string">"loan_times"</span>], loan_times_title_pd_30[<span class="string">"title"</span>], ax=ax_loan_times_per_title,</span><br><span class="line">            palette=<span class="string">"tab10"</span>)</span><br><span class="line">ax_loan_times_per_title.set_title(<span class="string">"loan times per title"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_title.set_xlabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_title.set_ylabel(<span class="string">"title"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_loan_times_per_title.savefig(<span class="string">"./pictures/loan times per title bar.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="工作年限与贷款笔数的直方图"><a href="#工作年限与贷款笔数的直方图" class="headerlink" title="工作年限与贷款笔数的直方图"></a>工作年限与贷款笔数的直方图</h2><p>特征emp_length为贷款申请人的工作年限。我们将数据集按工作年限进行分组，统计每个工作年限的贷款笔数。我们可以发现工作10年以上的人申请贷款数目远远超过其他年限。<br>​    要注意的一点是，该特征虽然是类别型特征的形式，但是其内容却是典型的数值，因此后面模型预测前我们要将其转化为数值型特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># histogram of the year of participation in working with loan figures</span></span><br><span class="line">loan_times_length = loan_data[<span class="string">"emp_length"</span>].value_counts().to_dict()</span><br><span class="line"><span class="comment"># print(loan_times_length)</span></span><br><span class="line"><span class="comment"># &#123;"10+ years": 713245, "2 years": 192330, "&lt; 1 year": 179177, "3 years": 170699, "1 year": 139017, "5 years": 130985,</span></span><br><span class="line"><span class="comment"># "4 years": 128027, "6 years": 96294, "7 years": 87537, "8 years": 87182, "9 years": 75405&#125;</span></span><br><span class="line">loan_times_length_pd = pd.DataFrame(list(loan_times_length.items()), columns=[<span class="string">"length"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan_times_per_length, ax_loan_times_per_length = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># palette为调色板参数,可选项"muted"\"RdBu"\"RdBu_r"\"Blues_d"\"Set1"\"husl"</span></span><br><span class="line">sns.barplot(loan_times_length_pd[<span class="string">"length"</span>], loan_times_length_pd[<span class="string">"loan_times"</span>], ax=ax_loan_times_per_length,</span><br><span class="line">            palette=<span class="string">"Blues_d"</span>)</span><br><span class="line">ax_loan_times_per_length.set_title(<span class="string">"loan times per length"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_length.set_xlabel(<span class="string">"worked length"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_length.set_ylabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_loan_times_per_length.savefig(<span class="string">"./pictures/loan times per length bar.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="用户年收入与贷款笔数直方图"><a href="#用户年收入与贷款笔数直方图" class="headerlink" title="用户年收入与贷款笔数直方图"></a>用户年收入与贷款笔数直方图</h2><p>特征annual_inc为申请人的年收入。这是一个数值型特征。我们将收入分成三档:20000以下为low，20000-60000为mid，&gt;60000为high。按照这三档将该数值型特征变为类别型特征，然后将数据集按该特征分组，计算每组的贷款笔数。我们发现年收入为low的人贷款笔数远远小于另外两档，推测是因为银行的审核贷款机制判定大部分年收入为low的人没有能力偿还贷款，因此不批贷款导致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># histogram of the customer"s annual income with loan figures</span></span><br><span class="line"><span class="comment"># 我们将年收入分为三档:20000以下为low，20000-60000为mid，&gt;60000为high</span></span><br><span class="line">max_value = loan_data[<span class="string">"annual_inc"</span>].max() + <span class="number">1.0</span></span><br><span class="line">set_bins = [<span class="number">0.0</span>, <span class="number">20000.0</span>, <span class="number">60000.0</span>, max_value]</span><br><span class="line">set_label = [<span class="string">"low"</span>, <span class="string">"mid"</span>, <span class="string">"high"</span>]</span><br><span class="line">loan_data[<span class="string">"income"</span>] = pd.cut(loan_data[<span class="string">"annual_inc"</span>], bins=set_bins, labels=set_label)</span><br><span class="line">loan_times_income = loan_data[<span class="string">"income"</span>].value_counts().to_dict()</span><br><span class="line"><span class="comment"># print(loan_times_income)</span></span><br><span class="line"><span class="comment"># &#123;"high": 1187055, "mid": 912572, "low": 37443&#125;</span></span><br><span class="line">loan_times_income_pd = pd.DataFrame(list(loan_times_income.items()), columns=[<span class="string">"income"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan_times_per_income, ax_loan_times_per_income = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># palette为调色板参数,可选项"muted"\"RdBu"\"RdBu_r"\"Blues_d"\"Set1"\"husl"</span></span><br><span class="line">sns.barplot(loan_times_income_pd[<span class="string">"income"</span>], loan_times_income_pd[<span class="string">"loan_times"</span>], ax=ax_loan_times_per_income,</span><br><span class="line">            palette=<span class="string">"muted"</span>)</span><br><span class="line">ax_loan_times_per_income.set_title(<span class="string">"loan times per income"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_income.set_xlabel(<span class="string">"income"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_income.set_ylabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"income"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line">f_loan_times_per_income.savefig(<span class="string">"./pictures/loan times per income bar.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="优质贷款与不良贷款的比例"><a href="#优质贷款与不良贷款的比例" class="headerlink" title="优质贷款与不良贷款的比例"></a>优质贷款与不良贷款的比例</h2><p>特征loan_status为贷款状态，我们用1表示贷款状况良好，用0表示不良贷款，则各种情况如下:<br>loan_status_dict = {‘Fully Paid’: 1, ‘Current’: 1, ‘Charged Off’: 0, ‘Late (31-120 days)’: 0,’In Grace Period’: 0, ‘Late (16-30 days)’: 0, ‘Default’: 0}<br>按照上面的映射规则处理特征loan_status，这样我们就可以确定一个贷款是优质贷款还是不良贷款。画出总的优质贷款和不良贷款的饼状比例图。然后再按年分组，画出每年优质贷款和不良贷款占总贷款笔数的比例。<br>从右侧每年优质贷款和不良贷款比例的直方图中我们可以看出自2016年以后放贷笔数持续增长，但不良贷款的数量却明显下降了，这说明公司的风控部门的工作卓有成效。<br>另外，我们可以发现这个数据集的正负样本不平衡情况很严重，在进行模型拟合和预测时要进行特殊处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The ratio of good loans and bad loans for each year</span></span><br><span class="line"><span class="comment"># print(loan_data["loan_status"].value_counts().to_dict())</span></span><br><span class="line"><span class="comment"># &#123;"Fully Paid": 962556, "Current": 899615, "Charged Off": 241514, "Late (31-120 days)": 21051, "In Grace Period": 8701,</span></span><br><span class="line"><span class="comment"># "Late (16-30 days)": 3607, "Default": 29&#125;</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line"><span class="comment"># 用1表示贷款状况良好，用0表示不良贷款</span></span><br><span class="line">loan_data[<span class="string">"loan_status_count"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count"</span>] = loan_data[<span class="string">"loan_status_count"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line"><span class="comment"># print(loan_data["loan_status"].value_counts().to_dict())</span></span><br><span class="line"><span class="comment"># &#123;1.0: 1862171, 0.0: 274902&#125;可以看到正负样本不均衡，在后面我们训练模型预测loan_status时需要注意正负样本不平衡的问题</span></span><br><span class="line">loan_status_count = loan_data[<span class="string">"loan_status_count"</span>].value_counts().to_dict()</span><br><span class="line"><span class="keyword">if</span> <span class="number">0</span> <span class="keyword">not</span> <span class="keyword">in</span> loan_status_count.keys():</span><br><span class="line">loan_status_count[<span class="string">"0"</span>] = <span class="number">0.0</span></span><br><span class="line">count_sum = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> loan_status_count.items():</span><br><span class="line">count_sum += value</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> loan_status_count.items():</span><br><span class="line">value = value / count_sum</span><br><span class="line">loan_status_count[key] = value</span><br><span class="line">loan_status_count_pd = pd.DataFrame(list(loan_status_count.items()), columns=[<span class="string">"loan status"</span>, <span class="string">"count_percent"</span>])</span><br><span class="line"><span class="comment"># print(loan_status_count_pd)</span></span><br><span class="line"><span class="comment">#    loan status  count_percent</span></span><br><span class="line"><span class="comment"># 0          1.0       0.871365</span></span><br><span class="line"><span class="comment"># 1          0.0       0.128635</span></span><br><span class="line">loan_data[<span class="string">"year"</span>] = pd.to_datetime(loan_data[<span class="string">"issue_d"</span>]).dt.year</span><br><span class="line">f_loan_status, ax_loan_status = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">ax_loan_status[<span class="number">0</span>].pie(loan_status_count_pd[<span class="string">"count_percent"</span>], autopct=<span class="string">"%1.2f%%"</span>, shadow=<span class="literal">True</span>,</span><br><span class="line">                      labels=labels, startangle=<span class="number">70</span>)</span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count"</span>] = loan_data[<span class="string">"loan_status_count"</span>].map(loan_status_dict)</span><br><span class="line">sns.barplot(x=loan_data[<span class="string">"year"</span>], y=loan_data[<span class="string">"loan_amnt"</span>], hue=loan_data[<span class="string">"loan_status_count"</span>], hue_order=labels,</span><br><span class="line">            ax=ax_loan_status[<span class="number">1</span>], estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data[<span class="string">"loan_status_count"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status[<span class="number">0</span>].set_title(<span class="string">"good loans and bad loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status[<span class="number">0</span>].set_ylabel(<span class="string">"Loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status[<span class="number">1</span>].set_title(<span class="string">"good loans and bad loans percent per year"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status[<span class="number">1</span>].set_ylabel(<span class="string">"Loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count"</span>, <span class="string">"year"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line">f_loan_status.savefig(<span class="string">"./pictures/good loans and bad loans percent per year.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                      bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="各州不良贷款笔数-比例的地理坐标系图"><a href="#各州不良贷款笔数-比例的地理坐标系图" class="headerlink" title="各州不良贷款笔数/比例的地理坐标系图"></a>各州不良贷款笔数/比例的地理坐标系图</h2><p>我们按州为单位统计每个州的不良贷款笔数，并用颜色的深浅来区别。可以看到加州的不良贷款数远远高于其他州，但结合之前的各州总贷款笔数直方图，这可能是由于加州的放贷笔数最多的原因。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># the map of geographical coordinates of each state"s good loan number and bad loan number</span></span><br><span class="line">code_and_name_dict = &#123;<span class="string">"AL"</span>: <span class="string">"Alabama"</span>, <span class="string">"AK"</span>: <span class="string">"Alaska"</span>, <span class="string">"AZ"</span>: <span class="string">"Arizona"</span>, <span class="string">"AR"</span>: <span class="string">"Arkansas"</span>, <span class="string">"CA"</span>: <span class="string">"California"</span>,</span><br><span class="line">                      <span class="string">"CO"</span>: <span class="string">"Colorado"</span>, <span class="string">"CT"</span>: <span class="string">"Connecticut"</span>, <span class="string">"DC"</span>: <span class="string">"District of Columbia"</span>, <span class="string">"DE"</span>: <span class="string">"Delaware"</span>,</span><br><span class="line">                      <span class="string">"FL"</span>: <span class="string">"Florida"</span>, <span class="string">"GA"</span>: <span class="string">"Georgia"</span>, <span class="string">"HI"</span>: <span class="string">"Hawaii"</span>, <span class="string">"ID"</span>: <span class="string">"Idaho"</span>, <span class="string">"IL"</span>: <span class="string">"Illinois"</span>,</span><br><span class="line">                      <span class="string">"IN"</span>: <span class="string">"Indiana"</span>, <span class="string">"IA"</span>: <span class="string">"Iowa"</span>, <span class="string">"KS"</span>: <span class="string">"Kansas"</span>, <span class="string">"KY"</span>: <span class="string">"Kentucky"</span>, <span class="string">"LA"</span>: <span class="string">"Louisiana"</span>, <span class="string">"ME"</span>: <span class="string">"Maine"</span>,</span><br><span class="line">                      <span class="string">"MD"</span>: <span class="string">"Maryland"</span>, <span class="string">"MA"</span>: <span class="string">"Massachusetts"</span>, <span class="string">"MI"</span>: <span class="string">"Michigan"</span>, <span class="string">"MN"</span>: <span class="string">"Minnesota"</span>, <span class="string">"MS"</span>: <span class="string">"Mississippi"</span>,</span><br><span class="line">                      <span class="string">"MO"</span>: <span class="string">"Missouri"</span>, <span class="string">"MT"</span>: <span class="string">"Montana"</span>, <span class="string">"NE"</span>: <span class="string">"Nebraska"</span>, <span class="string">"NV"</span>: <span class="string">"Nevada"</span>, <span class="string">"NH"</span>: <span class="string">"New Hampshire"</span>,</span><br><span class="line">                      <span class="string">"NJ"</span>: <span class="string">"New Jersey"</span>, <span class="string">"NM"</span>: <span class="string">"New Mexico"</span>, <span class="string">"NY"</span>: <span class="string">"New York"</span>, <span class="string">"NC"</span>: <span class="string">"North Carolina"</span>,</span><br><span class="line">                      <span class="string">"ND"</span>: <span class="string">"North Dakota"</span>, <span class="string">"OH"</span>: <span class="string">"Ohio"</span>, <span class="string">"OK"</span>: <span class="string">"Oklahoma"</span>, <span class="string">"OR"</span>: <span class="string">"Oregon"</span>, <span class="string">"PA"</span>: <span class="string">"Pennsylvania"</span>,</span><br><span class="line">                      <span class="string">"RI"</span>: <span class="string">"Rhode Island"</span>, <span class="string">"SC"</span>: <span class="string">"South Carolina"</span>, <span class="string">"SD"</span>: <span class="string">"South Dakota"</span>, <span class="string">"TN"</span>: <span class="string">"Tennessee"</span>,</span><br><span class="line">                      <span class="string">"TX"</span>: <span class="string">"Texas"</span>, <span class="string">"UT"</span>: <span class="string">"Utah"</span>, <span class="string">"VT"</span>: <span class="string">"Vermont"</span>, <span class="string">"VA"</span>: <span class="string">"Virginia"</span>, <span class="string">"WA"</span>: <span class="string">"Washington"</span>,</span><br><span class="line">                      <span class="string">"WV"</span>: <span class="string">"West Virginia"</span>, <span class="string">"WI"</span>: <span class="string">"Wisconsin"</span>, <span class="string">"WY"</span>: <span class="string">"Wyoming"</span>&#125;</span><br><span class="line"><span class="comment"># 为了便于计算坏账数,我们令坏账为1,好帐为0</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">0</span>, <span class="string">"Current"</span>: <span class="number">0</span>, <span class="string">"Charged Off"</span>: <span class="number">1</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">1</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">1</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">1</span>, <span class="string">"Default"</span>: <span class="number">1</span>&#125;</span><br><span class="line"><span class="comment"># 用1表示贷款状况良好，用0表示不良贷款</span></span><br><span class="line">loan_data[<span class="string">"loan_status_count_2"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_2"</span>] = loan_data[<span class="string">"loan_status_count_2"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line"><span class="comment"># print(loan_data["loan_status_count"].value_counts().to_dict())</span></span><br><span class="line"><span class="comment"># &#123;0.0: 1862171, 1.0: 274902&#125;</span></span><br><span class="line">loan_status_per_state = loan_data.groupby(<span class="string">"addr_state"</span>)[<span class="string">"loan_status_count_2"</span>].sum().to_dict()</span><br><span class="line"><span class="comment"># print(loan_status_per_state)</span></span><br><span class="line">loan_status_per_state_pd = pd.DataFrame(list(loan_status_per_state.items()),</span><br><span class="line">                                        columns=[<span class="string">"state_code"</span>, <span class="string">"bad_loan_num"</span>])</span><br><span class="line">loan_status_per_state_pd[<span class="string">"state_name"</span>] = <span class="literal">None</span></span><br><span class="line"><span class="comment"># print(loan_status_per_state_pd)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(loan_status_per_state_pd.shape[<span class="number">0</span>]):</span><br><span class="line">state_name = code_and_name_dict[loan_status_per_state_pd.ix[i, <span class="string">"state_code"</span>]]</span><br><span class="line">loan_status_per_state_pd.ix[i, <span class="string">"state_name"</span>] = state_name</span><br><span class="line"><span class="comment"># print(loan_status_per_state_pd)</span></span><br><span class="line"><span class="comment"># 设立颜色条色彩渐变颜色</span></span><br><span class="line"><span class="comment"># colorscale可选项:["Greys", "YlGnBu", "Greens", "YlOrRd", "Bluered", "RdBu","Reds", "Blues", "Picnic", "Rainbow",</span></span><br><span class="line"><span class="comment"># "Portland", "Jet","Hot", "Blackbody", "Earth", "Electric", "Viridis", "Cividis"]</span></span><br><span class="line">colorscale = <span class="string">"Hot"</span></span><br><span class="line"><span class="comment"># colorbar为颜色条注释,位置由各州的编号，即缩写表示,z值越高颜色越深</span></span><br><span class="line">data = [dict(type=<span class="string">"choropleth"</span>, colorscale=colorscale, autocolorscale=<span class="literal">False</span>, reversescale=<span class="literal">True</span>,</span><br><span class="line">             locations=loan_status_per_state_pd[<span class="string">"state_code"</span>], z=loan_status_per_state_pd[<span class="string">"bad_loan_num"</span>],</span><br><span class="line">             locationmode=<span class="string">"USA-states"</span>, text=loan_status_per_state_pd[<span class="string">"state_name"</span>],</span><br><span class="line">             marker=dict(line=dict(color=<span class="string">"rgb(255,255,255)"</span>, width=<span class="number">2</span>)),</span><br><span class="line">             colorbar=dict(title=<span class="string">"bad loans num"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">32</span>)))]</span><br><span class="line">layout = dict(title=<span class="string">"bad loans num per state map"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">50</span>),</span><br><span class="line">              geo=dict(scope=<span class="string">"usa"</span>, projection=dict(type=<span class="string">"albers usa"</span>)))</span><br><span class="line">fig = dict(data=data, layout=layout)</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_2"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment"># filename为网站上个人空间中保存的文件名</span></span><br><span class="line">py.plot(fig, filename=<span class="string">"bad loans num per state map"</span>, auto_open=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># filename为本地保存的文件名,plotly本地保存只支持png,svg,jpeg,pdf</span></span><br><span class="line">py.image.save_as(fig, filename=<span class="string">"./pictures/bad loans num per state map.png"</span>, width=<span class="number">2500</span>, height=<span class="number">1500</span>)</span><br></pre></td></tr></table></figure><p>继续计算每个州的不良贷款占各州总贷款笔数的比例。可以发现前面的推断是正确的，各州之间不良贷款比例的差距并不大。注意有一个州大概是数据特别少或者数据缺失，不良贷款比例接近0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># the map of geographical coordinates of each state"s good loan ratio and bad loan ratio</span></span><br><span class="line">code_and_name_dict = &#123;<span class="string">"AL"</span>: <span class="string">"Alabama"</span>, <span class="string">"AK"</span>: <span class="string">"Alaska"</span>, <span class="string">"AZ"</span>: <span class="string">"Arizona"</span>, <span class="string">"AR"</span>: <span class="string">"Arkansas"</span>, <span class="string">"CA"</span>: <span class="string">"California"</span>,</span><br><span class="line">                      <span class="string">"CO"</span>: <span class="string">"Colorado"</span>, <span class="string">"CT"</span>: <span class="string">"Connecticut"</span>, <span class="string">"DC"</span>: <span class="string">"District of Columbia"</span>, <span class="string">"DE"</span>: <span class="string">"Delaware"</span>,</span><br><span class="line">                      <span class="string">"FL"</span>: <span class="string">"Florida"</span>, <span class="string">"GA"</span>: <span class="string">"Georgia"</span>, <span class="string">"HI"</span>: <span class="string">"Hawaii"</span>, <span class="string">"ID"</span>: <span class="string">"Idaho"</span>, <span class="string">"IL"</span>: <span class="string">"Illinois"</span>,</span><br><span class="line">                      <span class="string">"IN"</span>: <span class="string">"Indiana"</span>, <span class="string">"IA"</span>: <span class="string">"Iowa"</span>, <span class="string">"KS"</span>: <span class="string">"Kansas"</span>, <span class="string">"KY"</span>: <span class="string">"Kentucky"</span>, <span class="string">"LA"</span>: <span class="string">"Louisiana"</span>, <span class="string">"ME"</span>: <span class="string">"Maine"</span>,</span><br><span class="line">                      <span class="string">"MD"</span>: <span class="string">"Maryland"</span>, <span class="string">"MA"</span>: <span class="string">"Massachusetts"</span>, <span class="string">"MI"</span>: <span class="string">"Michigan"</span>, <span class="string">"MN"</span>: <span class="string">"Minnesota"</span>, <span class="string">"MS"</span>: <span class="string">"Mississippi"</span>,</span><br><span class="line">                      <span class="string">"MO"</span>: <span class="string">"Missouri"</span>, <span class="string">"MT"</span>: <span class="string">"Montana"</span>, <span class="string">"NE"</span>: <span class="string">"Nebraska"</span>, <span class="string">"NV"</span>: <span class="string">"Nevada"</span>, <span class="string">"NH"</span>: <span class="string">"New Hampshire"</span>,</span><br><span class="line">                      <span class="string">"NJ"</span>: <span class="string">"New Jersey"</span>, <span class="string">"NM"</span>: <span class="string">"New Mexico"</span>, <span class="string">"NY"</span>: <span class="string">"New York"</span>, <span class="string">"NC"</span>: <span class="string">"North Carolina"</span>,</span><br><span class="line">                      <span class="string">"ND"</span>: <span class="string">"North Dakota"</span>, <span class="string">"OH"</span>: <span class="string">"Ohio"</span>, <span class="string">"OK"</span>: <span class="string">"Oklahoma"</span>, <span class="string">"OR"</span>: <span class="string">"Oregon"</span>, <span class="string">"PA"</span>: <span class="string">"Pennsylvania"</span>,</span><br><span class="line">                      <span class="string">"RI"</span>: <span class="string">"Rhode Island"</span>, <span class="string">"SC"</span>: <span class="string">"South Carolina"</span>, <span class="string">"SD"</span>: <span class="string">"South Dakota"</span>, <span class="string">"TN"</span>: <span class="string">"Tennessee"</span>,</span><br><span class="line">                      <span class="string">"TX"</span>: <span class="string">"Texas"</span>, <span class="string">"UT"</span>: <span class="string">"Utah"</span>, <span class="string">"VT"</span>: <span class="string">"Vermont"</span>, <span class="string">"VA"</span>: <span class="string">"Virginia"</span>, <span class="string">"WA"</span>: <span class="string">"Washington"</span>,</span><br><span class="line">                      <span class="string">"WV"</span>: <span class="string">"West Virginia"</span>, <span class="string">"WI"</span>: <span class="string">"Wisconsin"</span>, <span class="string">"WY"</span>: <span class="string">"Wyoming"</span>&#125;</span><br><span class="line"><span class="comment"># 为了便于计算坏账数,我们令坏账为1,好帐为0</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">0</span>, <span class="string">"Current"</span>: <span class="number">0</span>, <span class="string">"Charged Off"</span>: <span class="number">1</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">1</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">1</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">1</span>, <span class="string">"Default"</span>: <span class="number">1</span>&#125;</span><br><span class="line"><span class="comment"># 用1表示贷款状况良好，用0表示不良贷款</span></span><br><span class="line">loan_data[<span class="string">"loan_status_count_3"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_3"</span>] = loan_data[<span class="string">"loan_status_count_3"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line"><span class="comment"># print(loan_data["loan_status_count"].value_counts().to_dict())</span></span><br><span class="line"><span class="comment"># &#123;0.0: 1862171, 1.0: 274902&#125;</span></span><br><span class="line">loan_status_per_state = loan_data.groupby(<span class="string">"addr_state"</span>)[<span class="string">"loan_status_count_3"</span>].sum().to_dict()</span><br><span class="line">loan_status_per_state_pd = pd.DataFrame(list(loan_status_per_state.items()),</span><br><span class="line">                                        columns=[<span class="string">"state_code"</span>, <span class="string">"bad_loan_percent"</span>])</span><br><span class="line">loan_times_per_state_sum_dict = loan_data[<span class="string">"addr_state"</span>].value_counts().to_dict()</span><br><span class="line">loan_status_per_state_pd[<span class="string">"state_name"</span>] = <span class="literal">None</span></span><br><span class="line"><span class="comment"># print(loan_status_per_state_pd)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(loan_status_per_state_pd.shape[<span class="number">0</span>]):</span><br><span class="line">state_name = code_and_name_dict[loan_status_per_state_pd.ix[i, <span class="string">"state_code"</span>]]</span><br><span class="line">loan_status_per_state_pd.ix[i, <span class="string">"state_name"</span>] = state_name</span><br><span class="line"><span class="comment"># print(loan_status_per_state_pd)</span></span><br><span class="line"><span class="comment"># print(loan_times_per_state_sum_dict)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(loan_status_per_state_pd.shape[<span class="number">0</span>]):</span><br><span class="line">per_state_sum = loan_times_per_state_sum_dict[loan_status_per_state_pd.ix[i, <span class="string">"state_code"</span>]]</span><br><span class="line">loan_status_per_state_pd.ix[i, <span class="string">"bad_loan_percent"</span>] = float(</span><br><span class="line">loan_status_per_state_pd.ix[i, <span class="string">"bad_loan_percent"</span>]) / per_state_sum</span><br><span class="line"><span class="comment"># print(loan_status_per_state_pd)</span></span><br><span class="line"><span class="comment"># 设立颜色条色彩渐变颜色</span></span><br><span class="line"><span class="comment"># colorscale可选项:["Greys", "YlGnBu", "Greens", "YlOrRd", "Bluered", "RdBu","Reds", "Blues", "Picnic", "Rainbow",</span></span><br><span class="line"><span class="comment"># "Portland", "Jet","Hot", "Blackbody", "Earth", "Electric", "Viridis", "Cividis"]</span></span><br><span class="line">colorscale = <span class="string">"Reds"</span></span><br><span class="line"><span class="comment"># colorbar为颜色条注释,位置由各州的编号，即缩写表示,z值越高颜色越深</span></span><br><span class="line">data = [dict(type=<span class="string">"choropleth"</span>, colorscale=colorscale, autocolorscale=<span class="literal">False</span>, reversescale=<span class="literal">False</span>,</span><br><span class="line">             locations=loan_status_per_state_pd[<span class="string">"state_code"</span>], z=loan_status_per_state_pd[<span class="string">"bad_loan_percent"</span>],</span><br><span class="line">             locationmode=<span class="string">"USA-states"</span>, text=loan_status_per_state_pd[<span class="string">"state_name"</span>],</span><br><span class="line">             marker=dict(line=dict(color=<span class="string">"rgb(255,255,255)"</span>, width=<span class="number">2</span>)),</span><br><span class="line">             colorbar=dict(title=<span class="string">"bad loans percent"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">32</span>)))]</span><br><span class="line">layout = dict(title=<span class="string">"bad loans percent per state map"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">50</span>),</span><br><span class="line">              geo=dict(scope=<span class="string">"usa"</span>, projection=dict(type=<span class="string">"albers usa"</span>)))</span><br><span class="line">fig = dict(data=data, layout=layout)</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_3"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment"># filename为网站上个人空间中保存的文件名</span></span><br><span class="line">py.plot(fig, filename=<span class="string">"bad loans percent per state map"</span>, auto_open=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># filename为本地保存的文件名,plotly本地保存只支持png,svg,jpeg,pdf</span></span><br><span class="line">py.image.save_as(fig, filename=<span class="string">"./pictures/bad loans percent per state map.png"</span>, width=<span class="number">2500</span>, height=<span class="number">1500</span>)</span><br></pre></td></tr></table></figure><h2 id="贷款目的词云图"><a href="#贷款目的词云图" class="headerlink" title="贷款目的词云图"></a>贷款目的词云图</h2><p>特征purpose为每笔贷款申请时填写的目的。我们将数据集按该特征分组，然后计算每种purpose的贷款笔数，画成词云图。词云图中文字尺寸越大的目的，代表该目的的贷款笔数越多。我们可以发现贷款目的中debt consolidation(债务合并)这一目的的比例远远超过其他目的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loan purpose word cloud map</span></span><br><span class="line">loan_times_per_purpose_sum_dict = loan_data[<span class="string">"purpose"</span>].value_counts().to_dict()</span><br><span class="line"><span class="comment"># print(loan_times_per_purpose_sum_dict)</span></span><br><span class="line">loan_times_per_purpose_sum_pd = pd.DataFrame(list(loan_times_per_purpose_sum_dict.items()),</span><br><span class="line">                                             columns=[<span class="string">"purpose"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line"><span class="comment"># print(loan_times_per_purpose_sum_pd)</span></span><br><span class="line">wordcloud = WordCloud(width=<span class="number">1500</span>, height=<span class="number">1000</span>)</span><br><span class="line">wordcloud.add(<span class="string">"loan purpose word cloud"</span>, loan_times_per_purpose_sum_pd[<span class="string">"purpose"</span>],</span><br><span class="line">              loan_times_per_purpose_sum_pd[<span class="string">"loan_times"</span>], shape=<span class="string">"diamond"</span>,</span><br><span class="line">              rotate_step=<span class="number">60</span>, word_size_range=[<span class="number">10</span>, <span class="number">100</span>])</span><br><span class="line">wordcloud.render(path=<span class="string">"./pictures/loan purpose word cloud.html"</span>)</span><br><span class="line">wordcloud.render(path=<span class="string">"./pictures/loan purpose word cloud.pdf"</span>)</span><br></pre></td></tr></table></figure><h2 id="各种贷款目的的优质-不良贷款比例"><a href="#各种贷款目的的优质-不良贷款比例" class="headerlink" title="各种贷款目的的优质/不良贷款比例"></a>各种贷款目的的优质/不良贷款比例</h2><p>我们将数据集按贷款目的分组，然后计算每种目的中的优质贷款笔数和不良贷款笔数占总贷款笔数的比例。可以发现贷款目的中debt consolidation(债务合并)这一目的的比例远远超过其他目的，同时其不良贷款比例也是最高的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># the ratio of good loans and bad loans for each loan purpose</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_4"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_4"</span>] = loan_data[<span class="string">"loan_status_count_4"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">f_loan_status_purpose, ax_loan_status_purpose = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_4"</span>] = loan_data[<span class="string">"loan_status_count_4"</span>].map(loan_status_dict)</span><br><span class="line">sns.barplot(x=loan_data[<span class="string">"purpose"</span>], y=loan_data[<span class="string">"loan_amnt"</span>], hue=loan_data[<span class="string">"loan_status_count_4"</span>], hue_order=labels,</span><br><span class="line">            ax=ax_loan_status_purpose, estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data[<span class="string">"loan_status_count_4"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status_purpose.set_title(<span class="string">"Loan status per purpose percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_purpose.set_xticklabels(ax_loan_status_purpose.get_xticklabels(), rotation=<span class="number">45</span>)</span><br><span class="line">ax_loan_status_purpose.set_xlabel(<span class="string">"purpose"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_purpose.set_ylabel(<span class="string">"per purpose loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_4"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line">f_loan_status_purpose.savefig(<span class="string">"./pictures/Loan status per purpose percent bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                              bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="优质-不良贷款客户的住房情况比例"><a href="#优质-不良贷款客户的住房情况比例" class="headerlink" title="优质/不良贷款客户的住房情况比例"></a>优质/不良贷款客户的住房情况比例</h2><p>将数据集先按优质/不良贷款分组，然后每个分组再按住房情况进行分组。我们可以发现在MORTGAGE（即按揭）这种情况中，优质贷款客户中属于按揭购买住房的比例明显更高，这部分人应当属于优质客户，可以作为放贷的重点发展对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ratio of housing for good loans customer and bad loans customer</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_5"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_5"</span>] = loan_data[<span class="string">"loan_status_count_5"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">f_loan_status_home, ax_loan_status_home = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_5"</span>] = loan_data[<span class="string">"loan_status_count_5"</span>].map(loan_status_dict)</span><br><span class="line">sns.barplot(x=loan_data[<span class="string">"home_ownership"</span>], y=loan_data[<span class="string">"loan_amnt"</span>], hue=loan_data[<span class="string">"loan_status_count_5"</span>],</span><br><span class="line">            hue_order=labels,</span><br><span class="line">            ax=ax_loan_status_home, estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data[<span class="string">"loan_status_count_5"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status_home.set_title(<span class="string">"Loan status per home percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_home.set_xlabel(<span class="string">"home ownership"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_home.set_ylabel(<span class="string">"per home ownership loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_5"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line">f_loan_status_home.savefig(<span class="string">"./pictures/Loan status per home ownership percent bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                           bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="按收入分组的不良贷款比例"><a href="#按收入分组的不良贷款比例" class="headerlink" title="按收入分组的不良贷款比例"></a>按收入分组的不良贷款比例</h2><p>我们仍按收入将数据集分成三组:20000以下为low，20000-60000为mid，&gt;60000为high。计算每个分组的不良贷款比例。可以发现高收入客户中不良贷款笔数占的高收入客户的总贷款笔数的比例相对更小。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ratio of good loans and bad loans for each income level</span></span><br><span class="line"><span class="comment"># 我们将年收入分为三档:20000以下为low，20000-60000为mid，&gt;60000为high</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_6"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_6"</span>] = loan_data[<span class="string">"loan_status_count_6"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">max_value = loan_data[<span class="string">"annual_inc"</span>].max() + <span class="number">1.0</span></span><br><span class="line">set_bins = [<span class="number">0.0</span>, <span class="number">20000.0</span>, <span class="number">60000.0</span>, max_value]</span><br><span class="line">set_label = [<span class="string">"low"</span>, <span class="string">"mid"</span>, <span class="string">"high"</span>]</span><br><span class="line">loan_data[<span class="string">"income"</span>] = pd.cut(loan_data[<span class="string">"annual_inc"</span>], bins=set_bins, labels=set_label)</span><br><span class="line">f_loan_status_income, ax_loan_status_income = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_6"</span>] = loan_data[<span class="string">"loan_status_count_6"</span>].map(loan_status_dict)</span><br><span class="line">sns.barplot(x=loan_data[<span class="string">"income"</span>], y=loan_data[<span class="string">"loan_amnt"</span>], hue=loan_data[<span class="string">"loan_status_count_6"</span>], hue_order=labels,</span><br><span class="line">            ax=ax_loan_status_income, estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data[<span class="string">"loan_status_count_6"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status_income.set_title(<span class="string">"Loan status per income percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_income.set_xlabel(<span class="string">"income"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_income.set_ylabel(<span class="string">"per income loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_6"</span>, <span class="string">"income"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line">f_loan_status_income.savefig(<span class="string">"./pictures/Loan status per income percent bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                             bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="各个信用等级的优质-不良贷款比例"><a href="#各个信用等级的优质-不良贷款比例" class="headerlink" title="各个信用等级的优质/不良贷款比例"></a>各个信用等级的优质/不良贷款比例</h2><p>特征grade代表每笔贷款的申请人的信用等级。信用等级从高到低为A-G，信用等级较高的客户贷款次数也较多，因为这类人群有能力还款，所以愿意贷款。另外，信用等级较高的客户不良贷款的比例也更小（相对于本信用等级总贷款笔数）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># the ratio of good loans and bad loans for each credit rating</span></span><br><span class="line">loan_data_sorted = loan_data.sort_values(by=[<span class="string">"grade"</span>], inplace=<span class="literal">False</span>)</span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data_sorted[<span class="string">"loan_status_count_7"</span>] = loan_data_sorted[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data_sorted[<span class="string">"loan_status_count_7"</span>] = loan_data_sorted[<span class="string">"loan_status_count_7"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">f_loan_status_grade, ax_loan_status_grade = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data_sorted[<span class="string">"loan_status_count_7"</span>] = loan_data_sorted[<span class="string">"loan_status_count_7"</span>].map(loan_status_dict)</span><br><span class="line">sns.barplot(x=loan_data_sorted[<span class="string">"grade"</span>], y=loan_data_sorted[<span class="string">"loan_amnt"</span>], hue=loan_data_sorted[<span class="string">"loan_status_count_7"</span>],</span><br><span class="line">            hue_order=labels,</span><br><span class="line">            ax=ax_loan_status_grade, estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data_sorted[<span class="string">"loan_status_count_7"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status_grade.set_title(<span class="string">"Loan status per grade percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_grade.set_xlabel(<span class="string">"grade"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_grade.set_ylabel(<span class="string">"per grade loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">print(loan_data.shape)</span><br><span class="line">f_loan_status_grade.savefig(<span class="string">"./pictures/Loan status per grade percent bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                            bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="贷款利率的数据分布"><a href="#贷款利率的数据分布" class="headerlink" title="贷款利率的数据分布"></a>贷款利率的数据分布</h2><p>特征int_rate代表每笔贷款的利率。我们单独提取出这个特征的所有值，画其数据分布图。我们可以发现这个特征的取值比较符合高斯分布，但中间有些值的离散情况比较严重。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># data distribution of loan interest rates</span></span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_int_rate, ax_int_rate = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.distplot(loan_data[<span class="string">"int_rate"</span>], ax=ax_int_rate[<span class="number">0</span>], color=<span class="string">"#2F8FF7"</span>)</span><br><span class="line">sns.violinplot(y=loan_data[<span class="string">"int_rate"</span>], ax=ax_int_rate[<span class="number">1</span>], inner=<span class="string">"quartile"</span>, palette=<span class="string">"Blues"</span>)</span><br><span class="line">ax_int_rate[<span class="number">0</span>].set_title(<span class="string">"Int rate distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_int_rate[<span class="number">1</span>].set_title(<span class="string">"Int rate distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_int_rate[<span class="number">0</span>].set_xlabel(<span class="string">"Int rate"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_int_rate[<span class="number">0</span>].set_ylabel(<span class="string">"Int rate"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_int_rate.savefig(<span class="string">"./pictures/Int rate distribution.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="优质-不良贷款在各个信用等级的平均利率"><a href="#优质-不良贷款在各个信用等级的平均利率" class="headerlink" title="优质/不良贷款在各个信用等级的平均利率"></a>优质/不良贷款在各个信用等级的平均利率</h2><p>我们将数据集按信用等级分组，每个信用等级再按优质/不良贷款分组，然后计算每个分组的平均利率。我们发现越是高信用客户，其越倾向于利率较低的贷款。另外每个信用等级中不良贷款和优质贷款中的平均利率基本相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># average interest rate of good loans and bad loans for each credit ratings</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_8"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_8"</span>] = loan_data[<span class="string">"loan_status_count_8"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">f_inc_rate_grade, ax_inc_rate_grade = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_8"</span>] = loan_data[<span class="string">"loan_status_count_8"</span>].map(loan_status_dict)</span><br><span class="line">loan_data_sorted = loan_data.sort_values(by=[<span class="string">"grade"</span>], inplace=<span class="literal">False</span>)</span><br><span class="line">sns.barplot(x=loan_data_sorted[<span class="string">"grade"</span>], y=loan_data_sorted[<span class="string">"int_rate"</span>], hue=loan_data_sorted[<span class="string">"loan_status_count_8"</span>],</span><br><span class="line">            hue_order=labels, ax=ax_inc_rate_grade, ci=<span class="literal">None</span>)</span><br><span class="line">ax_inc_rate_grade.set_title(<span class="string">"mean int rate per grade"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_inc_rate_grade.set_xlabel(<span class="string">"grade"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_inc_rate_grade.set_ylabel(<span class="string">"mean int rate"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_8"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line">f_inc_rate_grade.savefig(<span class="string">"./pictures/mean int rate per grade bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                         bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="贷款人每月还款占其总收入比例的数据分布"><a href="#贷款人每月还款占其总收入比例的数据分布" class="headerlink" title="贷款人每月还款占其总收入比例的数据分布"></a>贷款人每月还款占其总收入比例的数据分布</h2><p>特征dti为每笔贷款的贷款人每月还款占其总收入比例的数据分布。该数据中有异常值-1.0，且有很大的离散值，我们需要将其先过滤掉然后再画数据分布图。该特征是一个比较完美的高斯分布，这对于我们后面模型拟合前的预处理有很好的指示效果。<br>需要注意的是，实际上不止dti这一个特征有异常值，在后面模型拟合前对数据集进行预处理时必须考虑异常值对数据集的影响。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># data distribution of the percentage of the lender"s month-repayments divide the lender"s income</span></span><br><span class="line"><span class="comment"># max_value=loan_data["dti"].max()</span></span><br><span class="line"><span class="comment"># min_value=loan_data["dti"].min()</span></span><br><span class="line"><span class="comment"># print(max_value,min_value)</span></span><br><span class="line"><span class="comment"># 999.0 -1.0 这里的数值应当是百分比</span></span><br><span class="line"><span class="comment"># 该数据中有异常值-1.0,且有很大的离散值,我们需要将其先过滤掉,否则图像效果不好</span></span><br><span class="line">loan_data_dti = loan_data[loan_data[<span class="string">"dti"</span>] &lt;= <span class="number">100.0</span>]</span><br><span class="line">loan_data_dti = loan_data_dti[loan_data_dti[<span class="string">"dti"</span>] &gt; <span class="number">0.0</span>]</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_dti, ax_dti = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.distplot(loan_data_dti[<span class="string">"dti"</span>], ax=ax_dti[<span class="number">0</span>], color=<span class="string">"#F7522F"</span>)</span><br><span class="line">sns.violinplot(y=loan_data_dti[<span class="string">"dti"</span>], ax=ax_dti[<span class="number">1</span>], inner=<span class="string">"quartile"</span>, palette=<span class="string">"Reds"</span>)</span><br><span class="line">ax_dti[<span class="number">0</span>].set_title(<span class="string">"dti distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti[<span class="number">1</span>].set_title(<span class="string">"dti distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti[<span class="number">0</span>].set_xlabel(<span class="string">"dti"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti[<span class="number">1</span>].set_ylabel(<span class="string">"dti"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_dti.savefig(<span class="string">"./pictures/dti distribution.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="优质-不良贷款的贷款人每月还款占其总收入比例的数据分布"><a href="#优质-不良贷款的贷款人每月还款占其总收入比例的数据分布" class="headerlink" title="优质/不良贷款的贷款人每月还款占其总收入比例的数据分布"></a>优质/不良贷款的贷款人每月还款占其总收入比例的数据分布</h2><p>我们再将数据集按优质/不良贷款分组，查看每个分组的贷款人每月还款占其总收入比例的数据分布。看起来两个分组中的高斯分布十分接近，说明优质/不良贷款分组对特征dti的分布没有什么影响。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># data distribution of the percentage of the good lender"s month-repayments divide the lender"s income and the percentage of the bad lender"s month-repayments divide the lender"s income</span></span><br><span class="line"><span class="comment"># 请先过滤异常值和极大离散点,只保留0-200之间的数据</span></span><br><span class="line">loan_data_dti = loan_data[loan_data[<span class="string">"dti"</span>] &lt;= <span class="number">100.0</span>]</span><br><span class="line">loan_data_dti = loan_data_dti[loan_data_dti[<span class="string">"dti"</span>] &gt;= <span class="number">0.0</span>]</span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data_dti[<span class="string">"loan_status_count_9"</span>] = loan_data_dti[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data_dti[<span class="string">"loan_status_count_9"</span>] = loan_data_dti[<span class="string">"loan_status_count_9"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">labels = <span class="string">"Bad loans"</span>, <span class="string">"Good loans"</span></span><br><span class="line"><span class="comment"># 取出groupby后的分组结果</span></span><br><span class="line">loans_dti_per_status = dict(list(loan_data_dti.groupby(<span class="string">"loan_status_count_9"</span>)[<span class="string">"dti"</span>]))</span><br><span class="line">good_loan_dti = pd.DataFrame(loans_dti_per_status[<span class="number">1.0</span>], index=<span class="literal">None</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">bad_loan_dti = pd.DataFrame(loans_dti_per_status[<span class="number">0.0</span>], index=<span class="literal">None</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(good_loan_dti, bad_loan_dti)</span></span><br><span class="line"><span class="comment"># print(good_loan_dti.shape, bad_loan_dti.shape)</span></span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_dti_per_loan_status, ax_dti_per_loan_status = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.distplot(good_loan_dti[<span class="string">"dti"</span>], ax=ax_dti_per_loan_status[<span class="number">0</span>], color=<span class="string">"#2F8FF7"</span>)</span><br><span class="line">sns.distplot(bad_loan_dti[<span class="string">"dti"</span>], ax=ax_dti_per_loan_status[<span class="number">1</span>], color=<span class="string">"#F7522F"</span>)</span><br><span class="line">ax_dti_per_loan_status[<span class="number">0</span>].set_title(<span class="string">"good loans dti distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti_per_loan_status[<span class="number">1</span>].set_title(<span class="string">"bad loans dti distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti_per_loan_status[<span class="number">0</span>].set_xlabel(<span class="string">"dti"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti_per_loan_status[<span class="number">1</span>].set_ylabel(<span class="string">"dti"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">print(loan_data.shape)</span><br><span class="line">f_dti_per_loan_status.savefig(<span class="string">"./pictures/dti distribution per loan status.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="优质-不良贷款中短期和长期贷款的比例"><a href="#优质-不良贷款中短期和长期贷款的比例" class="headerlink" title="优质/不良贷款中短期和长期贷款的比例"></a>优质/不良贷款中短期和长期贷款的比例</h2><p>贷款期限分为36个月和60个月两种，36个月的短期贷款笔数更多，但短期贷款中不良贷款笔数占短期贷款总笔数的比例更小，说明短期贷款的风险更小。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ratio of short-term and long-term loans for good loans and bad loans</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_10"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_10"</span>] = loan_data[<span class="string">"loan_status_count_10"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">f_loan_status_term, ax_loan_status_term = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_10"</span>] = loan_data[<span class="string">"loan_status_count_10"</span>].map(loan_status_dict)</span><br><span class="line">loan_data_sorted = loan_data.sort_values(by=[<span class="string">"grade"</span>], inplace=<span class="literal">False</span>)</span><br><span class="line">sns.barplot(x=loan_data_sorted[<span class="string">"term"</span>], y=loan_data_sorted[<span class="string">"loan_amnt"</span>], hue=loan_data_sorted[<span class="string">"loan_status_count_10"</span>],</span><br><span class="line">            hue_order=labels,</span><br><span class="line">            ax=ax_loan_status_term, estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data_sorted[<span class="string">"loan_status_count_10"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status_term.set_title(<span class="string">"loan times per term"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_term.set_xlabel(<span class="string">"term"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_term.set_ylabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_10"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line">f_loan_status_term.savefig(<span class="string">"./pictures/loan times per term bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                           bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h1 id="模型训练和预测前的数据预处理"><a href="#模型训练和预测前的数据预处理" class="headerlink" title="模型训练和预测前的数据预处理"></a>模型训练和预测前的数据预处理</h1><p>如果我们想直接进行模型训练和预测，跳过数据可视化分析部分，那么我们只需运行数据可视化分析前的数据预处理中所有部分的代码，然后接着运行模型训练和预测前的数据集处理中所有代码，再运行模型训练和预测代码即可。</p><h2 id="引入包和载入数据集"><a href="#引入包和载入数据集" class="headerlink" title="引入包和载入数据集"></a>引入包和载入数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> RobustScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report, confusion_matrix</span><br><span class="line"></span><br><span class="line">loan_data = pd.read_csv(<span class="string">"loan_clean_data.csv"</span>, low_memory=<span class="literal">False</span>)</span><br><span class="line">print(loan_data.shape)</span><br></pre></td></tr></table></figure><h2 id="样本类别不平衡状态的统计"><a href="#样本类别不平衡状态的统计" class="headerlink" title="样本类别不平衡状态的统计"></a>样本类别不平衡状态的统计</h2><p>该数据集中存在严重的样本不平衡，训练集中正样本：负样本=6.775：1。在后面进行模型训练和预测时我们需要注意这个问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># There is a serious problem of sample imbalance in this dataset</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line"><span class="comment"># 用1表示贷款状况良好，用0表示不良贷款</span></span><br><span class="line">loan_data[<span class="string">"loan_status_count_11"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_11"</span>] = loan_data[<span class="string">"loan_status_count_11"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">loan_data_status_count = loan_data[<span class="string">"loan_status_count_11"</span>].value_counts().to_dict()</span><br><span class="line">sum_value = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> loan_data_status_count.items():</span><br><span class="line">sum_value += value</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> loan_data_status_count.items():</span><br><span class="line">loan_data_status_count[key] = value / sum_value</span><br><span class="line">print(loan_data_status_count)</span><br><span class="line"><span class="comment"># &#123;1.0: 0.8713651803190625, 0.0: 0.12863481968093743&#125;</span></span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_11"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment"># (2137073, 87)</span></span><br></pre></td></tr></table></figure><h2 id="特征的抛弃、转换、填充"><a href="#特征的抛弃、转换、填充" class="headerlink" title="特征的抛弃、转换、填充"></a>特征的抛弃、转换、填充</h2><p>特征loan_status代表该贷款的状态，我们可按下面的映射转为数值型特征:<br>loan_status_dict = {“Fully Paid”: 1, “Current”: 1, “Charged Off”: 0, “Late (31-120 days)”: 0,<br>​                    “In Grace Period”: 0, “Late (16-30 days)”: 0, “Default”: 0}<br>即变为二分类问题。<br>特征emp_length代表贷款人的工作年限，可按下面的映射转为数值型特征：<br>emp_length_dict = {‘10+ years’: 10, ‘2 years’: 2, ‘&lt; 1 year’: 0.5, ‘3 years’: 3, ‘1 year’: 1, ‘5 years’: 5,’4 years’: 4, ‘6 years’: 6, ‘7 years’: 7, ‘8 years’: 8, ‘9 years’: 9}<br>注意小于1年的映射为0.5，另外该特征的缺失值填充为0。<br>删除无用特征：emp_title’, ‘title’, ‘zip_code’, ‘earliest_cr_line’, ‘last_pymnt_d’, ‘last_credit_pull_d。<br>emp_title的特征取值过多且每个取值出现次数占总样本数的比例很小，对模型学习和预测没有帮助，故删除。<br>‘zip_code’, ‘earliest_cr_line’, ‘last_pymnt_d’, ‘last_credit_pull_d’这几个特征对于模型学习没有什么实际的意义，故也删除。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># feature:loan_status‘s change to 0 or 1</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line"><span class="comment"># 1 is good loan,0 is bad loan</span></span><br><span class="line">loan_data[<span class="string">"loan_status"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status"</span>] = loan_data[<span class="string">"loan_status"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line"><span class="comment"># print(loan_data["emp_length"].value_counts().to_dict)</span></span><br><span class="line">emp_length_dict = &#123;<span class="string">"10+ years"</span>: <span class="number">10</span>, <span class="string">"2 years"</span>: <span class="number">2</span>, <span class="string">"&lt; 1 year"</span>: <span class="number">0.5</span>, <span class="string">"3 years"</span>: <span class="number">3</span>, <span class="string">"1 year"</span>: <span class="number">1</span>, <span class="string">"5 years"</span>: <span class="number">5</span>,</span><br><span class="line">                   <span class="string">"4 years"</span>: <span class="number">4</span>, <span class="string">"6 years"</span>: <span class="number">6</span>, <span class="string">"7 years"</span>: <span class="number">7</span>, <span class="string">"8 years"</span>: <span class="number">8</span>, <span class="string">"9 years"</span>: <span class="number">9</span>&#125;</span><br><span class="line">loan_data[<span class="string">"emp_length"</span>] = loan_data[<span class="string">"emp_length"</span>].map(emp_length_dict)</span><br><span class="line">loan_data[<span class="string">"emp_length"</span>] = loan_data[<span class="string">"emp_length"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line"><span class="comment"># fill missing value of emp_length to 0</span></span><br><span class="line">loan_data[<span class="string">"emp_length"</span>].fillna(value=<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># drop some features</span></span><br><span class="line">loan_data.drop([<span class="string">"emp_title"</span>, <span class="string">"title"</span>, <span class="string">"zip_code"</span>, <span class="string">"earliest_cr_line"</span>, <span class="string">"last_pymnt_d"</span>, <span class="string">"last_credit_pull_d"</span>], axis=<span class="number">1</span>,</span><br><span class="line">               inplace=<span class="literal">True</span>)</span><br><span class="line">loan_data[<span class="string">"month"</span>], loan_data[<span class="string">"year"</span>] = loan_data[<span class="string">"issue_d"</span>].str.split(<span class="string">"-"</span>, <span class="number">1</span>).str</span><br><span class="line">loan_data.drop([<span class="string">"issue_d"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment"># (2137073, 82)</span></span><br></pre></td></tr></table></figure><h2 id="数值型特征的皮尔森相关系数矩阵"><a href="#数值型特征的皮尔森相关系数矩阵" class="headerlink" title="数值型特征的皮尔森相关系数矩阵"></a>数值型特征的皮尔森相关系数矩阵</h2><p>皮尔森相关系数矩阵可以表示两两特征之间的线性相关性。 若&gt;0，表明两个变量是正相关，即一个变量的值越大，另一个变量的值也会越大；若&lt;0，表明两个变量是负相关，即一个变量的值越大，另一个变量的值反而会越小；若r=0，表明两个变量间不是线性相关，但有可能是非线性相关。<br>注意皮尔森相关系数只需要对数值型特征进行计算。我们可以看到一开始可视化的loan_amnt和funded_amnt的两个特征（下图第一个和第二个特征）相关系数接近1，这验证了我们之前对这两个特征的相关性猜想。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">numerical_feature_name = loan_data.columns[(loan_data.dtypes == <span class="string">"float64"</span>) | (loan_data.dtypes == <span class="string">"int64"</span>)].tolist()</span><br><span class="line"><span class="comment"># category_feature_name = loan_data.columns[loan_data.dtypes == "object"].tolist()</span></span><br><span class="line"><span class="comment"># draw pearson correlation coefficient matrix</span></span><br><span class="line"><span class="comment"># 若&gt;0，表明两个变量是正相关,即一个变量的值越大，另一个变量的值也会越大</span></span><br><span class="line"><span class="comment"># 若&lt;0，表明两个变量是负相关，即一个变量的值越大另一个变量的值反而会越小</span></span><br><span class="line"><span class="comment"># 若r=0，表明两个变量间不是线性相关，但有可能是非线性相关</span></span><br><span class="line">corrmat = loan_data[numerical_feature_name].corr()</span><br><span class="line">f, ax = plt.subplots(figsize=(<span class="number">30</span>, <span class="number">20</span>))</span><br><span class="line"><span class="comment"># vmax、vmin即热力图颜色取值的最大值和最小值,默认会从data中推导</span></span><br><span class="line"><span class="comment"># square=True会将单元格设为正方形</span></span><br><span class="line">sns.heatmap(corrmat, square=<span class="literal">True</span>, ax=ax, cmap=<span class="string">"Blues"</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">ax.set_title(<span class="string">"Correlation coefficient matrix"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">"feature names"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">"feature names"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f.savefig(<span class="string">"./pictures/Correlation coefficient matrix.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="将特征和标签分开、特征one-hot编码化"><a href="#将特征和标签分开、特征one-hot编码化" class="headerlink" title="将特征和标签分开、特征one_hot编码化"></a>将特征和标签分开、特征one_hot编码化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split features and labels</span></span><br><span class="line">X = loan_data.ix[:, loan_data.columns != <span class="string">"loan_status"</span>]</span><br><span class="line">Y = loan_data[<span class="string">"loan_status"</span>]</span><br><span class="line">print(X.shape, Y.shape)</span><br><span class="line"><span class="comment"># (2137073, 81) (2137073,)</span></span><br><span class="line">X = pd.get_dummies(X, drop_first=<span class="literal">True</span>)</span><br><span class="line">print(X.shape)</span><br><span class="line"><span class="comment"># (2137073, 200)</span></span><br></pre></td></tr></table></figure><h2 id="划分训练集和测试集、数值型特征归一化"><a href="#划分训练集和测试集、数值型特征归一化" class="headerlink" title="划分训练集和测试集、数值型特征归一化"></a>划分训练集和测试集、数值型特征归一化</h2><p>这里我们要根据后面使用的是lr模型还是rf或xgb模型分别处理。<br>我们按照8:2划分训练集和测试集，训练集用来进行模型学习，测试集用来测试模型性能。<br>如果使用lr模型，那么数值型特征还要归一化。该数据集中存在异常点（如前面的dti特征中就有异常点），我们也无法确保其他特征中没有异常点，因此我们对数值型特征进行RobustScaler归一化，这种算法取第一分位数到第四分位数之间的数据生成均值和标准差，然后对特征进行z score标准化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # if use lr model to train and test,please run this cell</span></span><br><span class="line"><span class="comment"># # divide training sets and testing sets</span></span><br><span class="line"><span class="comment"># x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)</span></span><br><span class="line"><span class="comment"># print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)</span></span><br><span class="line"><span class="comment"># # (1709658, 200) (427415, 200) (1709658,) (427415,)</span></span><br><span class="line"><span class="comment"># numerical_feature_name_2 = X.columns[(X.dtypes == "float64") | (X.dtypes == "int64")].tolist()</span></span><br><span class="line"><span class="comment"># category_feature_name_2 = X.columns[X.dtypes == "uint8"].tolist()</span></span><br><span class="line"><span class="comment"># print(len(numerical_feature_name_2), len(category_feature_name_2))</span></span><br><span class="line"><span class="comment"># # 67 133</span></span><br><span class="line"><span class="comment"># # 此时类别型特征已经全部变为one_hot编码(k-1列),数值型特征还需要归一化,由于特征值中有异常值,我们使用RobustScaler方法归一化</span></span><br><span class="line"><span class="comment"># x_train_num, x_train_cat = x_train[numerical_feature_name_2], x_train[category_feature_name_2]</span></span><br><span class="line"><span class="comment"># x_test_num, x_test_cat = x_test[numerical_feature_name_2], x_test[category_feature_name_2]</span></span><br><span class="line"><span class="comment"># # get feature names</span></span><br><span class="line"><span class="comment"># feature_names = list(x_train_num.columns)</span></span><br><span class="line"><span class="comment"># feature_names.extend(list(x_train_cat.columns))</span></span><br><span class="line"><span class="comment"># feature_names = np.array(feature_names)</span></span><br><span class="line"><span class="comment"># print(feature_names.shape)</span></span><br><span class="line"><span class="comment"># # 200</span></span><br><span class="line"><span class="comment"># # robust scalar,默认为第一分位数到第四分位数之间的范围计算均值和方差,归一化还是z_score标准化</span></span><br><span class="line"><span class="comment"># rob_scaler = RobustScaler()</span></span><br><span class="line"><span class="comment"># x_train_num_rob = rob_scaler.fit_transform(x_train_num)</span></span><br><span class="line"><span class="comment"># x_test_num_rob = rob_scaler.transform(x_test_num)</span></span><br><span class="line"><span class="comment"># x_train_nom_pd = pd.DataFrame(np.hstack((x_train_num_rob, x_train_cat)))</span></span><br><span class="line"><span class="comment"># x_test_nom_pd = pd.DataFrame(np.hstack((x_test_num_rob, x_test_cat)))</span></span><br><span class="line"><span class="comment"># y_test_pd = pd.DataFrame(y_test)</span></span><br><span class="line"><span class="comment"># x_train_sm_np, y_train_sm_np = x_train_nom_pd, y_train</span></span><br><span class="line"><span class="comment"># print(x_train_sm_np.shape, y_train_sm_np.shape, x_test_nom_pd.shape, y_test.shape)</span></span><br><span class="line"><span class="comment"># # (1709658, 200) (1709658,) (427415, 200) (427415,)</span></span><br></pre></td></tr></table></figure><p>如果使用rf或xgb模型，直接按8:2划分训练集和测试集即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># if use rf or xgb model to train and test,please run this cell</span></span><br><span class="line"><span class="comment"># divide training sets and testing sets</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)</span><br><span class="line"><span class="comment"># (1709658, 200) (427415, 200) (1709658,) (427415,)</span></span><br><span class="line">x_train_sm_np, x_test_nom_pd, y_train_sm_np, y_test = x_train, x_test, y_train, y_test</span><br><span class="line">feature_names = X.columns.tolist()</span><br><span class="line">feature_names = np.array(feature_names)</span><br><span class="line">print(feature_names.shape)</span><br><span class="line"><span class="comment"># (200,)</span></span><br></pre></td></tr></table></figure><p><strong>注意:</strong><br>对数据集做归一化和one_hot编码化实际上只是为了后面的lr模型准备的，数值型特征归一化后各特征的数值在同一个数量级上，这样lr模型的收敛速度会加快；类别型特征想要用在lr模型中必须进行one_hot编码化，这样一个原始的类别型特征就可以由其one_hot编码化后的kone_hot个特征在欧氏空间中进行距离的度量分类。<br><strong>对于rf和xgb这样的树模型，数值型特征不做归一化直接进行模型训练完全没有问题。(做了以后再训练也可以，基本不影响模型最终性能，但增加了训练时间）</strong></p><p><strong>树模型不需要进行归一化的原因:</strong></p><ul><li>对于rf和xgb这样的树模型，其实不需要进行数据集的归一化和one_hot编码化就可以直接进行模型训练。因为基于决策树的树模型其分裂节点时的决策规则计算出的分裂点不受数值缩放的影响（当然归一化后计算出的分裂点也是一样的），因此是否归一化对树模型的结构不会造成影响。</li><li>另外，树模型是按照特征值进行排序的，排序的顺序不变，那么所属的分支以及分裂点就不会有不同。而且树模型不能进行梯度下降，因为构建树模型（回归树）寻找最优点时是通过寻找最优分裂点完成的，因此树模型是阶跃的，阶跃点是不可导的，并且求导没意义，也就不需要归一化。</li></ul><p><strong>树模型不需要进行one_hot编码化的原因:</strong></p><ul><li>GBDT树处理高维稀疏矩阵的时候效果并不好，即使是低维的稀疏矩阵也未必比SVM好 ；</li><li>类别型特征one_hot后再训练树，树的深度容易被加深；<br><strong>举例:</strong><br>假若某个特征A有1000个取值，CART分类树可以自动选择一个最佳的特征值a来分裂，得到一个2层的二叉树。如果将该特征使用onehot编码，变成1000维特征，每个特征只取0，1两种情况，再使用CART树来分裂，完全分裂的情况下，会对该特征生成的这1000维特征都要分裂一次，相当于这一个特征经过onehot编码后就会生成1000层二叉树（这是极端情况，节点的阈值数，基尼指数，或决策树的深度等限制会防止这种情况出现），这显然是不太合理的。</li><li>如果用one_hot后的数据集构建随机森林，每次分裂随机选择一部分特征，那么one_hot后的特征容易被低估重要性（因为原始特征只有1个，现在拆成了2个，相当于特征的贡献度也被拆成了两部分），最后one_hot后的特征得到的importance会比实际值低。</li></ul><p><strong>需要注意的是，对于本数据集，其类别型特征的数据并不是int、float、bool中的某一种，这种情况下数据集是不能直接送入rf或xgb模型进行训练的，故对于本数据集，要想使用rf或xgb模型进行训练或预测，数据集可以不归一化，但必须one_hot编码化。</strong></p><h2 id="样本不平衡问题的处理"><a href="#样本不平衡问题的处理" class="headerlink" title="样本不平衡问题的处理"></a>样本不平衡问题的处理</h2><p><strong>由于我们后面分别使用lr、rf、xgb模型进行模型训练和预测。使用lr模型时，使用参数class_weight=”balanced”即根据样本比例确定样本的权重来进行训练即可解决样本不平衡问题。使用rf和xgb模型时，由于树模型本身的特点，不需要进行样本不平衡的处理。</strong><br>我们还可以使用SMOTE算法生成少数类样本，使得不同类别的样本数量大致平衡。由于该算法占用内存较多，对于该数据集，你需要至少32GB内存才可以使用SMOTE算法。<br><strong>SMOTE算法流程：</strong><br>对于少数类中每一个样本x，以欧氏距离为标准计算它到少数类样本集中所有样本的距离，得到其k个近邻;<br>根据样本不平衡比例设置一个采样比例以确定采样倍率N，对于每一个少数类样本x，重复N次下列操作：从其k个近邻中随机选择某个样本，假设选择的近邻为xn。对于每一个随机选出的近邻xn，生成一个0-1之间的随机权重t，按公式x+t*(x-xn)构建一个新的少数类样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # we can choose class_weight="balanced" to deal with sample imbalance problem when we use logistic model</span></span><br><span class="line"><span class="comment"># # if we use random foreast model or xgboost model,we don’t need to deal with sample imbalance problem</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # besides,we can also use SMOTE to generate some sample of the category with low number of samples,but it needs over 16GB memory</span></span><br><span class="line"><span class="comment"># # so,if you want to use SMOTE,you can run all these code on a local computer with at least 32GB memory</span></span><br><span class="line"><span class="comment"># # SMOTE算法即对于少数类中的每一个样本a,执行N次下列操作:</span></span><br><span class="line"><span class="comment"># # 从k个最近邻样本中随机选择一个样本b, 然后从a与b的连线上随机选取一个点c作为新的少数类样本</span></span><br><span class="line"><span class="comment"># # n_jobs=-1表示使用所有CPU</span></span><br><span class="line"><span class="comment"># sm = SMOTE(k_neighbors=10, random_state=0, n_jobs=-1)</span></span><br><span class="line"><span class="comment"># x_train_sm_np, y_train_sm_np = sm.fit_sample(x_train_nom_pd, y_train)</span></span><br><span class="line"><span class="comment"># print(x_train_sm_np.shape, y_train_sm_np.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SMOTE算法需要大量内存,如果使用了该算法,则本py文件需要机器具有至少32GB内存才能一次执行完,故我们可以先将SMOTE结果存起来</span></span><br><span class="line"><span class="comment"># 然后直接读取SMOTE算法处理后的数据集进行预测,这样只需要16GB内存即可</span></span><br><span class="line"><span class="comment"># x_train_sm_pd = pd.DataFrame(x_train_sm_np)</span></span><br><span class="line"><span class="comment"># y_train_sm_pd = pd.DataFrame(y_train_sm_np)</span></span><br><span class="line"><span class="comment"># x_train_sm_pd.to_csv("x_train_sm_np.csv", index=None)</span></span><br><span class="line"><span class="comment"># y_train_sm_pd.to_csv("y_train_sm_np.csv", index=None)</span></span><br><span class="line"><span class="comment"># x_test_nom_pd.to_csv("x_test_nom_np.csv", index=None)</span></span><br><span class="line"><span class="comment"># y_test_pd.to_csv("y_test.csv", index=None)</span></span><br><span class="line"><span class="comment"># x_train_sm_np = np.array(pd.read_csv("x_train_sm_np.csv", low_memory=False))</span></span><br><span class="line"><span class="comment"># y_train_sm_np = np.array(pd.read_csv("y_train_sm_np.csv", low_memory=False))</span></span><br><span class="line"><span class="comment"># x_test_nom_pd = np.array(pd.read_csv("x_test_nom_np.csv", low_memory=False))</span></span><br><span class="line"><span class="comment"># y_test = np.array(pd.read_csv("y_test.csv", low_memory=False))</span></span><br><span class="line"><span class="comment"># print(x_train_sm_np.shape, y_train_sm_np.shape, x_test_nom_pd.shape, y_test.shape)</span></span><br><span class="line"><span class="comment"># # (2980148, 200) (2980148, 1) (427415, 200) (427415, 1)</span></span><br><span class="line"><span class="comment"># # 标签需要降维成一维数组</span></span><br><span class="line"><span class="comment"># y_train_sm_np = y_train_sm_np.ravel()</span></span><br><span class="line"><span class="comment"># y_test = y_test.ravel()</span></span><br><span class="line"><span class="comment"># print(x_train_sm_np.shape, y_train_sm_np.shape, x_test_nom_pd.shape, y_test.shape)</span></span><br><span class="line"><span class="comment"># # (2980148, 200) (2980148,) (427415, 200) (427415,)</span></span><br></pre></td></tr></table></figure><h1 id="模型训练和预测"><a href="#模型训练和预测" class="headerlink" title="模型训练和预测"></a>模型训练和预测</h1><h2 id="使用lr模型进行训练和预测"><a href="#使用lr模型进行训练和预测" class="headerlink" title="使用lr模型进行训练和预测"></a>使用lr模型进行训练和预测</h2><p>sag即随机平均梯度下降，和普通梯度下降法的区别是每次迭代仅仅用一部分的样本来计算梯度，适合于样本数据多的时候；class_weight=”balanced”根据用来训练的样本的各个类别的比例确定权重；n_jobs=-1表示使用所有CPU一起进行模型拟合和预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # use logistic regression model to train and predict</span></span><br><span class="line"><span class="comment"># # jobs=-1使用所有CPU进行运算</span></span><br><span class="line"><span class="comment"># # sag即随机平均梯度下降，和普通梯度下降法的区别是每次迭代仅仅用一部分的样本来计算梯度，适合于样本数据多的时候</span></span><br><span class="line"><span class="comment"># # class_weight="balanced"根据用来训练的样本的各个类别的比例确定权重</span></span><br><span class="line"><span class="comment"># print("use logistic model to train and predict")</span></span><br><span class="line"><span class="comment"># lr = LogisticRegression(solver="sag", class_weight="balanced", n_jobs=-1)</span></span><br><span class="line"><span class="comment"># lr.fit(x_train_sm_np, y_train_sm_np)</span></span><br><span class="line"><span class="comment"># lr_y_pred = lr.predict(x_test_nom_pd)</span></span><br><span class="line"><span class="comment"># lr_test_acc = accuracy_score(y_test, lr_y_pred)</span></span><br><span class="line"><span class="comment"># lr_classification_score = classification_report(y_test, lr_y_pred)</span></span><br><span class="line"><span class="comment"># print("Lr model test accuracy:&#123;:.2f&#125;".format(lr_test_acc))</span></span><br><span class="line"><span class="comment"># print("Lr model classification_score:\n", lr_classification_score)</span></span><br><span class="line"><span class="comment"># lr_confusion_score = confusion_matrix(y_test, lr_y_pred)</span></span><br><span class="line"><span class="comment"># f_lr, ax_lr = plt.subplots(1, 3, figsize=(15, 10))</span></span><br><span class="line"><span class="comment"># # 混淆矩阵的y轴为true label,x轴为pred label</span></span><br><span class="line"><span class="comment"># # 精确率,如对正类 ,所有预测为正类样本中中真实的正类占所有预测为正类的比例</span></span><br><span class="line"><span class="comment"># # 召回率,如对正类,所有真实的正类样本中有多少被预测为正类的比例</span></span><br><span class="line"><span class="comment"># # 分别计算预测预测的正样本数和负样本数以及真实的正样本数和负样本数</span></span><br><span class="line"><span class="comment"># lr_cm_pred_label_sum = lr_confusion_score.sum(axis=0)</span></span><br><span class="line"><span class="comment"># lr_cm_true_label_sum = lr_confusion_score.sum(axis=1)</span></span><br><span class="line"><span class="comment"># # 计算正样本和负样本的精确率和召回率</span></span><br><span class="line"><span class="comment"># lr_model_precision, lr_model_recall = np.empty([2, 2], dtype=float), np.empty([2, 2], dtype=float)</span></span><br><span class="line"><span class="comment"># lr_model_precision[0][0], lr_model_precision[1][0] = lr_confusion_score[0][0] / lr_cm_pred_label_sum[0], \</span></span><br><span class="line"><span class="comment">#                                                      lr_confusion_score[1][0] / lr_cm_pred_label_sum[0]</span></span><br><span class="line"><span class="comment"># lr_model_precision[0][1], lr_model_precision[1][1] = lr_confusion_score[0][1] / lr_cm_pred_label_sum[1], \</span></span><br><span class="line"><span class="comment">#                                                      lr_confusion_score[1][1] / lr_cm_pred_label_sum[1]</span></span><br><span class="line"><span class="comment"># lr_model_recall[0][0], lr_model_recall[0][1] = lr_confusion_score[0][0] / lr_cm_true_label_sum[0], \</span></span><br><span class="line"><span class="comment">#                                                lr_confusion_score[0][1] / lr_cm_true_label_sum[0]</span></span><br><span class="line"><span class="comment"># lr_model_recall[1][0], lr_model_recall[1][1] = lr_confusion_score[1][0] / lr_cm_true_label_sum[1], \</span></span><br><span class="line"><span class="comment">#                                                lr_confusion_score[1][1] / lr_cm_true_label_sum[1]</span></span><br><span class="line"><span class="comment"># sns.heatmap(lr_confusion_score, annot=True, fmt="d", cmap="Blues", ax=ax_lr[0], square=True, linewidths=0.5)</span></span><br><span class="line"><span class="comment"># sns.heatmap(lr_model_precision, annot=True, fmt=".5f", cmap="Blues", ax=ax_lr[1], square=True, linewidths=0.5)</span></span><br><span class="line"><span class="comment"># sns.heatmap(lr_model_recall, annot=True, fmt=".5f", cmap="Blues", ax=ax_lr[2], square=True, linewidths=0.5)</span></span><br><span class="line"><span class="comment"># ax_lr[0].set_title("lr confusion matrix", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[1].set_title("lr model precision", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[2].set_title("lr model recall", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[0].set_xlabel("Predicted label", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[0].set_ylabel("True label", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[1].set_xlabel("Predicted label", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[1].set_ylabel("True label", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[2].set_xlabel("Predicted label", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[2].set_ylabel("True label", fontsize=16)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"><span class="comment"># plt.close()</span></span><br><span class="line"><span class="comment"># f_lr.savefig("./pictures/lr model confusion matrix.jpg", dpi=200, bbox_inches="tight")</span></span><br><span class="line"><span class="comment"># # result</span></span><br><span class="line"><span class="comment"># # Lr model test accuracy:0.88</span></span><br><span class="line"><span class="comment"># # Lr model classification_score:</span></span><br><span class="line"><span class="comment"># #                precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment"># #          0.0       0.54      0.73      0.62     55318</span></span><br><span class="line"><span class="comment"># #          1.0       0.96      0.91      0.93    372097</span></span><br><span class="line"><span class="comment"># #    micro avg       0.88      0.88      0.88    427415</span></span><br><span class="line"><span class="comment"># #    macro avg       0.75      0.82      0.78    427415</span></span><br><span class="line"><span class="comment"># # weighted avg       0.90      0.88      0.89    427415</span></span><br></pre></td></tr></table></figure><p>混淆矩阵从左到右三个子图为lr模型预测标签/实际标签的样本的数量，lr模型预测负/正样本的精确率（第二张图左上角和右下角数值），lr模型预测负/正样本的召回率（第三张图左上角和右下角数值）。<br>Lr模型预测总体准确率0.88，其中正样本预测精确率0.96，但负样本预测精确率很低，只有0.54。同时正样本预测召回率0.91，负样本召回率0.73也很低。由于我们更想用模型预测出不良贷款，而这个模型的负样本准确率和召回率太低了，模型的预测性能不太好。</p><h2 id="使用rf模型进行训练和预测"><a href="#使用rf模型进行训练和预测" class="headerlink" title="使用rf模型进行训练和预测"></a>使用rf模型进行训练和预测</h2><p>n_estimators=200表示模型有200课树，n_jobs=-1使用所有CPU进行模型拟合和预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># use randomforest model to train and predict</span></span><br><span class="line">print(<span class="string">"use randomforest model to train and predict"</span>)</span><br><span class="line">rf = RandomForestClassifier(n_estimators=<span class="number">200</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">rf.fit(x_train_sm_np, y_train_sm_np)</span><br><span class="line">rf_y_pred = rf.predict(x_test_nom_pd)</span><br><span class="line">rf_test_acc = accuracy_score(y_test, rf_y_pred)</span><br><span class="line">rf_classification_score = classification_report(y_test, rf_y_pred)</span><br><span class="line">print(<span class="string">"Rf model test accuracy:&#123;:.4f&#125;"</span>.format(rf_test_acc))</span><br><span class="line">print(<span class="string">"rf model classification_score:\n"</span>, rf_classification_score)</span><br><span class="line">rf_confusion_score = confusion_matrix(y_test, rf_y_pred)</span><br><span class="line"><span class="comment"># print(rf_confusion_score)</span></span><br><span class="line">f_rf, ax_rf = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># 混淆矩阵的y轴为true label,x轴为pred label</span></span><br><span class="line"><span class="comment"># 精确率,如对正类 ,所有预测为正类样本中中真实的正类占所有预测为正类的比例</span></span><br><span class="line"><span class="comment"># 召回率,如对正类,所有真实的正类样本中有多少被预测为正类的比例</span></span><br><span class="line"><span class="comment"># 分别计算预测预测的正样本数和负样本数以及真实的正样本数和负样本数</span></span><br><span class="line">rf_cm_pred_label_sum = rf_confusion_score.sum(axis=<span class="number">0</span>)</span><br><span class="line">rf_cm_true_label_sum = rf_confusion_score.sum(axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 计算正样本和负样本的精确率和召回率</span></span><br><span class="line">rf_model_precision, rf_model_recall = np.empty([<span class="number">2</span>, <span class="number">2</span>], dtype=float), np.empty([<span class="number">2</span>, <span class="number">2</span>], dtype=float)</span><br><span class="line">rf_model_precision[<span class="number">0</span>][<span class="number">0</span>], rf_model_precision[<span class="number">1</span>][<span class="number">0</span>] = rf_confusion_score[<span class="number">0</span>][<span class="number">0</span>] / rf_cm_pred_label_sum[<span class="number">0</span>], \</span><br><span class="line">                                                     rf_confusion_score[<span class="number">1</span>][<span class="number">0</span>] / rf_cm_pred_label_sum[<span class="number">0</span>]</span><br><span class="line">rf_model_precision[<span class="number">0</span>][<span class="number">1</span>], rf_model_precision[<span class="number">1</span>][<span class="number">1</span>] = rf_confusion_score[<span class="number">0</span>][<span class="number">1</span>] / rf_cm_pred_label_sum[<span class="number">1</span>], \</span><br><span class="line">                                                     rf_confusion_score[<span class="number">1</span>][<span class="number">1</span>] / rf_cm_pred_label_sum[<span class="number">1</span>]</span><br><span class="line">rf_model_recall[<span class="number">0</span>][<span class="number">0</span>], rf_model_recall[<span class="number">0</span>][<span class="number">1</span>] = rf_confusion_score[<span class="number">0</span>][<span class="number">0</span>] / rf_cm_true_label_sum[<span class="number">0</span>], \</span><br><span class="line">                                               rf_confusion_score[<span class="number">0</span>][<span class="number">1</span>] / rf_cm_true_label_sum[<span class="number">0</span>]</span><br><span class="line">rf_model_recall[<span class="number">1</span>][<span class="number">0</span>], rf_model_recall[<span class="number">1</span>][<span class="number">1</span>] = rf_confusion_score[<span class="number">1</span>][<span class="number">0</span>] / rf_cm_true_label_sum[<span class="number">1</span>], \</span><br><span class="line">                                               rf_confusion_score[<span class="number">1</span>][<span class="number">1</span>] / rf_cm_true_label_sum[<span class="number">1</span>]</span><br><span class="line">sns.heatmap(rf_confusion_score, annot=<span class="literal">True</span>, fmt=<span class="string">"d"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_rf[<span class="number">0</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">sns.heatmap(rf_model_precision, annot=<span class="literal">True</span>, fmt=<span class="string">".5f"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_rf[<span class="number">1</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">sns.heatmap(rf_model_recall, annot=<span class="literal">True</span>, fmt=<span class="string">".5f"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_rf[<span class="number">2</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">ax_rf[<span class="number">0</span>].set_title(<span class="string">"rf confusion matrix"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">1</span>].set_title(<span class="string">"rf model precision"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">2</span>].set_title(<span class="string">"rf model recall"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">0</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">0</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">1</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">1</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">2</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">2</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_rf.savefig(<span class="string">"./pictures/rf model confusion matrix.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"><span class="comment"># Rf model test accuracy:0.9828</span></span><br><span class="line"><span class="comment"># rf model classification_score:</span></span><br><span class="line"><span class="comment">#                precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#          0.0       1.00      0.87      0.93     55318</span></span><br><span class="line"><span class="comment">#          1.0       0.98      1.00      0.99    372097</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#    micro avg       0.98      0.98      0.98    427415</span></span><br><span class="line"><span class="comment">#    macro avg       0.99      0.93      0.96    427415</span></span><br><span class="line"><span class="comment"># weighted avg       0.98      0.98      0.98    427415</span></span><br></pre></td></tr></table></figure><p>混淆矩阵从左到右三个子图为rf模型预测标签/实际标签的样本的数量，rf模型预测负/正样本的精确率（第二张图左上角和右下角数值），rf模型预测负/正样本的召回率（第三张图左上角和右下角数值）。<br>rf模型预测总体准确率0.98，其中正样本预测精确率0.981，负样本预测精确率0.999。同时正样本预测召回率0.999，负样本召回率0.868。该模型对于负样本（不良贷款）预测的精确率很高，召回率也相对较好，故该模型比较适合用来预测。<br><strong>我们还可以画出该模型训练时各特征的贡献度:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># random forest model feature contribution visualization</span></span><br><span class="line">feature_importances = rf.feature_importances_</span><br><span class="line"><span class="comment"># print(feature_importances)</span></span><br><span class="line"><span class="comment"># y=x.argsort()函数是将x中的元素从小到大排列，提取其对应的index(索引)</span></span><br><span class="line">indices = np.argsort(feature_importances)[::<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># 只取贡献度最高的30个特征来作图</span></span><br><span class="line">show_indices = indices[<span class="number">0</span>:<span class="number">30</span>]</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f, ax = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.barplot(x=feature_importances[show_indices], y=feature_names[show_indices], ax=ax)</span><br><span class="line">ax.set_title(<span class="string">"rf model feature importance top30"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">"feature importance score"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">"feature name"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f.savefig(<span class="string">"./pictures/rf model feature importance top30.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h2 id="使用xgb模型进行训练和预测"><a href="#使用xgb模型进行训练和预测" class="headerlink" title="使用xgb模型进行训练和预测"></a>使用xgb模型进行训练和预测</h2><p>n_estimators=200表示使用200课回归树，nthread=-1表示使用CPU所有线程进行模型拟合和预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># use XGBoost model to train and predict</span></span><br><span class="line">print(<span class="string">"use XGBoost model to train and predict"</span>)</span><br><span class="line">xgb = XGBClassifier(n_estimators=<span class="number">200</span>, nthread=<span class="number">-1</span>)</span><br><span class="line">xgb.fit(x_train_sm_np, y_train_sm_np)</span><br><span class="line">xgb_y_pred = xgb.predict(x_test_nom_pd)</span><br><span class="line">xgb_test_acc = accuracy_score(y_test, xgb_y_pred)</span><br><span class="line">xgb_classification_score = classification_report(y_test, xgb_y_pred)</span><br><span class="line">print(<span class="string">"Xgb model test accuracy:&#123;:.4f&#125;"</span>.format(xgb_test_acc))</span><br><span class="line">print(<span class="string">"Xgb model classification_score:\n"</span>, xgb_classification_score)</span><br><span class="line">xgb_confusion_score = confusion_matrix(y_test, xgb_y_pred)</span><br><span class="line"><span class="comment"># print(xgb_confusion_score)</span></span><br><span class="line">f_xgb, ax_xgb = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># 混淆矩阵的y轴为true label,x轴为pred label</span></span><br><span class="line"><span class="comment"># 精确率,如对正类 ,所有预测为正类样本中中真实的正类占所有预测为正类的比例</span></span><br><span class="line"><span class="comment"># 召回率,如对正类,所有真实的正类样本中有多少被预测为正类的比例</span></span><br><span class="line"><span class="comment"># 分别计算预测预测的正样本数和负样本数以及真实的正样本数和负样本数</span></span><br><span class="line">xgb_cm_pred_label_sum = xgb_confusion_score.sum(axis=<span class="number">0</span>)</span><br><span class="line">xgb_cm_true_label_sum = xgb_confusion_score.sum(axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># print(xgb_cm_pred_label_sum,xgb_cm_true_label_sum)</span></span><br><span class="line"><span class="comment"># 计算正样本和负样本的精确率和召回率</span></span><br><span class="line">xgb_model_precision, xgb_model_recall = np.empty([<span class="number">2</span>, <span class="number">2</span>], dtype=float), np.empty([<span class="number">2</span>, <span class="number">2</span>], dtype=float)</span><br><span class="line">xgb_model_precision[<span class="number">0</span>][<span class="number">0</span>], xgb_model_precision[<span class="number">1</span>][<span class="number">0</span>] = xgb_confusion_score[<span class="number">0</span>][<span class="number">0</span>] / xgb_cm_pred_label_sum[<span class="number">0</span>], \</span><br><span class="line">                                                       xgb_confusion_score[<span class="number">1</span>][<span class="number">0</span>] / xgb_cm_pred_label_sum[<span class="number">0</span>]</span><br><span class="line">xgb_model_precision[<span class="number">0</span>][<span class="number">1</span>], xgb_model_precision[<span class="number">1</span>][<span class="number">1</span>] = xgb_confusion_score[<span class="number">0</span>][<span class="number">1</span>] / xgb_cm_pred_label_sum[<span class="number">1</span>], \</span><br><span class="line">                                                       xgb_confusion_score[<span class="number">1</span>][<span class="number">1</span>] / xgb_cm_pred_label_sum[<span class="number">1</span>]</span><br><span class="line">xgb_model_recall[<span class="number">0</span>][<span class="number">0</span>], xgb_model_recall[<span class="number">0</span>][<span class="number">1</span>] = xgb_confusion_score[<span class="number">0</span>][<span class="number">0</span>] / xgb_cm_true_label_sum[<span class="number">0</span>], \</span><br><span class="line">                                                 xgb_confusion_score[<span class="number">0</span>][<span class="number">1</span>] / xgb_cm_true_label_sum[<span class="number">0</span>]</span><br><span class="line">xgb_model_recall[<span class="number">1</span>][<span class="number">0</span>], xgb_model_recall[<span class="number">1</span>][<span class="number">1</span>] = xgb_confusion_score[<span class="number">1</span>][<span class="number">0</span>] / xgb_cm_true_label_sum[<span class="number">1</span>], \</span><br><span class="line">                                                 xgb_confusion_score[<span class="number">1</span>][<span class="number">1</span>] / xgb_cm_true_label_sum[<span class="number">1</span>]</span><br><span class="line">sns.heatmap(xgb_confusion_score, annot=<span class="literal">True</span>, fmt=<span class="string">"d"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_xgb[<span class="number">0</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">sns.heatmap(xgb_model_precision, annot=<span class="literal">True</span>, fmt=<span class="string">".5f"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_xgb[<span class="number">1</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">sns.heatmap(xgb_model_recall, annot=<span class="literal">True</span>, fmt=<span class="string">".5f"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_xgb[<span class="number">2</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">ax_xgb[<span class="number">0</span>].set_title(<span class="string">"xgb confusion matrix"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">1</span>].set_title(<span class="string">"xgb model precision"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">2</span>].set_title(<span class="string">"xgb model recall"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">0</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">0</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">1</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">1</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">2</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">2</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_xgb.savefig(<span class="string">"./pictures/xgb model confusion matrix.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"><span class="comment"># Xgb model test accuracy:0.9822</span></span><br><span class="line"><span class="comment"># Xgb model classification_score:</span></span><br><span class="line"><span class="comment">#                precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#          0.0       1.00      0.86      0.93     55318</span></span><br><span class="line"><span class="comment">#          1.0       0.98      1.00      0.99    372097</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#    micro avg       0.98      0.98      0.98    427415</span></span><br><span class="line"><span class="comment">#    macro avg       0.99      0.93      0.96    427415</span></span><br><span class="line"><span class="comment"># weighted avg       0.98      0.98      0.98    427415</span></span><br></pre></td></tr></table></figure><p>混淆矩阵从左到右三个子图为xgb模型预测标签/实际标签的样本的数量，xgb模型预测负/正样本的精确率（第二张图左上角和右下角数值），xgb模型预测负/正样本的召回率（第三张图左上角和右下角数值）。<br>xgb模型预测总体准确率0.98，其中正样本预测精确率0.978，但负样本预测精确率0.999。同时正样本预测召回率0.999，负样本召回率0.854。该模型对于负样本（不良贷款）预测的精确率也很高，召回率也相对较好，模型性能略逊于rf模型，但相差很小，该模型也比较适合用来预测。<br><strong>我们还可以画出该模型训练时各特征的贡献度:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xgboost model feature contribution visualization</span></span><br><span class="line">feature_importances = xgb.feature_importances_</span><br><span class="line"><span class="comment"># print(feature_importances)</span></span><br><span class="line"><span class="comment"># y=x.argsort()函数是将x中的元素从小到大排列，提取其对应的index(索引)</span></span><br><span class="line">indices = np.argsort(feature_importances)[::<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># 只取贡献度最高的30个特征来作图</span></span><br><span class="line">show_indices = indices[<span class="number">0</span>:<span class="number">30</span>]</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f, ax = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.barplot(x=feature_importances[show_indices], y=feature_names[show_indices], ax=ax)</span><br><span class="line">ax.set_title(<span class="string">"xgb model feature importance top30"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">"feature importance score"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">"feature name"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f.savefig(<span class="string">"./pictures/xgb model feature importance top30.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><h1 id="完整本地运行代码"><a href="#完整本地运行代码" class="headerlink" title="完整本地运行代码"></a>完整本地运行代码</h1><p>包含data_visualization.py和model_training_and_testing.py两个文件。<br>data_visualization.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> plotly</span><br><span class="line"><span class="keyword">import</span> plotly.plotly <span class="keyword">as</span> py</span><br><span class="line"><span class="keyword">import</span> plotly.graph_objs <span class="keyword">as</span> go</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Bar3D, Line3D</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.simplefilter(action=<span class="string">"ignore"</span>, category=FutureWarning)</span><br><span class="line">warnings.simplefilter(action=<span class="string">"ignore"</span>, category=DeprecationWarning)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This is my free plotly account,this account allows up to 100 images to be generated every 24 hours.Please use your own plotly account.</span></span><br><span class="line">plotly.tools.set_credentials_file(username=<span class="string">"zgcr"</span>, api_key=<span class="string">"GQW92qmUOFbZmTQwQtJ1"</span>)</span><br><span class="line">plotly.tools.set_config_file(world_readable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data preprocessing before Data analysis visualization</span></span><br><span class="line">loan_data = pd.read_csv(<span class="string">"loan.csv"</span>, low_memory=<span class="literal">False</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># (2260668, 145)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate the missing value percent of features</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_missing_data_table</span><span class="params">(data)</span>:</span></span><br><span class="line">total = data.isnull().sum().sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">percent = (data.isnull().sum() / data.shape[<span class="number">0</span>]).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">missing_data = pd.concat([total, percent], axis=<span class="number">1</span>, keys=[<span class="string">"Total"</span>, <span class="string">"Percent"</span>])</span><br><span class="line">missing_data.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line">missing_data.rename(columns=&#123;<span class="string">"index"</span>: <span class="string">"feature_name"</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> missing_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># save missing value percent of features</span></span><br><span class="line">missing_data_count = draw_missing_data_table(loan_data)</span><br><span class="line">missing_data_count.to_csv(<span class="string">"missing_data_count.csv"</span>)</span><br><span class="line">missing_data_count = pd.read_csv(<span class="string">"missing_data_count.csv"</span>, header=<span class="number">0</span>, index_col=<span class="number">0</span>)</span><br><span class="line">missing_data_count = missing_data_count[missing_data_count[<span class="string">"Percent"</span>] &gt; <span class="number">0.0</span>]</span><br><span class="line">print(missing_data_count.head())</span><br><span class="line"><span class="comment">#                                  feature_name    Total   Percent</span></span><br><span class="line"><span class="comment"># 0                                          id  2260668  1.000000</span></span><br><span class="line"><span class="comment"># 1                                   member_id  2260668  1.000000</span></span><br><span class="line"><span class="comment"># 2                                         url  2260668  1.000000</span></span><br><span class="line"><span class="comment"># 3  orig_projected_additional_accrued_interest  2252242  0.996273</span></span><br><span class="line"><span class="comment"># 4                         hardship_start_date  2250055  0.995305</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># draw a graph of missing value percent of features(percent&gt;0.03)</span></span><br><span class="line">missing_data_count_show = missing_data_count[missing_data_count[<span class="string">"Percent"</span>] &gt; <span class="number">0.03</span>]</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f, ax = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.barplot(x=missing_data_count_show[<span class="string">"Percent"</span>], y=missing_data_count_show[<span class="string">"feature_name"</span>], ax=ax)</span><br><span class="line">ax.set_title(<span class="string">"Missing value percent for each feature"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">"missing percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">"feature name"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f.savefig(<span class="string">"./pictures/Missing value percent for each feature.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># delete features that missing value percent more than 0.15</span></span><br><span class="line"><span class="keyword">for</span> index, feature_count_null <span class="keyword">in</span> missing_data_count.iterrows():</span><br><span class="line"><span class="keyword">if</span> feature_count_null[<span class="string">"Percent"</span>] &gt; <span class="number">0.15</span>:</span><br><span class="line">drop_feature_name = feature_count_null[<span class="string">"feature_name"</span>]</span><br><span class="line">loan_data.drop([drop_feature_name], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">missing_data_count = missing_data_count[missing_data_count[<span class="string">"Percent"</span>] &lt;= <span class="number">0.15</span>]</span><br><span class="line">print(missing_data_count.head())</span><br><span class="line"><span class="comment">#              feature_name   Total   Percent</span></span><br><span class="line"><span class="comment"># 58  mths_since_recent_inq  295435  0.130685</span></span><br><span class="line"><span class="comment"># 59              emp_title  166969  0.073858</span></span><br><span class="line"><span class="comment"># 60       num_tl_120dpd_2m  153657  0.067970</span></span><br><span class="line"><span class="comment"># 61             emp_length  146907  0.064984</span></span><br><span class="line"><span class="comment"># 62     mo_sin_old_il_acct  139071  0.061518</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># delete rows which contain missing value for features that  missing value precent less than 0.04</span></span><br><span class="line"><span class="keyword">for</span> index, feature_count_null <span class="keyword">in</span> missing_data_count.iterrows():</span><br><span class="line"><span class="keyword">if</span> feature_count_null[<span class="string">"Percent"</span>] &lt; <span class="number">0.04</span>:</span><br><span class="line">drop_feature_name = feature_count_null[<span class="string">"feature_name"</span>]</span><br><span class="line">drop_index = loan_data[loan_data[drop_feature_name].isnull().values == <span class="literal">True</span>].index</span><br><span class="line">loan_data.drop(index=drop_index, axis=<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment"># (2137073, 87)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate the missing value percent of features again,save missing value percent of features</span></span><br><span class="line">missing_data_count_2 = draw_missing_data_table(loan_data)</span><br><span class="line">missing_data_count_2.to_csv(<span class="string">"missing_data_count_2.csv"</span>)</span><br><span class="line">missing_data_count_2 = missing_data_count_2[missing_data_count_2[<span class="string">"Percent"</span>] &gt; <span class="number">0.0</span>]</span><br><span class="line">print(missing_data_count_2)</span><br><span class="line"><span class="comment">#             feature_name   Total   Percent</span></span><br><span class="line"><span class="comment"># 0  mths_since_recent_inq  235741  0.110310</span></span><br><span class="line"><span class="comment"># 1              emp_title  154722  0.072399</span></span><br><span class="line"><span class="comment"># 2             emp_length  137175  0.064188</span></span><br><span class="line"><span class="comment"># 3       num_tl_120dpd_2m   81243  0.038016</span></span><br><span class="line"><span class="comment"># 4     mo_sin_old_il_acct   66915  0.031312</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># fill missing value of mths_since_recent_inq/num_tl_120dpd_2m/mo_sin_old_il_acct by mean value of each feature</span></span><br><span class="line"><span class="comment"># don"t fill emp_title and emp_length</span></span><br><span class="line">loan_data[<span class="string">"mths_since_recent_inq"</span>].fillna(loan_data[<span class="string">"mths_since_recent_inq"</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line">loan_data[<span class="string">"num_tl_120dpd_2m"</span>].fillna(loan_data[<span class="string">"num_tl_120dpd_2m"</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line">loan_data[<span class="string">"mo_sin_old_il_acct"</span>].fillna(loan_data[<span class="string">"mo_sin_old_il_acct"</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Convert the value of feature:"term" from category to numeric</span></span><br><span class="line">term_dict = &#123;<span class="string">" 36 months"</span>: <span class="number">36</span>, <span class="string">" 60 months"</span>: <span class="number">60</span>&#125;</span><br><span class="line">loan_data[<span class="string">"term"</span>] = loan_data[<span class="string">"term"</span>].map(term_dict)</span><br><span class="line">loan_data[<span class="string">"term"</span>] = loan_data[<span class="string">"term"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate the missing value percent of features the three times,save missing value percent of features</span></span><br><span class="line">missing_data_count_3 = draw_missing_data_table(loan_data)</span><br><span class="line">missing_data_count_3.to_csv(<span class="string">"missing_data_count_3.csv"</span>)</span><br><span class="line">missing_data_count_3 = missing_data_count_3[missing_data_count_3[<span class="string">"Percent"</span>] &gt; <span class="number">0.0</span>]</span><br><span class="line">print(missing_data_count_3)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment">#   feature_name   Total   Percent</span></span><br><span class="line"><span class="comment"># 0    emp_title  154722  0.072399</span></span><br><span class="line"><span class="comment"># 1   emp_length  137175  0.064188</span></span><br><span class="line"><span class="comment"># (2137073, 87)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># save the dataset after all missing value operation</span></span><br><span class="line">loan_data.to_csv(<span class="string">"loan_clean_data.csv"</span>, index=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># loan_data = pd.read_csv("loan_clean_data.csv", low_memory=False)</span></span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment"># (2137073, 87)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Data analysis visualization</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># seaborn has five themes:darkgrid(灰色网格)\whitegrid(白色网格)\dark(黑色)\white(白色)\ticks(十字叉)</span></span><br><span class="line"><span class="comment"># Palette has those options:"muted"\"RdBu"\"RdBu_r"\"Blues_d"\"Set1"\"husl"</span></span><br><span class="line"><span class="comment"># plotly only supports world maps,the United States maps</span></span><br><span class="line"><span class="comment"># pyechart only supports world maps and China maps</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Data distribution of the loan amount and actual loan amount</span></span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan, ax_loan = plt.subplots(<span class="number">2</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.distplot(loan_data[<span class="string">"loan_amnt"</span>], ax=ax_loan[<span class="number">0</span>, <span class="number">0</span>], color=<span class="string">"#F7522F"</span>)</span><br><span class="line">sns.violinplot(y=loan_data[<span class="string">"loan_amnt"</span>], ax=ax_loan[<span class="number">0</span>, <span class="number">1</span>], inner=<span class="string">"quartile"</span>, palette=<span class="string">"Reds"</span>)</span><br><span class="line">sns.distplot(loan_data[<span class="string">"funded_amnt"</span>], ax=ax_loan[<span class="number">1</span>, <span class="number">0</span>], color=<span class="string">"#2F8FF7"</span>)</span><br><span class="line">sns.violinplot(y=loan_data[<span class="string">"funded_amnt"</span>], ax=ax_loan[<span class="number">1</span>, <span class="number">1</span>], inner=<span class="string">"quartile"</span>, palette=<span class="string">"Blues"</span>)</span><br><span class="line">ax_loan[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">"Loan amount distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">"Loan amount distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">"Funded amount distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">1</span>, <span class="number">1</span>].set_title(<span class="string">"Funded amount distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">0</span>, <span class="number">0</span>].set_xlabel(<span class="string">"loan amount"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">1</span>, <span class="number">0</span>].set_xlabel(<span class="string">"loan amount"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">0</span>, <span class="number">1</span>].set_ylabel(<span class="string">"loan amount"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan[<span class="number">1</span>, <span class="number">1</span>].set_ylabel(<span class="string">"loan amount"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_loan.savefig(<span class="string">"./pictures/Loan amount and funded amount distribution.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># histogram of annual loan figures and histogram of total amount of annual loan lending</span></span><br><span class="line">loan_data[<span class="string">"year"</span>] = pd.to_datetime(loan_data[<span class="string">"issue_d"</span>]).dt.year</span><br><span class="line">loan_year_num = loan_data[<span class="string">"year"</span>].value_counts().to_dict()</span><br><span class="line">loan_year_num_pd = pd.DataFrame(list(loan_year_num.items()), columns=[<span class="string">"year"</span>, <span class="string">"loan times"</span>])</span><br><span class="line">loan_year_num_pd.sort_values(<span class="string">"year"</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(loan_year_num_pd)</span></span><br><span class="line">loan_data[<span class="string">"year"</span>] = pd.to_datetime(loan_data[<span class="string">"issue_d"</span>]).dt.year</span><br><span class="line">loan_money_count_per_year = loan_data.groupby(<span class="string">"year"</span>)[<span class="string">"loan_amnt"</span>].sum().to_dict()</span><br><span class="line">loan_money_count_per_year_pd = pd.DataFrame(list(loan_money_count_per_year.items()), columns=[<span class="string">"year"</span>, <span class="string">"loan_amnt"</span>])</span><br><span class="line">loan_money_count_per_year_pd.sort_values(<span class="string">"year"</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(loan_money_count_per_year_pd)</span></span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan_per_year, ax_loan_per_year = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.barplot(loan_year_num_pd[<span class="string">"year"</span>], loan_year_num_pd[<span class="string">"loan times"</span>], ax=ax_loan_per_year[<span class="number">0</span>],</span><br><span class="line">            palette=<span class="string">"tab10"</span>)</span><br><span class="line">sns.barplot(loan_money_count_per_year_pd[<span class="string">"year"</span>], loan_money_count_per_year_pd[<span class="string">"loan_amnt"</span>], ax=ax_loan_per_year[<span class="number">1</span>],</span><br><span class="line">            palette=<span class="string">"tab10"</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">0</span>].set_title(<span class="string">"loan times per year"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">1</span>].set_title(<span class="string">"Loan amount per year"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">0</span>].set_xlabel(<span class="string">"year"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">0</span>].set_ylabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">1</span>].set_xlabel(<span class="string">"year"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_per_year[<span class="number">1</span>].set_ylabel(<span class="string">"loan amount"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"year"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># (2137073, 87)</span></span><br><span class="line">f_loan_per_year.savefig(<span class="string">"./pictures/loan times and loan amount per year.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># # 各年各月每笔贷款平均贷款金额3D柱状图和3D折线图</span></span><br><span class="line"><span class="comment"># loan_data["month"], loan_data["year"] = loan_data["issue_d"].str.split("-", 1).str</span></span><br><span class="line"><span class="comment"># months_list = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]</span></span><br><span class="line"><span class="comment"># years_list = ["2012", "2013", "2014", "2015", "2016", "2017", "2018"]</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_dict = loan_data.groupby(["month", "year"])["loan_amnt"].mean().to_dict()</span></span><br><span class="line"><span class="comment"># # print(loan_amnt_per_year_per_month_dict)</span></span><br><span class="line"><span class="comment"># max_value = max(mean_loan_amnt_per_year_per_month_dict.values())</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_list = []</span></span><br><span class="line"><span class="comment"># for key, value in mean_loan_amnt_per_year_per_month_dict.items():</span></span><br><span class="line"><span class="comment"># temp = [key[0], key[1], value]</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_list.append(temp)</span></span><br><span class="line"><span class="comment"># # print(loan_amnt_per_year_per_month_list)</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_bar3d = Bar3D("每月贷款金额3D柱状图", width=1500, height=1000)</span></span><br><span class="line"><span class="comment"># range_color = ["#313695", "#4575b4", "#74add1", "#abd9e9", "#e0f3f8", "#ffffbf", "#fee090", "#fdae61", "#f46d43",</span></span><br><span class="line"><span class="comment">#                "#d73027", "#a50026"]</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_bar3d.add("mean loan amnt per year per month bar3D", x_axis=months_list, y_axis=years_list,</span></span><br><span class="line"><span class="comment">#                                             data=mean_loan_amnt_per_year_per_month_list,</span></span><br><span class="line"><span class="comment">#                                             is_visualmap=True, visual_range=[0, max_value], visual_range_color=range_color,</span></span><br><span class="line"><span class="comment">#                                             grid3d_width=200, grid3d_height=100, grid3d_depth=80)</span></span><br><span class="line"><span class="comment"># # 3D图不能保存为png格式</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_bar3d.render(path="./pictures/mean loan amnt per year per month bar3D.html")</span></span><br><span class="line"><span class="comment"># months_to_num_dict = &#123;"Jan": 1, "Feb": 2, "Mar": 3, "Apr": 4, "May": 5, "Jun": 6, "Jul": 7, "Aug": 8, "Sep": 9,</span></span><br><span class="line"><span class="comment">#                       "Oct": 10, "Nov": 11, "Dec": 12&#125;</span></span><br><span class="line"><span class="comment"># for item in mean_loan_amnt_per_year_per_month_list:</span></span><br><span class="line"><span class="comment"># item[0], item[1] = months_to_num_dict[item[0]], int(item[1])</span></span><br><span class="line"><span class="comment"># # 画折线图时按照给定数据的输入顺序连线,所以我们要对列表先按月再按年从小到大排序</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_list.sort(key=lambda x: x[0])</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_list.sort(key=lambda x: x[1])</span></span><br><span class="line"><span class="comment"># colorscale = ["#9ecae1", "#85bcdb", "#6baed6", "#57a0ce", "#4292c6", "#3082be", "#2171b5", "#1361a9", "#08519c",</span></span><br><span class="line"><span class="comment">#               "#0b4083", "#08306b"]</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_line3d = Line3D("每月贷款金额变化3D折线图", width=1500, height=1000)</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_line3d.add("mean loan amnt per year per month line3D",</span></span><br><span class="line"><span class="comment">#                                              data=mean_loan_amnt_per_year_per_month_list,</span></span><br><span class="line"><span class="comment">#                                              yaxis3d_min=2012, yaxis3d_max=2018,</span></span><br><span class="line"><span class="comment">#                                              is_visualmap=True, visual_range=[0, max_value], visual_range_color=colorscale,</span></span><br><span class="line"><span class="comment">#                                              grid3d_width=200, grid3d_height=100, grid3d_depth=80)</span></span><br><span class="line"><span class="comment"># # 3D图不能保存为png格式</span></span><br><span class="line"><span class="comment"># mean_loan_amnt_per_year_per_month_line3d.render(path="./pictures/mean loan amnt per year per month line3D.html")</span></span><br><span class="line"><span class="comment"># loan_data.drop(["month","year"], axis=1, inplace=True)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 各年各月贷款笔数3D柱状图和3D折线图</span></span><br><span class="line"><span class="comment"># loan_data["month"], loan_data["year"] = loan_data["issue_d"].str.split("-", 1).str</span></span><br><span class="line"><span class="comment"># # print(loan_data["month"].value_counts())</span></span><br><span class="line"><span class="comment"># # print(loan_data["year"].value_counts())</span></span><br><span class="line"><span class="comment"># months_list = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]</span></span><br><span class="line"><span class="comment"># years_list = ["2012", "2013", "2014", "2015", "2016", "2017", "2018"]</span></span><br><span class="line"><span class="comment"># loan_times_per_year_num_dict = loan_data.groupby(["month"])["year"].value_counts().to_dict()</span></span><br><span class="line"><span class="comment"># max_value = max(loan_times_per_year_num_dict.values())</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_num_list = []</span></span><br><span class="line"><span class="comment"># for key, value in loan_times_per_year_num_dict.items():</span></span><br><span class="line"><span class="comment"># temp = [key[0], key[1], value]</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_num_list.append(temp)</span></span><br><span class="line"><span class="comment"># # print(loan_per_month_per_year_num_list)</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_bar3d = Bar3D("每月贷款笔数3D柱状图", width=1500, height=1000)</span></span><br><span class="line"><span class="comment"># range_color = ["#313695", "#4575b4", "#74add1", "#abd9e9", "#e0f3f8", "#ffffbf", "#fee090", "#fdae61", "#f46d43",</span></span><br><span class="line"><span class="comment">#                "#d73027", "#a50026"]</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_bar3d.add("loan times per month per year bar3D", x_axis=months_list, y_axis=years_list,</span></span><br><span class="line"><span class="comment">#                                         data=loan_times_per_month_per_year_num_list,</span></span><br><span class="line"><span class="comment">#                                         is_visualmap=True, visual_range=[0, max_value], visual_range_color=range_color,</span></span><br><span class="line"><span class="comment">#                                         grid3d_width=200, grid3d_height=100, grid3d_depth=80)</span></span><br><span class="line"><span class="comment"># # 3D图不能保存为png格式</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_bar3d.render(path="./pictures/loan times per month per year bar3D.html")</span></span><br><span class="line"><span class="comment"># months_to_num_dict = &#123;"Jan": 1, "Feb": 2, "Mar": 3, "Apr": 4, "May": 5, "Jun": 6, "Jul": 7, "Aug": 8, "Sep": 9,</span></span><br><span class="line"><span class="comment">#                       "Oct": 10, "Nov": 11, "Dec": 12&#125;</span></span><br><span class="line"><span class="comment"># for item in loan_times_per_month_per_year_num_list:</span></span><br><span class="line"><span class="comment"># item[0], item[1] = months_to_num_dict[item[0]], int(item[1])</span></span><br><span class="line"><span class="comment"># # 画折线图时按照给定数据的输入顺序连线,所以我们要对列表先按月再按年从小到大排序</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_num_list.sort(key=lambda x: x[0])</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_num_list.sort(key=lambda x: x[1])</span></span><br><span class="line"><span class="comment"># # print(loan_times_per_month_per_year_num_list)</span></span><br><span class="line"><span class="comment"># # loan_times_per_month_per_year_num_list=[[8, 2012, 894], [9, 2012, 5924], [10, 2012, 6192], [11, 2012, 6312], [12, 2012, 6006], [1, 2013, 6814], [2, 2013, 7506], [3, 2013, 8199], [4, 2013, 9354], [5, 2013, 10285], [6, 2013, 10815], [7, 2013, 11816], [8, 2013, 12562], [9, 2013, 12866], [10, 2013, 13858], [11, 2013, 14561], [12, 2013, 14854], [1, 2014, 15470], [2, 2014, 15111], [3, 2014, 16296], [4, 2014, 18829], [5, 2014, 18870], [6, 2014, 16996], [7, 2014, 28948], [8, 2014, 18632], [9, 2014, 10498], [10, 2014, 38244], [11, 2014, 24679], [12, 2014, 10173], [1, 2015, 34691], [2, 2015, 23474], [3, 2015, 25123], [4, 2015, 35052], [5, 2015, 31547], [6, 2015, 28170], [7, 2015, 45446], [8, 2015, 35469], [9, 2015, 28343], [10, 2015, 48064], [11, 2015, 37084], [12, 2015, 43702], [1, 2016, 29548], [2, 2016, 35778], [3, 2016, 56707], [4, 2016, 33093], [5, 2016, 25975], [6, 2016, 30512], [7, 2016, 32575], [8, 2016, 33488], [9, 2016, 26432], [10, 2016, 32318], [11, 2016, 34068], [12, 2016, 35618], [1, 2017, 31435], [2, 2017, 27418], [3, 2017, 36754], [4, 2017, 29270], [5, 2017, 37245], [6, 2017, 37548], [7, 2017, 38784], [8, 2017, 42765], [9, 2017, 38988], [10, 2017, 37434], [11, 2017, 41513], [12, 2017, 37376], [1, 2018, 35718], [2, 2018, 32126], [3, 2018, 38054], [4, 2018, 42177], [5, 2018, 45489], [6, 2018, 40821], [7, 2018, 42372], [8, 2018, 45298], [9, 2018, 38380], [10, 2018, 45540], [11, 2018, 41247], [12, 2018, 39480]]</span></span><br><span class="line"><span class="comment"># colorscale = ["#9ecae1", "#85bcdb", "#6baed6", "#57a0ce", "#4292c6", "#3082be", "#2171b5", "#1361a9", "#08519c",</span></span><br><span class="line"><span class="comment">#               "#0b4083", "#08306b"]</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_line3d = Line3D("每月贷款笔数变化3D折线图", width=1500, height=1000)</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_line3d.add("loan times per month per year line3D",</span></span><br><span class="line"><span class="comment">#                                          data=loan_times_per_month_per_year_num_list,</span></span><br><span class="line"><span class="comment">#                                          yaxis3d_min=2012, yaxis3d_max=2018,</span></span><br><span class="line"><span class="comment">#                                          is_visualmap=True, visual_range=[0, max_value], visual_range_color=colorscale,</span></span><br><span class="line"><span class="comment">#                                          grid3d_width=200, grid3d_height=100, grid3d_depth=80)</span></span><br><span class="line"><span class="comment"># # 3D图不能保存为png格式</span></span><br><span class="line"><span class="comment"># loan_times_per_month_per_year_line3d.render(path="./pictures/loan times per month per year line3D.html")</span></span><br><span class="line"><span class="comment"># loan_data.drop(["month","year"], axis=1, inplace=True)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># the map of geographical coordinates of each state"s loan figures</span></span><br><span class="line"><span class="comment"># addr_state即申请贷款的人的所属州,是两位代码,可以被plotly识别</span></span><br><span class="line">code_and_name_dict = &#123;<span class="string">"AL"</span>: <span class="string">"Alabama"</span>, <span class="string">"AK"</span>: <span class="string">"Alaska"</span>, <span class="string">"AZ"</span>: <span class="string">"Arizona"</span>, <span class="string">"AR"</span>: <span class="string">"Arkansas"</span>, <span class="string">"CA"</span>: <span class="string">"California"</span>,</span><br><span class="line">                      <span class="string">"CO"</span>: <span class="string">"Colorado"</span>, <span class="string">"CT"</span>: <span class="string">"Connecticut"</span>, <span class="string">"DC"</span>: <span class="string">"District of Columbia"</span>, <span class="string">"DE"</span>: <span class="string">"Delaware"</span>,</span><br><span class="line">                      <span class="string">"FL"</span>: <span class="string">"Florida"</span>, <span class="string">"GA"</span>: <span class="string">"Georgia"</span>, <span class="string">"HI"</span>: <span class="string">"Hawaii"</span>, <span class="string">"ID"</span>: <span class="string">"Idaho"</span>, <span class="string">"IL"</span>: <span class="string">"Illinois"</span>,</span><br><span class="line">                      <span class="string">"IN"</span>: <span class="string">"Indiana"</span>, <span class="string">"IA"</span>: <span class="string">"Iowa"</span>, <span class="string">"KS"</span>: <span class="string">"Kansas"</span>, <span class="string">"KY"</span>: <span class="string">"Kentucky"</span>, <span class="string">"LA"</span>: <span class="string">"Louisiana"</span>, <span class="string">"ME"</span>: <span class="string">"Maine"</span>,</span><br><span class="line">                      <span class="string">"MD"</span>: <span class="string">"Maryland"</span>, <span class="string">"MA"</span>: <span class="string">"Massachusetts"</span>, <span class="string">"MI"</span>: <span class="string">"Michigan"</span>, <span class="string">"MN"</span>: <span class="string">"Minnesota"</span>, <span class="string">"MS"</span>: <span class="string">"Mississippi"</span>,</span><br><span class="line">                      <span class="string">"MO"</span>: <span class="string">"Missouri"</span>, <span class="string">"MT"</span>: <span class="string">"Montana"</span>, <span class="string">"NE"</span>: <span class="string">"Nebraska"</span>, <span class="string">"NV"</span>: <span class="string">"Nevada"</span>, <span class="string">"NH"</span>: <span class="string">"New Hampshire"</span>,</span><br><span class="line">                      <span class="string">"NJ"</span>: <span class="string">"New Jersey"</span>, <span class="string">"NM"</span>: <span class="string">"New Mexico"</span>, <span class="string">"NY"</span>: <span class="string">"New York"</span>, <span class="string">"NC"</span>: <span class="string">"North Carolina"</span>,</span><br><span class="line">                      <span class="string">"ND"</span>: <span class="string">"North Dakota"</span>, <span class="string">"OH"</span>: <span class="string">"Ohio"</span>, <span class="string">"OK"</span>: <span class="string">"Oklahoma"</span>, <span class="string">"OR"</span>: <span class="string">"Oregon"</span>, <span class="string">"PA"</span>: <span class="string">"Pennsylvania"</span>,</span><br><span class="line">                      <span class="string">"RI"</span>: <span class="string">"Rhode Island"</span>, <span class="string">"SC"</span>: <span class="string">"South Carolina"</span>, <span class="string">"SD"</span>: <span class="string">"South Dakota"</span>, <span class="string">"TN"</span>: <span class="string">"Tennessee"</span>,</span><br><span class="line">                      <span class="string">"TX"</span>: <span class="string">"Texas"</span>, <span class="string">"UT"</span>: <span class="string">"Utah"</span>, <span class="string">"VT"</span>: <span class="string">"Vermont"</span>, <span class="string">"VA"</span>: <span class="string">"Virginia"</span>, <span class="string">"WA"</span>: <span class="string">"Washington"</span>,</span><br><span class="line">                      <span class="string">"WV"</span>: <span class="string">"West Virginia"</span>, <span class="string">"WI"</span>: <span class="string">"Wisconsin"</span>, <span class="string">"WY"</span>: <span class="string">"Wyoming"</span>&#125;</span><br><span class="line">loan_times_per_state = loan_data[<span class="string">"addr_state"</span>].value_counts().to_dict()</span><br><span class="line">loan_times_per_state_pd = pd.DataFrame(list(loan_times_per_state.items()), columns=[<span class="string">"state_code"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line">loan_times_per_state_pd[<span class="string">"state_name"</span>] = <span class="literal">None</span></span><br><span class="line"><span class="comment"># print(loan_times_per_state_pd)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(loan_times_per_state_pd.shape[<span class="number">0</span>]):</span><br><span class="line">state_name = code_and_name_dict[loan_times_per_state_pd.ix[i, <span class="string">"state_code"</span>]]</span><br><span class="line">loan_times_per_state_pd.ix[i, <span class="string">"state_name"</span>] = state_name</span><br><span class="line"><span class="comment"># print(loan_times_per_state_pd)</span></span><br><span class="line"><span class="comment"># 设立颜色条色彩渐变颜色</span></span><br><span class="line"><span class="comment"># colorscale可选项:["Greys", "YlGnBu", "Greens", "YlOrRd", "Bluered", "RdBu","Reds", "Blues", "Picnic", "Rainbow",</span></span><br><span class="line"><span class="comment"># "Portland", "Jet","Hot", "Blackbody", "Earth", "Electric", "Viridis", "Cividis"]</span></span><br><span class="line">colorscale = <span class="string">"Blues"</span></span><br><span class="line"><span class="comment"># colorbar为颜色条注释,位置由各州的编号，即缩写表示,z值越高颜色越深</span></span><br><span class="line">data = [dict(type=<span class="string">"choropleth"</span>, colorscale=colorscale, autocolorscale=<span class="literal">False</span>, reversescale=<span class="literal">True</span>,</span><br><span class="line">             locations=loan_times_per_state_pd[<span class="string">"state_code"</span>], z=loan_times_per_state_pd[<span class="string">"loan_times"</span>].astype(float),</span><br><span class="line">             locationmode=<span class="string">"USA-states"</span>, text=loan_times_per_state_pd[<span class="string">"state_name"</span>],</span><br><span class="line">             marker=dict(line=dict(color=<span class="string">"rgb(255,255,255)"</span>, width=<span class="number">2</span>)),</span><br><span class="line">             colorbar=dict(title=<span class="string">"loan times"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">32</span>)))]</span><br><span class="line">layout = dict(title=<span class="string">"loan times per state map"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">50</span>),</span><br><span class="line">              geo=dict(scope=<span class="string">"usa"</span>, projection=dict(type=<span class="string">"albers usa"</span>)))</span><br><span class="line">fig = dict(data=data, layout=layout)</span><br><span class="line"><span class="comment"># filename为网站上个人空间中保存的文件名</span></span><br><span class="line">py.plot(fig, filename=<span class="string">"loan times per state map"</span>, auto_open=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># filename为本地保存的文件名,plotly本地保存只支持png,svg,jpeg,pdf</span></span><br><span class="line">py.image.save_as(fig, filename=<span class="string">"./pictures/loan times per state map.png"</span>, width=<span class="number">2500</span>, height=<span class="number">1500</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Histogram of each state"s loan figures (the top 30 states with the largest number of loans)</span></span><br><span class="line">code_and_name_dict = &#123;<span class="string">"AL"</span>: <span class="string">"Alabama"</span>, <span class="string">"AK"</span>: <span class="string">"Alaska"</span>, <span class="string">"AZ"</span>: <span class="string">"Arizona"</span>, <span class="string">"AR"</span>: <span class="string">"Arkansas"</span>, <span class="string">"CA"</span>: <span class="string">"California"</span>,</span><br><span class="line">                      <span class="string">"CO"</span>: <span class="string">"Colorado"</span>, <span class="string">"CT"</span>: <span class="string">"Connecticut"</span>, <span class="string">"DC"</span>: <span class="string">"District of Columbia"</span>, <span class="string">"DE"</span>: <span class="string">"Delaware"</span>,</span><br><span class="line">                      <span class="string">"FL"</span>: <span class="string">"Florida"</span>, <span class="string">"GA"</span>: <span class="string">"Georgia"</span>, <span class="string">"HI"</span>: <span class="string">"Hawaii"</span>, <span class="string">"ID"</span>: <span class="string">"Idaho"</span>, <span class="string">"IL"</span>: <span class="string">"Illinois"</span>,</span><br><span class="line">                      <span class="string">"IN"</span>: <span class="string">"Indiana"</span>, <span class="string">"IA"</span>: <span class="string">"Iowa"</span>, <span class="string">"KS"</span>: <span class="string">"Kansas"</span>, <span class="string">"KY"</span>: <span class="string">"Kentucky"</span>, <span class="string">"LA"</span>: <span class="string">"Louisiana"</span>, <span class="string">"ME"</span>: <span class="string">"Maine"</span>,</span><br><span class="line">                      <span class="string">"MD"</span>: <span class="string">"Maryland"</span>, <span class="string">"MA"</span>: <span class="string">"Massachusetts"</span>, <span class="string">"MI"</span>: <span class="string">"Michigan"</span>, <span class="string">"MN"</span>: <span class="string">"Minnesota"</span>, <span class="string">"MS"</span>: <span class="string">"Mississippi"</span>,</span><br><span class="line">                      <span class="string">"MO"</span>: <span class="string">"Missouri"</span>, <span class="string">"MT"</span>: <span class="string">"Montana"</span>, <span class="string">"NE"</span>: <span class="string">"Nebraska"</span>, <span class="string">"NV"</span>: <span class="string">"Nevada"</span>, <span class="string">"NH"</span>: <span class="string">"New Hampshire"</span>,</span><br><span class="line">                      <span class="string">"NJ"</span>: <span class="string">"New Jersey"</span>, <span class="string">"NM"</span>: <span class="string">"New Mexico"</span>, <span class="string">"NY"</span>: <span class="string">"New York"</span>, <span class="string">"NC"</span>: <span class="string">"North Carolina"</span>,</span><br><span class="line">                      <span class="string">"ND"</span>: <span class="string">"North Dakota"</span>, <span class="string">"OH"</span>: <span class="string">"Ohio"</span>, <span class="string">"OK"</span>: <span class="string">"Oklahoma"</span>, <span class="string">"OR"</span>: <span class="string">"Oregon"</span>, <span class="string">"PA"</span>: <span class="string">"Pennsylvania"</span>,</span><br><span class="line">                      <span class="string">"RI"</span>: <span class="string">"Rhode Island"</span>, <span class="string">"SC"</span>: <span class="string">"South Carolina"</span>, <span class="string">"SD"</span>: <span class="string">"South Dakota"</span>, <span class="string">"TN"</span>: <span class="string">"Tennessee"</span>,</span><br><span class="line">                      <span class="string">"TX"</span>: <span class="string">"Texas"</span>, <span class="string">"UT"</span>: <span class="string">"Utah"</span>, <span class="string">"VT"</span>: <span class="string">"Vermont"</span>, <span class="string">"VA"</span>: <span class="string">"Virginia"</span>, <span class="string">"WA"</span>: <span class="string">"Washington"</span>,</span><br><span class="line">                      <span class="string">"WV"</span>: <span class="string">"West Virginia"</span>, <span class="string">"WI"</span>: <span class="string">"Wisconsin"</span>, <span class="string">"WY"</span>: <span class="string">"Wyoming"</span>&#125;</span><br><span class="line">loan_times = loan_data[<span class="string">"addr_state"</span>].value_counts().to_dict()</span><br><span class="line">loan_times_pd = pd.DataFrame(list(loan_times.items()), columns=[<span class="string">"state_code"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line">loan_times_pd[<span class="string">"state_name"</span>] = <span class="literal">None</span></span><br><span class="line"><span class="comment"># print(loan_times_pd)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(loan_times_pd.shape[<span class="number">0</span>]):</span><br><span class="line">state_name = code_and_name_dict[loan_times_pd.ix[i, <span class="string">"state_code"</span>]]</span><br><span class="line">loan_times_pd.ix[i, <span class="string">"state_name"</span>] = state_name</span><br><span class="line"><span class="comment"># print(loan_times_pd)</span></span><br><span class="line">loan_times_pd_30 = loan_times_pd[<span class="number">0</span>:<span class="number">30</span>]</span><br><span class="line">loan_times_pd_30.drop([<span class="string">"state_code"</span>], axis=<span class="number">1</span>)</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan_times_per_state, ax_loan_times_per_state = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># # palette为调色板参数,可选项"muted"\"RdBu"\"RdBu_r"\"Blues_d"\"Set1"\"husl"</span></span><br><span class="line">sns.barplot(loan_times_pd_30[<span class="string">"loan_times"</span>], loan_times_pd_30[<span class="string">"state_name"</span>], ax=ax_loan_times_per_state,</span><br><span class="line">            palette=<span class="string">"tab10"</span>)</span><br><span class="line">ax_loan_times_per_state.set_title(<span class="string">"loan times per state"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_state.set_xlabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_state.set_ylabel(<span class="string">"state name"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_loan_times_per_state.savefig(<span class="string">"./pictures/loan times per state bar.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># histogram of the top 30 profession of loan figures</span></span><br><span class="line">loan_times_title = loan_data[<span class="string">"emp_title"</span>].value_counts().to_dict()</span><br><span class="line">loan_times_title_pd = pd.DataFrame(list(loan_times_title.items()), columns=[<span class="string">"title"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line">loan_times_title_pd_30 = loan_times_title_pd[<span class="number">0</span>:<span class="number">30</span>]</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan_times_per_title, ax_loan_times_per_title = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># # palette为调色板参数,可选项"muted"\"RdBu"\"RdBu_r"\"Blues_d"\"Set1"\"husl"</span></span><br><span class="line">sns.barplot(loan_times_title_pd_30[<span class="string">"loan_times"</span>], loan_times_title_pd_30[<span class="string">"title"</span>], ax=ax_loan_times_per_title,</span><br><span class="line">            palette=<span class="string">"tab10"</span>)</span><br><span class="line">ax_loan_times_per_title.set_title(<span class="string">"loan times per title"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_title.set_xlabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_title.set_ylabel(<span class="string">"title"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_loan_times_per_title.savefig(<span class="string">"./pictures/loan times per title bar.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># histogram of the year of participation in working with loan figures</span></span><br><span class="line">loan_times_length = loan_data[<span class="string">"emp_length"</span>].value_counts().to_dict()</span><br><span class="line"><span class="comment"># print(loan_times_length)</span></span><br><span class="line"><span class="comment"># &#123;"10+ years": 713245, "2 years": 192330, "&lt; 1 year": 179177, "3 years": 170699, "1 year": 139017, "5 years": 130985,</span></span><br><span class="line"><span class="comment"># "4 years": 128027, "6 years": 96294, "7 years": 87537, "8 years": 87182, "9 years": 75405&#125;</span></span><br><span class="line">loan_times_length_pd = pd.DataFrame(list(loan_times_length.items()), columns=[<span class="string">"length"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan_times_per_length, ax_loan_times_per_length = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># palette为调色板参数,可选项"muted"\"RdBu"\"RdBu_r"\"Blues_d"\"Set1"\"husl"</span></span><br><span class="line">sns.barplot(loan_times_length_pd[<span class="string">"length"</span>], loan_times_length_pd[<span class="string">"loan_times"</span>], ax=ax_loan_times_per_length,</span><br><span class="line">            palette=<span class="string">"Blues_d"</span>)</span><br><span class="line">ax_loan_times_per_length.set_title(<span class="string">"loan times per length"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_length.set_xlabel(<span class="string">"worked length"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_length.set_ylabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_loan_times_per_length.savefig(<span class="string">"./pictures/loan times per length bar.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># histogram of the customer"s annual income with loan figures</span></span><br><span class="line"><span class="comment"># 我们将年收入分为三档:20000以下为low，20000-60000为mid，&gt;60000为high</span></span><br><span class="line">max_value = loan_data[<span class="string">"annual_inc"</span>].max() + <span class="number">1.0</span></span><br><span class="line">set_bins = [<span class="number">0.0</span>, <span class="number">20000.0</span>, <span class="number">60000.0</span>, max_value]</span><br><span class="line">set_label = [<span class="string">"low"</span>, <span class="string">"mid"</span>, <span class="string">"high"</span>]</span><br><span class="line">loan_data[<span class="string">"income"</span>] = pd.cut(loan_data[<span class="string">"annual_inc"</span>], bins=set_bins, labels=set_label)</span><br><span class="line">loan_times_income = loan_data[<span class="string">"income"</span>].value_counts().to_dict()</span><br><span class="line"><span class="comment"># print(loan_times_income)</span></span><br><span class="line"><span class="comment"># &#123;"high": 1187055, "mid": 912572, "low": 37443&#125;</span></span><br><span class="line">loan_times_income_pd = pd.DataFrame(list(loan_times_income.items()), columns=[<span class="string">"income"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_loan_times_per_income, ax_loan_times_per_income = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># palette为调色板参数,可选项"muted"\"RdBu"\"RdBu_r"\"Blues_d"\"Set1"\"husl"</span></span><br><span class="line">sns.barplot(loan_times_income_pd[<span class="string">"income"</span>], loan_times_income_pd[<span class="string">"loan_times"</span>], ax=ax_loan_times_per_income,</span><br><span class="line">            palette=<span class="string">"muted"</span>)</span><br><span class="line">ax_loan_times_per_income.set_title(<span class="string">"loan times per income"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_income.set_xlabel(<span class="string">"income"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_times_per_income.set_ylabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"income"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">f_loan_times_per_income.savefig(<span class="string">"./pictures/loan times per income bar.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The ratio of good loans and bad loans for each year</span></span><br><span class="line"><span class="comment"># print(loan_data["loan_status"].value_counts().to_dict())</span></span><br><span class="line"><span class="comment"># &#123;"Fully Paid": 962556, "Current": 899615, "Charged Off": 241514, "Late (31-120 days)": 21051, "In Grace Period": 8701,</span></span><br><span class="line"><span class="comment"># "Late (16-30 days)": 3607, "Default": 29&#125;</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line"><span class="comment"># 用1表示贷款状况良好，用0表示不良贷款</span></span><br><span class="line">loan_data[<span class="string">"loan_status_count"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count"</span>] = loan_data[<span class="string">"loan_status_count"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line"><span class="comment"># print(loan_data["loan_status"].value_counts().to_dict())</span></span><br><span class="line"><span class="comment"># &#123;1.0: 1862171, 0.0: 274902&#125;可以看到正负样本不均衡，在后面我们训练模型预测loan_status时需要注意正负样本不平衡的问题</span></span><br><span class="line">loan_status_count = loan_data[<span class="string">"loan_status_count"</span>].value_counts().to_dict()</span><br><span class="line"><span class="keyword">if</span> <span class="number">0</span> <span class="keyword">not</span> <span class="keyword">in</span> loan_status_count.keys():</span><br><span class="line">loan_status_count[<span class="string">"0"</span>] = <span class="number">0.0</span></span><br><span class="line">count_sum = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> loan_status_count.items():</span><br><span class="line">count_sum += value</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> loan_status_count.items():</span><br><span class="line">value = value / count_sum</span><br><span class="line">loan_status_count[key] = value</span><br><span class="line">loan_status_count_pd = pd.DataFrame(list(loan_status_count.items()), columns=[<span class="string">"loan status"</span>, <span class="string">"count_percent"</span>])</span><br><span class="line"><span class="comment"># print(loan_status_count_pd)</span></span><br><span class="line"><span class="comment">#    loan status  count_percent</span></span><br><span class="line"><span class="comment"># 0          1.0       0.871365</span></span><br><span class="line"><span class="comment"># 1          0.0       0.128635</span></span><br><span class="line">loan_data[<span class="string">"year"</span>] = pd.to_datetime(loan_data[<span class="string">"issue_d"</span>]).dt.year</span><br><span class="line">f_loan_status, ax_loan_status = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">ax_loan_status[<span class="number">0</span>].pie(loan_status_count_pd[<span class="string">"count_percent"</span>], autopct=<span class="string">"%1.2f%%"</span>, shadow=<span class="literal">True</span>,</span><br><span class="line">                      labels=labels, startangle=<span class="number">70</span>)</span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count"</span>] = loan_data[<span class="string">"loan_status_count"</span>].map(loan_status_dict)</span><br><span class="line">sns.barplot(x=loan_data[<span class="string">"year"</span>], y=loan_data[<span class="string">"loan_amnt"</span>], hue=loan_data[<span class="string">"loan_status_count"</span>], hue_order=labels,</span><br><span class="line">            ax=ax_loan_status[<span class="number">1</span>], estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data[<span class="string">"loan_status_count"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status[<span class="number">0</span>].set_title(<span class="string">"good loans and bad loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status[<span class="number">0</span>].set_ylabel(<span class="string">"Loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status[<span class="number">1</span>].set_title(<span class="string">"good loans and bad loans percent per year"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status[<span class="number">1</span>].set_ylabel(<span class="string">"Loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count"</span>, <span class="string">"year"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">f_loan_status.savefig(<span class="string">"./pictures/good loans and bad loans percent per year.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                      bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the map of geographical coordinates of each state"s good loan number and bad loan number</span></span><br><span class="line">code_and_name_dict = &#123;<span class="string">"AL"</span>: <span class="string">"Alabama"</span>, <span class="string">"AK"</span>: <span class="string">"Alaska"</span>, <span class="string">"AZ"</span>: <span class="string">"Arizona"</span>, <span class="string">"AR"</span>: <span class="string">"Arkansas"</span>, <span class="string">"CA"</span>: <span class="string">"California"</span>,</span><br><span class="line">                      <span class="string">"CO"</span>: <span class="string">"Colorado"</span>, <span class="string">"CT"</span>: <span class="string">"Connecticut"</span>, <span class="string">"DC"</span>: <span class="string">"District of Columbia"</span>, <span class="string">"DE"</span>: <span class="string">"Delaware"</span>,</span><br><span class="line">                      <span class="string">"FL"</span>: <span class="string">"Florida"</span>, <span class="string">"GA"</span>: <span class="string">"Georgia"</span>, <span class="string">"HI"</span>: <span class="string">"Hawaii"</span>, <span class="string">"ID"</span>: <span class="string">"Idaho"</span>, <span class="string">"IL"</span>: <span class="string">"Illinois"</span>,</span><br><span class="line">                      <span class="string">"IN"</span>: <span class="string">"Indiana"</span>, <span class="string">"IA"</span>: <span class="string">"Iowa"</span>, <span class="string">"KS"</span>: <span class="string">"Kansas"</span>, <span class="string">"KY"</span>: <span class="string">"Kentucky"</span>, <span class="string">"LA"</span>: <span class="string">"Louisiana"</span>, <span class="string">"ME"</span>: <span class="string">"Maine"</span>,</span><br><span class="line">                      <span class="string">"MD"</span>: <span class="string">"Maryland"</span>, <span class="string">"MA"</span>: <span class="string">"Massachusetts"</span>, <span class="string">"MI"</span>: <span class="string">"Michigan"</span>, <span class="string">"MN"</span>: <span class="string">"Minnesota"</span>, <span class="string">"MS"</span>: <span class="string">"Mississippi"</span>,</span><br><span class="line">                      <span class="string">"MO"</span>: <span class="string">"Missouri"</span>, <span class="string">"MT"</span>: <span class="string">"Montana"</span>, <span class="string">"NE"</span>: <span class="string">"Nebraska"</span>, <span class="string">"NV"</span>: <span class="string">"Nevada"</span>, <span class="string">"NH"</span>: <span class="string">"New Hampshire"</span>,</span><br><span class="line">                      <span class="string">"NJ"</span>: <span class="string">"New Jersey"</span>, <span class="string">"NM"</span>: <span class="string">"New Mexico"</span>, <span class="string">"NY"</span>: <span class="string">"New York"</span>, <span class="string">"NC"</span>: <span class="string">"North Carolina"</span>,</span><br><span class="line">                      <span class="string">"ND"</span>: <span class="string">"North Dakota"</span>, <span class="string">"OH"</span>: <span class="string">"Ohio"</span>, <span class="string">"OK"</span>: <span class="string">"Oklahoma"</span>, <span class="string">"OR"</span>: <span class="string">"Oregon"</span>, <span class="string">"PA"</span>: <span class="string">"Pennsylvania"</span>,</span><br><span class="line">                      <span class="string">"RI"</span>: <span class="string">"Rhode Island"</span>, <span class="string">"SC"</span>: <span class="string">"South Carolina"</span>, <span class="string">"SD"</span>: <span class="string">"South Dakota"</span>, <span class="string">"TN"</span>: <span class="string">"Tennessee"</span>,</span><br><span class="line">                      <span class="string">"TX"</span>: <span class="string">"Texas"</span>, <span class="string">"UT"</span>: <span class="string">"Utah"</span>, <span class="string">"VT"</span>: <span class="string">"Vermont"</span>, <span class="string">"VA"</span>: <span class="string">"Virginia"</span>, <span class="string">"WA"</span>: <span class="string">"Washington"</span>,</span><br><span class="line">                      <span class="string">"WV"</span>: <span class="string">"West Virginia"</span>, <span class="string">"WI"</span>: <span class="string">"Wisconsin"</span>, <span class="string">"WY"</span>: <span class="string">"Wyoming"</span>&#125;</span><br><span class="line"><span class="comment"># 为了便于计算坏账数,我们令坏账为1,好帐为0</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">0</span>, <span class="string">"Current"</span>: <span class="number">0</span>, <span class="string">"Charged Off"</span>: <span class="number">1</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">1</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">1</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">1</span>, <span class="string">"Default"</span>: <span class="number">1</span>&#125;</span><br><span class="line"><span class="comment"># 用1表示贷款状况良好，用0表示不良贷款</span></span><br><span class="line">loan_data[<span class="string">"loan_status_count_2"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_2"</span>] = loan_data[<span class="string">"loan_status_count_2"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line"><span class="comment"># print(loan_data["loan_status_count"].value_counts().to_dict())</span></span><br><span class="line"><span class="comment"># &#123;0.0: 1862171, 1.0: 274902&#125;</span></span><br><span class="line">loan_status_per_state = loan_data.groupby(<span class="string">"addr_state"</span>)[<span class="string">"loan_status_count_2"</span>].sum().to_dict()</span><br><span class="line"><span class="comment"># print(loan_status_per_state)</span></span><br><span class="line">loan_status_per_state_pd = pd.DataFrame(list(loan_status_per_state.items()),</span><br><span class="line">                                        columns=[<span class="string">"state_code"</span>, <span class="string">"bad_loan_num"</span>])</span><br><span class="line">loan_status_per_state_pd[<span class="string">"state_name"</span>] = <span class="literal">None</span></span><br><span class="line"><span class="comment"># print(loan_status_per_state_pd)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(loan_status_per_state_pd.shape[<span class="number">0</span>]):</span><br><span class="line">state_name = code_and_name_dict[loan_status_per_state_pd.ix[i, <span class="string">"state_code"</span>]]</span><br><span class="line">loan_status_per_state_pd.ix[i, <span class="string">"state_name"</span>] = state_name</span><br><span class="line"><span class="comment"># print(loan_status_per_state_pd)</span></span><br><span class="line"><span class="comment"># 设立颜色条色彩渐变颜色</span></span><br><span class="line"><span class="comment"># colorscale可选项:["Greys", "YlGnBu", "Greens", "YlOrRd", "Bluered", "RdBu","Reds", "Blues", "Picnic", "Rainbow",</span></span><br><span class="line"><span class="comment"># "Portland", "Jet","Hot", "Blackbody", "Earth", "Electric", "Viridis", "Cividis"]</span></span><br><span class="line">colorscale = <span class="string">"Hot"</span></span><br><span class="line"><span class="comment"># colorbar为颜色条注释,位置由各州的编号，即缩写表示,z值越高颜色越深</span></span><br><span class="line">data = [dict(type=<span class="string">"choropleth"</span>, colorscale=colorscale, autocolorscale=<span class="literal">False</span>, reversescale=<span class="literal">True</span>,</span><br><span class="line">             locations=loan_status_per_state_pd[<span class="string">"state_code"</span>], z=loan_status_per_state_pd[<span class="string">"bad_loan_num"</span>],</span><br><span class="line">             locationmode=<span class="string">"USA-states"</span>, text=loan_status_per_state_pd[<span class="string">"state_name"</span>],</span><br><span class="line">             marker=dict(line=dict(color=<span class="string">"rgb(255,255,255)"</span>, width=<span class="number">2</span>)),</span><br><span class="line">             colorbar=dict(title=<span class="string">"bad loans num"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">32</span>)))]</span><br><span class="line">layout = dict(title=<span class="string">"bad loans num per state map"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">50</span>),</span><br><span class="line">              geo=dict(scope=<span class="string">"usa"</span>, projection=dict(type=<span class="string">"albers usa"</span>)))</span><br><span class="line">fig = dict(data=data, layout=layout)</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_2"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># filename为网站上个人空间中保存的文件名</span></span><br><span class="line">py.plot(fig, filename=<span class="string">"bad loans num per state map"</span>, auto_open=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># filename为本地保存的文件名,plotly本地保存只支持png,svg,jpeg,pdf</span></span><br><span class="line">py.image.save_as(fig, filename=<span class="string">"./pictures/bad loans num per state map.png"</span>, width=<span class="number">2500</span>, height=<span class="number">1500</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the map of geographical coordinates of each state"s good loan ratio and bad loan ratio</span></span><br><span class="line">code_and_name_dict = &#123;<span class="string">"AL"</span>: <span class="string">"Alabama"</span>, <span class="string">"AK"</span>: <span class="string">"Alaska"</span>, <span class="string">"AZ"</span>: <span class="string">"Arizona"</span>, <span class="string">"AR"</span>: <span class="string">"Arkansas"</span>, <span class="string">"CA"</span>: <span class="string">"California"</span>,</span><br><span class="line">                      <span class="string">"CO"</span>: <span class="string">"Colorado"</span>, <span class="string">"CT"</span>: <span class="string">"Connecticut"</span>, <span class="string">"DC"</span>: <span class="string">"District of Columbia"</span>, <span class="string">"DE"</span>: <span class="string">"Delaware"</span>,</span><br><span class="line">                      <span class="string">"FL"</span>: <span class="string">"Florida"</span>, <span class="string">"GA"</span>: <span class="string">"Georgia"</span>, <span class="string">"HI"</span>: <span class="string">"Hawaii"</span>, <span class="string">"ID"</span>: <span class="string">"Idaho"</span>, <span class="string">"IL"</span>: <span class="string">"Illinois"</span>,</span><br><span class="line">                      <span class="string">"IN"</span>: <span class="string">"Indiana"</span>, <span class="string">"IA"</span>: <span class="string">"Iowa"</span>, <span class="string">"KS"</span>: <span class="string">"Kansas"</span>, <span class="string">"KY"</span>: <span class="string">"Kentucky"</span>, <span class="string">"LA"</span>: <span class="string">"Louisiana"</span>, <span class="string">"ME"</span>: <span class="string">"Maine"</span>,</span><br><span class="line">                      <span class="string">"MD"</span>: <span class="string">"Maryland"</span>, <span class="string">"MA"</span>: <span class="string">"Massachusetts"</span>, <span class="string">"MI"</span>: <span class="string">"Michigan"</span>, <span class="string">"MN"</span>: <span class="string">"Minnesota"</span>, <span class="string">"MS"</span>: <span class="string">"Mississippi"</span>,</span><br><span class="line">                      <span class="string">"MO"</span>: <span class="string">"Missouri"</span>, <span class="string">"MT"</span>: <span class="string">"Montana"</span>, <span class="string">"NE"</span>: <span class="string">"Nebraska"</span>, <span class="string">"NV"</span>: <span class="string">"Nevada"</span>, <span class="string">"NH"</span>: <span class="string">"New Hampshire"</span>,</span><br><span class="line">                      <span class="string">"NJ"</span>: <span class="string">"New Jersey"</span>, <span class="string">"NM"</span>: <span class="string">"New Mexico"</span>, <span class="string">"NY"</span>: <span class="string">"New York"</span>, <span class="string">"NC"</span>: <span class="string">"North Carolina"</span>,</span><br><span class="line">                      <span class="string">"ND"</span>: <span class="string">"North Dakota"</span>, <span class="string">"OH"</span>: <span class="string">"Ohio"</span>, <span class="string">"OK"</span>: <span class="string">"Oklahoma"</span>, <span class="string">"OR"</span>: <span class="string">"Oregon"</span>, <span class="string">"PA"</span>: <span class="string">"Pennsylvania"</span>,</span><br><span class="line">                      <span class="string">"RI"</span>: <span class="string">"Rhode Island"</span>, <span class="string">"SC"</span>: <span class="string">"South Carolina"</span>, <span class="string">"SD"</span>: <span class="string">"South Dakota"</span>, <span class="string">"TN"</span>: <span class="string">"Tennessee"</span>,</span><br><span class="line">                      <span class="string">"TX"</span>: <span class="string">"Texas"</span>, <span class="string">"UT"</span>: <span class="string">"Utah"</span>, <span class="string">"VT"</span>: <span class="string">"Vermont"</span>, <span class="string">"VA"</span>: <span class="string">"Virginia"</span>, <span class="string">"WA"</span>: <span class="string">"Washington"</span>,</span><br><span class="line">                      <span class="string">"WV"</span>: <span class="string">"West Virginia"</span>, <span class="string">"WI"</span>: <span class="string">"Wisconsin"</span>, <span class="string">"WY"</span>: <span class="string">"Wyoming"</span>&#125;</span><br><span class="line"><span class="comment"># 为了便于计算坏账数,我们令坏账为1,好帐为0</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">0</span>, <span class="string">"Current"</span>: <span class="number">0</span>, <span class="string">"Charged Off"</span>: <span class="number">1</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">1</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">1</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">1</span>, <span class="string">"Default"</span>: <span class="number">1</span>&#125;</span><br><span class="line"><span class="comment"># 用1表示贷款状况良好，用0表示不良贷款</span></span><br><span class="line">loan_data[<span class="string">"loan_status_count_3"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_3"</span>] = loan_data[<span class="string">"loan_status_count_3"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line"><span class="comment"># print(loan_data["loan_status_count"].value_counts().to_dict())</span></span><br><span class="line"><span class="comment"># &#123;0.0: 1862171, 1.0: 274902&#125;</span></span><br><span class="line">loan_status_per_state = loan_data.groupby(<span class="string">"addr_state"</span>)[<span class="string">"loan_status_count_3"</span>].sum().to_dict()</span><br><span class="line">loan_status_per_state_pd = pd.DataFrame(list(loan_status_per_state.items()),</span><br><span class="line">                                        columns=[<span class="string">"state_code"</span>, <span class="string">"bad_loan_percent"</span>])</span><br><span class="line">loan_times_per_state_sum_dict = loan_data[<span class="string">"addr_state"</span>].value_counts().to_dict()</span><br><span class="line">loan_status_per_state_pd[<span class="string">"state_name"</span>] = <span class="literal">None</span></span><br><span class="line"><span class="comment"># print(loan_status_per_state_pd)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(loan_status_per_state_pd.shape[<span class="number">0</span>]):</span><br><span class="line">state_name = code_and_name_dict[loan_status_per_state_pd.ix[i, <span class="string">"state_code"</span>]]</span><br><span class="line">loan_status_per_state_pd.ix[i, <span class="string">"state_name"</span>] = state_name</span><br><span class="line"><span class="comment"># print(loan_status_per_state_pd)</span></span><br><span class="line"><span class="comment"># print(loan_times_per_state_sum_dict)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(loan_status_per_state_pd.shape[<span class="number">0</span>]):</span><br><span class="line">per_state_sum = loan_times_per_state_sum_dict[loan_status_per_state_pd.ix[i, <span class="string">"state_code"</span>]]</span><br><span class="line">loan_status_per_state_pd.ix[i, <span class="string">"bad_loan_percent"</span>] = float(</span><br><span class="line">loan_status_per_state_pd.ix[i, <span class="string">"bad_loan_percent"</span>]) / per_state_sum</span><br><span class="line"><span class="comment"># print(loan_status_per_state_pd)</span></span><br><span class="line"><span class="comment"># 设立颜色条色彩渐变颜色</span></span><br><span class="line"><span class="comment"># colorscale可选项:["Greys", "YlGnBu", "Greens", "YlOrRd", "Bluered", "RdBu","Reds", "Blues", "Picnic", "Rainbow",</span></span><br><span class="line"><span class="comment"># "Portland", "Jet","Hot", "Blackbody", "Earth", "Electric", "Viridis", "Cividis"]</span></span><br><span class="line">colorscale = <span class="string">"Reds"</span></span><br><span class="line"><span class="comment"># colorbar为颜色条注释,位置由各州的编号，即缩写表示,z值越高颜色越深</span></span><br><span class="line">data = [dict(type=<span class="string">"choropleth"</span>, colorscale=colorscale, autocolorscale=<span class="literal">False</span>, reversescale=<span class="literal">False</span>,</span><br><span class="line">             locations=loan_status_per_state_pd[<span class="string">"state_code"</span>], z=loan_status_per_state_pd[<span class="string">"bad_loan_percent"</span>],</span><br><span class="line">             locationmode=<span class="string">"USA-states"</span>, text=loan_status_per_state_pd[<span class="string">"state_name"</span>],</span><br><span class="line">             marker=dict(line=dict(color=<span class="string">"rgb(255,255,255)"</span>, width=<span class="number">2</span>)),</span><br><span class="line">             colorbar=dict(title=<span class="string">"bad loans percent"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">32</span>)))]</span><br><span class="line">layout = dict(title=<span class="string">"bad loans percent per state map"</span>, titlefont=dict(color=<span class="string">"rgb(0,0,0)"</span>, size=<span class="number">50</span>),</span><br><span class="line">              geo=dict(scope=<span class="string">"usa"</span>, projection=dict(type=<span class="string">"albers usa"</span>)))</span><br><span class="line">fig = dict(data=data, layout=layout)</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_3"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># filename为网站上个人空间中保存的文件名</span></span><br><span class="line">py.plot(fig, filename=<span class="string">"bad loans percent per state map"</span>, auto_open=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># filename为本地保存的文件名,plotly本地保存只支持png,svg,jpeg,pdf</span></span><br><span class="line">py.image.save_as(fig, filename=<span class="string">"./pictures/bad loans percent per state map.png"</span>, width=<span class="number">2500</span>, height=<span class="number">1500</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loan purpose word cloud map</span></span><br><span class="line">loan_times_per_purpose_sum_dict = loan_data[<span class="string">"purpose"</span>].value_counts().to_dict()</span><br><span class="line"><span class="comment"># print(loan_times_per_purpose_sum_dict)</span></span><br><span class="line">loan_times_per_purpose_sum_pd = pd.DataFrame(list(loan_times_per_purpose_sum_dict.items()),</span><br><span class="line">                                             columns=[<span class="string">"purpose"</span>, <span class="string">"loan_times"</span>])</span><br><span class="line"><span class="comment"># print(loan_times_per_purpose_sum_pd)</span></span><br><span class="line">wordcloud = WordCloud(width=<span class="number">1500</span>, height=<span class="number">1000</span>)</span><br><span class="line">wordcloud.add(<span class="string">"loan purpose word cloud"</span>, loan_times_per_purpose_sum_pd[<span class="string">"purpose"</span>],</span><br><span class="line">              loan_times_per_purpose_sum_pd[<span class="string">"loan_times"</span>], shape=<span class="string">"diamond"</span>,</span><br><span class="line">              rotate_step=<span class="number">60</span>, word_size_range=[<span class="number">10</span>, <span class="number">100</span>])</span><br><span class="line">wordcloud.render(path=<span class="string">"./pictures/loan purpose word cloud.html"</span>)</span><br><span class="line">wordcloud.render(path=<span class="string">"./pictures/loan purpose word cloud.pdf"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the ratio of good loans and bad loans for each loan purpose</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_4"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_4"</span>] = loan_data[<span class="string">"loan_status_count_4"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">f_loan_status_purpose, ax_loan_status_purpose = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_4"</span>] = loan_data[<span class="string">"loan_status_count_4"</span>].map(loan_status_dict)</span><br><span class="line">sns.barplot(x=loan_data[<span class="string">"purpose"</span>], y=loan_data[<span class="string">"loan_amnt"</span>], hue=loan_data[<span class="string">"loan_status_count_4"</span>], hue_order=labels,</span><br><span class="line">            ax=ax_loan_status_purpose, estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data[<span class="string">"loan_status_count_4"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status_purpose.set_title(<span class="string">"Loan status per purpose percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_purpose.set_xticklabels(ax_loan_status_purpose.get_xticklabels(), rotation=<span class="number">45</span>)</span><br><span class="line">ax_loan_status_purpose.set_xlabel(<span class="string">"purpose"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_purpose.set_ylabel(<span class="string">"per purpose loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_4"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">f_loan_status_purpose.savefig(<span class="string">"./pictures/Loan status per purpose percent bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                              bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ratio of housing for good loans customer and bad loans customer</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_5"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_5"</span>] = loan_data[<span class="string">"loan_status_count_5"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">f_loan_status_home, ax_loan_status_home = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_5"</span>] = loan_data[<span class="string">"loan_status_count_5"</span>].map(loan_status_dict)</span><br><span class="line">sns.barplot(x=loan_data[<span class="string">"home_ownership"</span>], y=loan_data[<span class="string">"loan_amnt"</span>], hue=loan_data[<span class="string">"loan_status_count_5"</span>],</span><br><span class="line">            hue_order=labels,</span><br><span class="line">            ax=ax_loan_status_home, estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data[<span class="string">"loan_status_count_5"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status_home.set_title(<span class="string">"Loan status per home percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_home.set_xlabel(<span class="string">"home ownership"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_home.set_ylabel(<span class="string">"per home ownership loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_5"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">f_loan_status_home.savefig(<span class="string">"./pictures/Loan status per home ownership percent bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                           bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ratio of good loans and bad loans for each income level</span></span><br><span class="line"><span class="comment"># 我们将年收入分为三档:20000以下为low，20000-60000为mid，&gt;60000为high</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_6"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_6"</span>] = loan_data[<span class="string">"loan_status_count_6"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">max_value = loan_data[<span class="string">"annual_inc"</span>].max() + <span class="number">1.0</span></span><br><span class="line">set_bins = [<span class="number">0.0</span>, <span class="number">20000.0</span>, <span class="number">60000.0</span>, max_value]</span><br><span class="line">set_label = [<span class="string">"low"</span>, <span class="string">"mid"</span>, <span class="string">"high"</span>]</span><br><span class="line">loan_data[<span class="string">"income"</span>] = pd.cut(loan_data[<span class="string">"annual_inc"</span>], bins=set_bins, labels=set_label)</span><br><span class="line">f_loan_status_income, ax_loan_status_income = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_6"</span>] = loan_data[<span class="string">"loan_status_count_6"</span>].map(loan_status_dict)</span><br><span class="line">sns.barplot(x=loan_data[<span class="string">"income"</span>], y=loan_data[<span class="string">"loan_amnt"</span>], hue=loan_data[<span class="string">"loan_status_count_6"</span>], hue_order=labels,</span><br><span class="line">            ax=ax_loan_status_income, estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data[<span class="string">"loan_status_count_6"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status_income.set_title(<span class="string">"Loan status per income percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_income.set_xlabel(<span class="string">"income"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_income.set_ylabel(<span class="string">"per income loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_6"</span>, <span class="string">"income"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">f_loan_status_income.savefig(<span class="string">"./pictures/Loan status per income percent bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                             bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the ratio of good loans and bad loans for each credit rating</span></span><br><span class="line">loan_data_sorted = loan_data.sort_values(by=[<span class="string">"grade"</span>], inplace=<span class="literal">False</span>)</span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data_sorted[<span class="string">"loan_status_count_7"</span>] = loan_data_sorted[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data_sorted[<span class="string">"loan_status_count_7"</span>] = loan_data_sorted[<span class="string">"loan_status_count_7"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">f_loan_status_grade, ax_loan_status_grade = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data_sorted[<span class="string">"loan_status_count_7"</span>] = loan_data_sorted[<span class="string">"loan_status_count_7"</span>].map(loan_status_dict)</span><br><span class="line">sns.barplot(x=loan_data_sorted[<span class="string">"grade"</span>], y=loan_data_sorted[<span class="string">"loan_amnt"</span>], hue=loan_data_sorted[<span class="string">"loan_status_count_7"</span>],</span><br><span class="line">            hue_order=labels,</span><br><span class="line">            ax=ax_loan_status_grade, estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data_sorted[<span class="string">"loan_status_count_7"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status_grade.set_title(<span class="string">"Loan status per grade percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_grade.set_xlabel(<span class="string">"grade"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_grade.set_ylabel(<span class="string">"per grade loans percent"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_loan_status_grade.savefig(<span class="string">"./pictures/Loan status per grade percent bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                            bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># data distribution of loan interest rates</span></span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_int_rate, ax_int_rate = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.distplot(loan_data[<span class="string">"int_rate"</span>], ax=ax_int_rate[<span class="number">0</span>], color=<span class="string">"#2F8FF7"</span>)</span><br><span class="line">sns.violinplot(y=loan_data[<span class="string">"int_rate"</span>], ax=ax_int_rate[<span class="number">1</span>], inner=<span class="string">"quartile"</span>, palette=<span class="string">"Blues"</span>)</span><br><span class="line">ax_int_rate[<span class="number">0</span>].set_title(<span class="string">"Int rate distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_int_rate[<span class="number">1</span>].set_title(<span class="string">"Int rate distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_int_rate[<span class="number">0</span>].set_xlabel(<span class="string">"Int rate"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_int_rate[<span class="number">0</span>].set_ylabel(<span class="string">"Int rate"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_int_rate.savefig(<span class="string">"./pictures/Int rate distribution.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># average interest rate of good loans and bad loans for each credit ratings</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_8"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_8"</span>] = loan_data[<span class="string">"loan_status_count_8"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">f_inc_rate_grade, ax_inc_rate_grade = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_8"</span>] = loan_data[<span class="string">"loan_status_count_8"</span>].map(loan_status_dict)</span><br><span class="line">loan_data_sorted = loan_data.sort_values(by=[<span class="string">"grade"</span>], inplace=<span class="literal">False</span>)</span><br><span class="line">sns.barplot(x=loan_data_sorted[<span class="string">"grade"</span>], y=loan_data_sorted[<span class="string">"int_rate"</span>], hue=loan_data_sorted[<span class="string">"loan_status_count_8"</span>],</span><br><span class="line">            hue_order=labels, ax=ax_inc_rate_grade, ci=<span class="literal">None</span>)</span><br><span class="line">ax_inc_rate_grade.set_title(<span class="string">"mean int rate per grade"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_inc_rate_grade.set_xlabel(<span class="string">"grade"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_inc_rate_grade.set_ylabel(<span class="string">"mean int rate"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_8"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">f_inc_rate_grade.savefig(<span class="string">"./pictures/mean int rate per grade bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                         bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># data distribution of the percentage of the lender"s month-repayments divide the lender"s income</span></span><br><span class="line"><span class="comment"># max_value=loan_data["dti"].max()</span></span><br><span class="line"><span class="comment"># min_value=loan_data["dti"].min()</span></span><br><span class="line"><span class="comment"># print(max_value,min_value)</span></span><br><span class="line"><span class="comment"># 999.0 -1.0 这里的数值应当是百分比</span></span><br><span class="line"><span class="comment"># 该数据中有异常值-1.0,且有很大的离散值,我们需要将其先过滤掉,否则图像效果不好</span></span><br><span class="line">loan_data_dti = loan_data[loan_data[<span class="string">"dti"</span>] &lt;= <span class="number">100.0</span>]</span><br><span class="line">loan_data_dti = loan_data_dti[loan_data_dti[<span class="string">"dti"</span>] &gt; <span class="number">0.0</span>]</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_dti, ax_dti = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.distplot(loan_data_dti[<span class="string">"dti"</span>], ax=ax_dti[<span class="number">0</span>], color=<span class="string">"#F7522F"</span>)</span><br><span class="line">sns.violinplot(y=loan_data_dti[<span class="string">"dti"</span>], ax=ax_dti[<span class="number">1</span>], inner=<span class="string">"quartile"</span>, palette=<span class="string">"Reds"</span>)</span><br><span class="line">ax_dti[<span class="number">0</span>].set_title(<span class="string">"dti distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti[<span class="number">1</span>].set_title(<span class="string">"dti distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti[<span class="number">0</span>].set_xlabel(<span class="string">"dti"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti[<span class="number">1</span>].set_ylabel(<span class="string">"dti"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_dti.savefig(<span class="string">"./pictures/dti distribution.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># data distribution of the percentage of the good lender"s month-repayments divide the lender"s income and the percentage of the bad lender"s month-repayments divide the lender"s income</span></span><br><span class="line"><span class="comment"># 请先过滤异常值和极大离散点,只保留0-200之间的数据</span></span><br><span class="line">loan_data_dti = loan_data[loan_data[<span class="string">"dti"</span>] &lt;= <span class="number">100.0</span>]</span><br><span class="line">loan_data_dti = loan_data_dti[loan_data_dti[<span class="string">"dti"</span>] &gt;= <span class="number">0.0</span>]</span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data_dti[<span class="string">"loan_status_count_9"</span>] = loan_data_dti[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data_dti[<span class="string">"loan_status_count_9"</span>] = loan_data_dti[<span class="string">"loan_status_count_9"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">labels = <span class="string">"Bad loans"</span>, <span class="string">"Good loans"</span></span><br><span class="line"><span class="comment"># 取出groupby后的分组结果</span></span><br><span class="line">loans_dti_per_status = dict(list(loan_data_dti.groupby(<span class="string">"loan_status_count_9"</span>)[<span class="string">"dti"</span>]))</span><br><span class="line">good_loan_dti = pd.DataFrame(loans_dti_per_status[<span class="number">1.0</span>], index=<span class="literal">None</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">bad_loan_dti = pd.DataFrame(loans_dti_per_status[<span class="number">0.0</span>], index=<span class="literal">None</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(good_loan_dti, bad_loan_dti)</span></span><br><span class="line"><span class="comment"># print(good_loan_dti.shape, bad_loan_dti.shape)</span></span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f_dti_per_loan_status, ax_dti_per_loan_status = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.distplot(good_loan_dti[<span class="string">"dti"</span>], ax=ax_dti_per_loan_status[<span class="number">0</span>], color=<span class="string">"#2F8FF7"</span>)</span><br><span class="line">sns.distplot(bad_loan_dti[<span class="string">"dti"</span>], ax=ax_dti_per_loan_status[<span class="number">1</span>], color=<span class="string">"#F7522F"</span>)</span><br><span class="line">ax_dti_per_loan_status[<span class="number">0</span>].set_title(<span class="string">"good loans dti distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti_per_loan_status[<span class="number">1</span>].set_title(<span class="string">"bad loans dti distribution"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti_per_loan_status[<span class="number">0</span>].set_xlabel(<span class="string">"dti"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_dti_per_loan_status[<span class="number">1</span>].set_ylabel(<span class="string">"dti"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_dti_per_loan_status.savefig(<span class="string">"./pictures/dti distribution per loan status.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ratio of short-term and long-term loans for good loans and bad loans</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_10"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_10"</span>] = loan_data[<span class="string">"loan_status_count_10"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">f_loan_status_term, ax_loan_status_term = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">labels = <span class="string">"Good loans"</span>, <span class="string">"Bad loans"</span></span><br><span class="line">loan_status_dict = &#123;<span class="number">1.0</span>: <span class="string">"Good loans"</span>, <span class="number">0.0</span>: <span class="string">"Bad loans"</span>&#125;</span><br><span class="line">loan_data[<span class="string">"loan_status_count_10"</span>] = loan_data[<span class="string">"loan_status_count_10"</span>].map(loan_status_dict)</span><br><span class="line">loan_data_sorted = loan_data.sort_values(by=[<span class="string">"grade"</span>], inplace=<span class="literal">False</span>)</span><br><span class="line">sns.barplot(x=loan_data_sorted[<span class="string">"term"</span>], y=loan_data_sorted[<span class="string">"loan_amnt"</span>], hue=loan_data_sorted[<span class="string">"loan_status_count_10"</span>],</span><br><span class="line">            hue_order=labels,</span><br><span class="line">            ax=ax_loan_status_term, estimator=<span class="keyword">lambda</span> x: len(x) / len(loan_data_sorted[<span class="string">"loan_status_count_10"</span>]) * <span class="number">100</span>)</span><br><span class="line">ax_loan_status_term.set_title(<span class="string">"loan times per term"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_term.set_xlabel(<span class="string">"term"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_loan_status_term.set_ylabel(<span class="string">"loan times"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_10"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">f_loan_status_term.savefig(<span class="string">"./pictures/loan times per term bar.jpg"</span>, dpi=<span class="number">200</span>,</span><br><span class="line">                           bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure><p>model_training_and_testing.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> RobustScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report, confusion_matrix</span><br><span class="line"></span><br><span class="line">loan_data = pd.read_csv(<span class="string">"loan_clean_data.csv"</span>, low_memory=<span class="literal">False</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># There is a serious problem of sample imbalance in this dataset</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line"><span class="comment"># 用1表示贷款状况良好，用0表示不良贷款</span></span><br><span class="line">loan_data[<span class="string">"loan_status_count_11"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status_count_11"</span>] = loan_data[<span class="string">"loan_status_count_11"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line">loan_data_status_count = loan_data[<span class="string">"loan_status_count_11"</span>].value_counts().to_dict()</span><br><span class="line">sum_value = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> loan_data_status_count.items():</span><br><span class="line">sum_value += value</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> loan_data_status_count.items():</span><br><span class="line">loan_data_status_count[key] = value / sum_value</span><br><span class="line">print(loan_data_status_count)</span><br><span class="line"><span class="comment"># &#123;1.0: 0.8713651803190625, 0.0: 0.12863481968093743&#125;</span></span><br><span class="line">loan_data.drop([<span class="string">"loan_status_count_11"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment"># (2137073, 87)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># feature:loan_status‘s change to 0 or 1</span></span><br><span class="line">loan_status_dict = &#123;<span class="string">"Fully Paid"</span>: <span class="number">1</span>, <span class="string">"Current"</span>: <span class="number">1</span>, <span class="string">"Charged Off"</span>: <span class="number">0</span>, <span class="string">"Late (31-120 days)"</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">"In Grace Period"</span>: <span class="number">0</span>, <span class="string">"Late (16-30 days)"</span>: <span class="number">0</span>, <span class="string">"Default"</span>: <span class="number">0</span>&#125;</span><br><span class="line"><span class="comment"># 1 is good loan,0 is bad loan</span></span><br><span class="line">loan_data[<span class="string">"loan_status"</span>] = loan_data[<span class="string">"loan_status"</span>].map(loan_status_dict)</span><br><span class="line">loan_data[<span class="string">"loan_status"</span>] = loan_data[<span class="string">"loan_status"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line"><span class="comment"># print(loan_data["emp_length"].value_counts().to_dict)</span></span><br><span class="line">emp_length_dict = &#123;<span class="string">"10+ years"</span>: <span class="number">10</span>, <span class="string">"2 years"</span>: <span class="number">2</span>, <span class="string">"&lt; 1 year"</span>: <span class="number">0.5</span>, <span class="string">"3 years"</span>: <span class="number">3</span>, <span class="string">"1 year"</span>: <span class="number">1</span>, <span class="string">"5 years"</span>: <span class="number">5</span>,</span><br><span class="line">                   <span class="string">"4 years"</span>: <span class="number">4</span>, <span class="string">"6 years"</span>: <span class="number">6</span>, <span class="string">"7 years"</span>: <span class="number">7</span>, <span class="string">"8 years"</span>: <span class="number">8</span>, <span class="string">"9 years"</span>: <span class="number">9</span>&#125;</span><br><span class="line">loan_data[<span class="string">"emp_length"</span>] = loan_data[<span class="string">"emp_length"</span>].map(emp_length_dict)</span><br><span class="line">loan_data[<span class="string">"emp_length"</span>] = loan_data[<span class="string">"emp_length"</span>].astype(<span class="string">"float"</span>)</span><br><span class="line"><span class="comment"># fill missing value of emp_length to 0</span></span><br><span class="line">loan_data[<span class="string">"emp_length"</span>].fillna(value=<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># drop some features</span></span><br><span class="line">loan_data.drop([<span class="string">"emp_title"</span>, <span class="string">"title"</span>, <span class="string">"zip_code"</span>, <span class="string">"earliest_cr_line"</span>, <span class="string">"last_pymnt_d"</span>, <span class="string">"last_credit_pull_d"</span>], axis=<span class="number">1</span>,</span><br><span class="line">               inplace=<span class="literal">True</span>)</span><br><span class="line">loan_data[<span class="string">"month"</span>], loan_data[<span class="string">"year"</span>] = loan_data[<span class="string">"issue_d"</span>].str.split(<span class="string">"-"</span>, <span class="number">1</span>).str</span><br><span class="line">loan_data.drop([<span class="string">"issue_d"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">print(loan_data.shape)</span><br><span class="line"><span class="comment"># (2137073, 82)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">numerical_feature_name = loan_data.columns[(loan_data.dtypes == <span class="string">"float64"</span>) | (loan_data.dtypes == <span class="string">"int64"</span>)].tolist()</span><br><span class="line"><span class="comment"># category_feature_name = loan_data.columns[loan_data.dtypes == "object"].tolist()</span></span><br><span class="line"><span class="comment"># draw pearson correlation coefficient matrix</span></span><br><span class="line"><span class="comment"># 若&gt;0，表明两个变量是正相关,即一个变量的值越大，另一个变量的值也会越大</span></span><br><span class="line"><span class="comment"># 若&lt;0，表明两个变量是负相关，即一个变量的值越大另一个变量的值反而会越小</span></span><br><span class="line"><span class="comment"># 若r=0，表明两个变量间不是线性相关，但有可能是非线性相关</span></span><br><span class="line">corrmat = loan_data[numerical_feature_name].corr()</span><br><span class="line">f, ax = plt.subplots(figsize=(<span class="number">30</span>, <span class="number">20</span>))</span><br><span class="line"><span class="comment"># vmax、vmin即热力图颜色取值的最大值和最小值,默认会从data中推导</span></span><br><span class="line"><span class="comment"># square=True会将单元格设为正方形</span></span><br><span class="line">sns.heatmap(corrmat, square=<span class="literal">True</span>, ax=ax, cmap=<span class="string">"Blues"</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">ax.set_title(<span class="string">"Correlation coefficient matrix"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">"feature names"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">"feature names"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f.savefig(<span class="string">"./pictures/Correlation coefficient matrix.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># split features and labels</span></span><br><span class="line">X = loan_data.ix[:, loan_data.columns != <span class="string">"loan_status"</span>]</span><br><span class="line">Y = loan_data[<span class="string">"loan_status"</span>]</span><br><span class="line">print(X.shape, Y.shape)</span><br><span class="line"><span class="comment"># (2137073, 81) (2137073,)</span></span><br><span class="line">X = pd.get_dummies(X, drop_first=<span class="literal">True</span>)</span><br><span class="line">print(X.shape)</span><br><span class="line"><span class="comment"># (2137073, 200)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # if use lr model to train and test,please run this cell</span></span><br><span class="line"><span class="comment"># # divide training sets and testing sets</span></span><br><span class="line"><span class="comment"># x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)</span></span><br><span class="line"><span class="comment"># print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)</span></span><br><span class="line"><span class="comment"># # (1709658, 200) (427415, 200) (1709658,) (427415,)</span></span><br><span class="line"><span class="comment"># numerical_feature_name_2 = X.columns[(X.dtypes == "float64") | (X.dtypes == "int64")].tolist()</span></span><br><span class="line"><span class="comment"># category_feature_name_2 = X.columns[X.dtypes == "uint8"].tolist()</span></span><br><span class="line"><span class="comment"># print(len(numerical_feature_name_2), len(category_feature_name_2))</span></span><br><span class="line"><span class="comment"># # 67 133</span></span><br><span class="line"><span class="comment"># # 此时类别型特征已经全部变为one_hot编码(k-1列),数值型特征还需要归一化,由于特征值中有异常值,我们使用RobustScaler方法归一化</span></span><br><span class="line"><span class="comment"># x_train_num, x_train_cat = x_train[numerical_feature_name_2], x_train[category_feature_name_2]</span></span><br><span class="line"><span class="comment"># x_test_num, x_test_cat = x_test[numerical_feature_name_2], x_test[category_feature_name_2]</span></span><br><span class="line"><span class="comment"># # get feature names</span></span><br><span class="line"><span class="comment"># feature_names = list(x_train_num.columns)</span></span><br><span class="line"><span class="comment"># feature_names.extend(list(x_train_cat.columns))</span></span><br><span class="line"><span class="comment"># feature_names = np.array(feature_names)</span></span><br><span class="line"><span class="comment"># print(feature_names.shape)</span></span><br><span class="line"><span class="comment"># # 200</span></span><br><span class="line"><span class="comment"># # robust scalar,默认为第一分位数到第四分位数之间的范围计算均值和方差,归一化还是z_score标准化</span></span><br><span class="line"><span class="comment"># rob_scaler = RobustScaler()</span></span><br><span class="line"><span class="comment"># x_train_num_rob = rob_scaler.fit_transform(x_train_num)</span></span><br><span class="line"><span class="comment"># x_test_num_rob = rob_scaler.transform(x_test_num)</span></span><br><span class="line"><span class="comment"># x_train_nom_pd = pd.DataFrame(np.hstack((x_train_num_rob, x_train_cat)))</span></span><br><span class="line"><span class="comment"># x_test_nom_pd = pd.DataFrame(np.hstack((x_test_num_rob, x_test_cat)))</span></span><br><span class="line"><span class="comment"># y_test_pd = pd.DataFrame(y_test)</span></span><br><span class="line"><span class="comment"># x_train_sm_np, y_train_sm_np = x_train_nom_pd, y_train</span></span><br><span class="line"><span class="comment"># print(x_train_sm_np.shape, y_train_sm_np.shape, x_test_nom_pd.shape, y_test.shape)</span></span><br><span class="line"><span class="comment"># # (1709658, 200) (1709658,) (427415, 200) (427415,)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># if use rf or xgb model to train and test,please run this cell</span></span><br><span class="line"><span class="comment"># divide training sets and testing sets</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)</span><br><span class="line"><span class="comment"># (1709658, 200) (427415, 200) (1709658,) (427415,)</span></span><br><span class="line">x_train_sm_np, x_test_nom_pd, y_train_sm_np, y_test = x_train, x_test, y_train, y_test</span><br><span class="line">feature_names = X.columns.tolist()</span><br><span class="line">feature_names = np.array(feature_names)</span><br><span class="line">print(feature_names.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># # we can choose class_weight="balanced" to deal with sample imbalance problem when we use logistic model</span></span><br><span class="line"><span class="comment"># # if we use random foreast model or xgboost model,we don’t need to deal with sample imbalance problem</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # besides,we can also use SMOTE to generate some sample of the category with low number of samples,but it needs over 16GB memory</span></span><br><span class="line"><span class="comment"># # so,if you want to use SMOTE,you can run all these code on a local computer with at least 32GB memory</span></span><br><span class="line"><span class="comment"># # SMOTE算法即对于少数类中的每一个样本a,执行N次下列操作:</span></span><br><span class="line"><span class="comment"># # 从k个最近邻样本中随机选择一个样本b, 然后从a与b的连线上随机选取一个点c作为新的少数类样本</span></span><br><span class="line"><span class="comment"># # n_jobs=-1表示使用所有CPU</span></span><br><span class="line"><span class="comment"># sm = SMOTE(k_neighbors=10, random_state=0, n_jobs=-1)</span></span><br><span class="line"><span class="comment"># x_train_sm_np, y_train_sm_np = sm.fit_sample(x_train_nom_pd, y_train)</span></span><br><span class="line"><span class="comment"># print(x_train_sm_np.shape, y_train_sm_np.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SMOTE算法需要大量内存,如果使用了该算法,则本py文件需要机器具有至少32GB内存才能一次执行完,故我们可以先将SMOTE结果存起来</span></span><br><span class="line"><span class="comment"># 然后直接读取SMOTE算法处理后的数据集进行预测,这样只需要16GB内存即可</span></span><br><span class="line"><span class="comment"># x_train_sm_pd = pd.DataFrame(x_train_sm_np)</span></span><br><span class="line"><span class="comment"># y_train_sm_pd = pd.DataFrame(y_train_sm_np)</span></span><br><span class="line"><span class="comment"># x_train_sm_pd.to_csv("x_train_sm_np.csv", index=None)</span></span><br><span class="line"><span class="comment"># y_train_sm_pd.to_csv("y_train_sm_np.csv", index=None)</span></span><br><span class="line"><span class="comment"># x_test_nom_pd.to_csv("x_test_nom_np.csv", index=None)</span></span><br><span class="line"><span class="comment"># y_test_pd.to_csv("y_test.csv", index=None)</span></span><br><span class="line"><span class="comment"># x_train_sm_np = np.array(pd.read_csv("x_train_sm_np.csv", low_memory=False))</span></span><br><span class="line"><span class="comment"># y_train_sm_np = np.array(pd.read_csv("y_train_sm_np.csv", low_memory=False))</span></span><br><span class="line"><span class="comment"># x_test_nom_pd = np.array(pd.read_csv("x_test_nom_np.csv", low_memory=False))</span></span><br><span class="line"><span class="comment"># y_test = np.array(pd.read_csv("y_test.csv", low_memory=False))</span></span><br><span class="line"><span class="comment"># print(x_train_sm_np.shape, y_train_sm_np.shape, x_test_nom_pd.shape, y_test.shape)</span></span><br><span class="line"><span class="comment"># # (2980148, 200) (2980148, 1) (427415, 200) (427415, 1)</span></span><br><span class="line"><span class="comment"># # 标签需要降维成一维数组</span></span><br><span class="line"><span class="comment"># y_train_sm_np = y_train_sm_np.ravel()</span></span><br><span class="line"><span class="comment"># y_test = y_test.ravel()</span></span><br><span class="line"><span class="comment"># print(x_train_sm_np.shape, y_train_sm_np.shape, x_test_nom_pd.shape, y_test.shape)</span></span><br><span class="line"><span class="comment"># # (2980148, 200) (2980148,) (427415, 200) (427415,)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # use logistic regression model to train and predict</span></span><br><span class="line"><span class="comment"># # jobs=-1使用所有CPU进行运算</span></span><br><span class="line"><span class="comment"># # sag即随机平均梯度下降，和普通梯度下降法的区别是每次迭代仅仅用一部分的样本来计算梯度，适合于样本数据多的时候</span></span><br><span class="line"><span class="comment"># # class_weight="balanced"根据用来训练的样本的各个类别的比例确定权重</span></span><br><span class="line"><span class="comment"># print("use logistic model to train and predict")</span></span><br><span class="line"><span class="comment"># lr = LogisticRegression(solver="sag", class_weight="balanced", n_jobs=-1)</span></span><br><span class="line"><span class="comment"># lr.fit(x_train_sm_np, y_train_sm_np)</span></span><br><span class="line"><span class="comment"># lr_y_pred = lr.predict(x_test_nom_pd)</span></span><br><span class="line"><span class="comment"># lr_test_acc = accuracy_score(y_test, lr_y_pred)</span></span><br><span class="line"><span class="comment"># lr_classification_score = classification_report(y_test, lr_y_pred)</span></span><br><span class="line"><span class="comment"># print("Lr model test accuracy:&#123;:.2f&#125;".format(lr_test_acc))</span></span><br><span class="line"><span class="comment"># print("Lr model classification_score:\n", lr_classification_score)</span></span><br><span class="line"><span class="comment"># lr_confusion_score = confusion_matrix(y_test, lr_y_pred)</span></span><br><span class="line"><span class="comment"># f_lr, ax_lr = plt.subplots(1, 3, figsize=(15, 10))</span></span><br><span class="line"><span class="comment"># # 混淆矩阵的y轴为true label,x轴为pred label</span></span><br><span class="line"><span class="comment"># # 精确率,如对正类 ,所有预测为正类样本中中真实的正类占所有预测为正类的比例</span></span><br><span class="line"><span class="comment"># # 召回率,如对正类,所有真实的正类样本中有多少被预测为正类的比例</span></span><br><span class="line"><span class="comment"># # 分别计算预测预测的正样本数和负样本数以及真实的正样本数和负样本数</span></span><br><span class="line"><span class="comment"># lr_cm_pred_label_sum = lr_confusion_score.sum(axis=0)</span></span><br><span class="line"><span class="comment"># lr_cm_true_label_sum = lr_confusion_score.sum(axis=1)</span></span><br><span class="line"><span class="comment"># # 计算正样本和负样本的精确率和召回率</span></span><br><span class="line"><span class="comment"># lr_model_precision, lr_model_recall = np.empty([2, 2], dtype=float), np.empty([2, 2], dtype=float)</span></span><br><span class="line"><span class="comment"># lr_model_precision[0][0], lr_model_precision[1][0] = lr_confusion_score[0][0] / lr_cm_pred_label_sum[0], \</span></span><br><span class="line"><span class="comment">#                                                      lr_confusion_score[1][0] / lr_cm_pred_label_sum[0]</span></span><br><span class="line"><span class="comment"># lr_model_precision[0][1], lr_model_precision[1][1] = lr_confusion_score[0][1] / lr_cm_pred_label_sum[1], \</span></span><br><span class="line"><span class="comment">#                                                      lr_confusion_score[1][1] / lr_cm_pred_label_sum[1]</span></span><br><span class="line"><span class="comment"># lr_model_recall[0][0], lr_model_recall[0][1] = lr_confusion_score[0][0] / lr_cm_true_label_sum[0], \</span></span><br><span class="line"><span class="comment">#                                                lr_confusion_score[0][1] / lr_cm_true_label_sum[0]</span></span><br><span class="line"><span class="comment"># lr_model_recall[1][0], lr_model_recall[1][1] = lr_confusion_score[1][0] / lr_cm_true_label_sum[1], \</span></span><br><span class="line"><span class="comment">#                                                lr_confusion_score[1][1] / lr_cm_true_label_sum[1]</span></span><br><span class="line"><span class="comment"># sns.heatmap(lr_confusion_score, annot=True, fmt="d", cmap="Blues", ax=ax_lr[0], square=True, linewidths=0.5)</span></span><br><span class="line"><span class="comment"># sns.heatmap(lr_model_precision, annot=True, fmt=".5f", cmap="Blues", ax=ax_lr[1], square=True, linewidths=0.5)</span></span><br><span class="line"><span class="comment"># sns.heatmap(lr_model_recall, annot=True, fmt=".5f", cmap="Blues", ax=ax_lr[2], square=True, linewidths=0.5)</span></span><br><span class="line"><span class="comment"># ax_lr[0].set_title("lr confusion matrix", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[1].set_title("lr model precision", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[2].set_title("lr model recall", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[0].set_xlabel("Predicted label", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[0].set_ylabel("True label", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[1].set_xlabel("Predicted label", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[1].set_ylabel("True label", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[2].set_xlabel("Predicted label", fontsize=16)</span></span><br><span class="line"><span class="comment"># ax_lr[2].set_ylabel("True label", fontsize=16)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"><span class="comment"># plt.close()</span></span><br><span class="line"><span class="comment"># f_lr.savefig("./pictures/lr model confusion matrix.jpg", dpi=200, bbox_inches="tight")</span></span><br><span class="line"><span class="comment"># # result</span></span><br><span class="line"><span class="comment"># # Lr model test accuracy:0.88</span></span><br><span class="line"><span class="comment"># # Lr model classification_score:</span></span><br><span class="line"><span class="comment"># #                precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment"># #          0.0       0.54      0.73      0.62     55318</span></span><br><span class="line"><span class="comment"># #          1.0       0.96      0.91      0.93    372097</span></span><br><span class="line"><span class="comment"># #    micro avg       0.88      0.88      0.88    427415</span></span><br><span class="line"><span class="comment"># #    macro avg       0.75      0.82      0.78    427415</span></span><br><span class="line"><span class="comment"># # weighted avg       0.90      0.88      0.89    427415</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># use randomforest model to train and predict</span></span><br><span class="line">print(<span class="string">"use randomforest model to train and predict"</span>)</span><br><span class="line">rf = RandomForestClassifier(n_estimators=<span class="number">200</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">rf.fit(x_train_sm_np, y_train_sm_np)</span><br><span class="line">rf_y_pred = rf.predict(x_test_nom_pd)</span><br><span class="line">rf_test_acc = accuracy_score(y_test, rf_y_pred)</span><br><span class="line">rf_classification_score = classification_report(y_test, rf_y_pred)</span><br><span class="line">print(<span class="string">"Rf model test accuracy:&#123;:.4f&#125;"</span>.format(rf_test_acc))</span><br><span class="line">print(<span class="string">"rf model classification_score:\n"</span>, rf_classification_score)</span><br><span class="line">rf_confusion_score = confusion_matrix(y_test, rf_y_pred)</span><br><span class="line"><span class="comment"># print(rf_confusion_score)</span></span><br><span class="line">f_rf, ax_rf = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># 混淆矩阵的y轴为true label,x轴为pred label</span></span><br><span class="line"><span class="comment"># 精确率,如对正类 ,所有预测为正类样本中中真实的正类占所有预测为正类的比例</span></span><br><span class="line"><span class="comment"># 召回率,如对正类,所有真实的正类样本中有多少被预测为正类的比例</span></span><br><span class="line"><span class="comment"># 分别计算预测预测的正样本数和负样本数以及真实的正样本数和负样本数</span></span><br><span class="line">rf_cm_pred_label_sum = rf_confusion_score.sum(axis=<span class="number">0</span>)</span><br><span class="line">rf_cm_true_label_sum = rf_confusion_score.sum(axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 计算正样本和负样本的精确率和召回率</span></span><br><span class="line">rf_model_precision, rf_model_recall = np.empty([<span class="number">2</span>, <span class="number">2</span>], dtype=float), np.empty([<span class="number">2</span>, <span class="number">2</span>], dtype=float)</span><br><span class="line">rf_model_precision[<span class="number">0</span>][<span class="number">0</span>], rf_model_precision[<span class="number">1</span>][<span class="number">0</span>] = rf_confusion_score[<span class="number">0</span>][<span class="number">0</span>] / rf_cm_pred_label_sum[<span class="number">0</span>], \</span><br><span class="line">                                                     rf_confusion_score[<span class="number">1</span>][<span class="number">0</span>] / rf_cm_pred_label_sum[<span class="number">0</span>]</span><br><span class="line">rf_model_precision[<span class="number">0</span>][<span class="number">1</span>], rf_model_precision[<span class="number">1</span>][<span class="number">1</span>] = rf_confusion_score[<span class="number">0</span>][<span class="number">1</span>] / rf_cm_pred_label_sum[<span class="number">1</span>], \</span><br><span class="line">                                                     rf_confusion_score[<span class="number">1</span>][<span class="number">1</span>] / rf_cm_pred_label_sum[<span class="number">1</span>]</span><br><span class="line">rf_model_recall[<span class="number">0</span>][<span class="number">0</span>], rf_model_recall[<span class="number">0</span>][<span class="number">1</span>] = rf_confusion_score[<span class="number">0</span>][<span class="number">0</span>] / rf_cm_true_label_sum[<span class="number">0</span>], \</span><br><span class="line">                                               rf_confusion_score[<span class="number">0</span>][<span class="number">1</span>] / rf_cm_true_label_sum[<span class="number">0</span>]</span><br><span class="line">rf_model_recall[<span class="number">1</span>][<span class="number">0</span>], rf_model_recall[<span class="number">1</span>][<span class="number">1</span>] = rf_confusion_score[<span class="number">1</span>][<span class="number">0</span>] / rf_cm_true_label_sum[<span class="number">1</span>], \</span><br><span class="line">                                               rf_confusion_score[<span class="number">1</span>][<span class="number">1</span>] / rf_cm_true_label_sum[<span class="number">1</span>]</span><br><span class="line">sns.heatmap(rf_confusion_score, annot=<span class="literal">True</span>, fmt=<span class="string">"d"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_rf[<span class="number">0</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">sns.heatmap(rf_model_precision, annot=<span class="literal">True</span>, fmt=<span class="string">".5f"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_rf[<span class="number">1</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">sns.heatmap(rf_model_recall, annot=<span class="literal">True</span>, fmt=<span class="string">".5f"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_rf[<span class="number">2</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">ax_rf[<span class="number">0</span>].set_title(<span class="string">"rf confusion matrix"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">1</span>].set_title(<span class="string">"rf model precision"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">2</span>].set_title(<span class="string">"rf model recall"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">0</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">0</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">1</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">1</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">2</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_rf[<span class="number">2</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_rf.savefig(<span class="string">"./pictures/rf model confusion matrix.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"><span class="comment"># Rf model test accuracy:0.9830</span></span><br><span class="line"><span class="comment"># rf model classification_score:</span></span><br><span class="line"><span class="comment">#                precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#          0.0       1.00      0.87      0.93     55318</span></span><br><span class="line"><span class="comment">#          1.0       0.98      1.00      0.99    372097</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#    micro avg       0.98      0.98      0.98    427415</span></span><br><span class="line"><span class="comment">#    macro avg       0.99      0.93      0.96    427415</span></span><br><span class="line"><span class="comment"># weighted avg       0.98      0.98      0.98    427415</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># random forest model feature contribution visualization</span></span><br><span class="line">feature_importances = rf.feature_importances_</span><br><span class="line"><span class="comment"># print(feature_importances)</span></span><br><span class="line"><span class="comment"># y=x.argsort()函数是将x中的元素从小到大排列，提取其对应的index(索引)</span></span><br><span class="line">indices = np.argsort(feature_importances)[::<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># 只取贡献度最高的30个特征来作图</span></span><br><span class="line">show_indices = indices[<span class="number">0</span>:<span class="number">30</span>]</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f, ax = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.barplot(x=feature_importances[show_indices], y=feature_names[show_indices], ax=ax)</span><br><span class="line">ax.set_title(<span class="string">"rf model feature importance top30"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">"feature importance score"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">"feature name"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f.savefig(<span class="string">"./pictures/rf model feature importance top30.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># use XGBoost model to train and predict</span></span><br><span class="line">print(<span class="string">"use XGBoost model to train and predict"</span>)</span><br><span class="line">xgb = XGBClassifier(n_estimators=<span class="number">200</span>, nthread=<span class="number">-1</span>)</span><br><span class="line">xgb.fit(x_train_sm_np, y_train_sm_np)</span><br><span class="line">xgb_y_pred = xgb.predict(x_test_nom_pd)</span><br><span class="line">xgb_test_acc = accuracy_score(y_test, xgb_y_pred)</span><br><span class="line">xgb_classification_score = classification_report(y_test, xgb_y_pred)</span><br><span class="line">print(<span class="string">"Xgb model test accuracy:&#123;:.4f&#125;"</span>.format(xgb_test_acc))</span><br><span class="line">print(<span class="string">"Xgb model classification_score:\n"</span>, xgb_classification_score)</span><br><span class="line">xgb_confusion_score = confusion_matrix(y_test, xgb_y_pred)</span><br><span class="line"><span class="comment"># print(xgb_confusion_score)</span></span><br><span class="line">f_xgb, ax_xgb = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># 混淆矩阵的y轴为true label,x轴为pred label</span></span><br><span class="line"><span class="comment"># 精确率,如对正类 ,所有预测为正类样本中中真实的正类占所有预测为正类的比例</span></span><br><span class="line"><span class="comment"># 召回率,如对正类,所有真实的正类样本中有多少被预测为正类的比例</span></span><br><span class="line"><span class="comment"># 分别计算预测预测的正样本数和负样本数以及真实的正样本数和负样本数</span></span><br><span class="line">xgb_cm_pred_label_sum = xgb_confusion_score.sum(axis=<span class="number">0</span>)</span><br><span class="line">xgb_cm_true_label_sum = xgb_confusion_score.sum(axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># print(xgb_cm_pred_label_sum,xgb_cm_true_label_sum)</span></span><br><span class="line"><span class="comment"># 计算正样本和负样本的精确率和召回率</span></span><br><span class="line">xgb_model_precision, xgb_model_recall = np.empty([<span class="number">2</span>, <span class="number">2</span>], dtype=float), np.empty([<span class="number">2</span>, <span class="number">2</span>], dtype=float)</span><br><span class="line">xgb_model_precision[<span class="number">0</span>][<span class="number">0</span>], xgb_model_precision[<span class="number">1</span>][<span class="number">0</span>] = xgb_confusion_score[<span class="number">0</span>][<span class="number">0</span>] / xgb_cm_pred_label_sum[<span class="number">0</span>], \</span><br><span class="line">                                                       xgb_confusion_score[<span class="number">1</span>][<span class="number">0</span>] / xgb_cm_pred_label_sum[<span class="number">0</span>]</span><br><span class="line">xgb_model_precision[<span class="number">0</span>][<span class="number">1</span>], xgb_model_precision[<span class="number">1</span>][<span class="number">1</span>] = xgb_confusion_score[<span class="number">0</span>][<span class="number">1</span>] / xgb_cm_pred_label_sum[<span class="number">1</span>], \</span><br><span class="line">                                                       xgb_confusion_score[<span class="number">1</span>][<span class="number">1</span>] / xgb_cm_pred_label_sum[<span class="number">1</span>]</span><br><span class="line">xgb_model_recall[<span class="number">0</span>][<span class="number">0</span>], xgb_model_recall[<span class="number">0</span>][<span class="number">1</span>] = xgb_confusion_score[<span class="number">0</span>][<span class="number">0</span>] / xgb_cm_true_label_sum[<span class="number">0</span>], \</span><br><span class="line">                                                 xgb_confusion_score[<span class="number">0</span>][<span class="number">1</span>] / xgb_cm_true_label_sum[<span class="number">0</span>]</span><br><span class="line">xgb_model_recall[<span class="number">1</span>][<span class="number">0</span>], xgb_model_recall[<span class="number">1</span>][<span class="number">1</span>] = xgb_confusion_score[<span class="number">1</span>][<span class="number">0</span>] / xgb_cm_true_label_sum[<span class="number">1</span>], \</span><br><span class="line">                                                 xgb_confusion_score[<span class="number">1</span>][<span class="number">1</span>] / xgb_cm_true_label_sum[<span class="number">1</span>]</span><br><span class="line">sns.heatmap(xgb_confusion_score, annot=<span class="literal">True</span>, fmt=<span class="string">"d"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_xgb[<span class="number">0</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">sns.heatmap(xgb_model_precision, annot=<span class="literal">True</span>, fmt=<span class="string">".5f"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_xgb[<span class="number">1</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">sns.heatmap(xgb_model_recall, annot=<span class="literal">True</span>, fmt=<span class="string">".5f"</span>, cmap=<span class="string">"Blues"</span>, ax=ax_xgb[<span class="number">2</span>], square=<span class="literal">True</span>, linewidths=<span class="number">0.5</span>)</span><br><span class="line">ax_xgb[<span class="number">0</span>].set_title(<span class="string">"xgb confusion matrix"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">1</span>].set_title(<span class="string">"xgb model precision"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">2</span>].set_title(<span class="string">"xgb model recall"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">0</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">0</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">1</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">1</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">2</span>].set_xlabel(<span class="string">"Predicted label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax_xgb[<span class="number">2</span>].set_ylabel(<span class="string">"True label"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f_xgb.savefig(<span class="string">"./pictures/xgb model confusion matrix.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br><span class="line"><span class="comment"># Xgb model test accuracy:0.9822</span></span><br><span class="line"><span class="comment"># Xgb model classification_score:</span></span><br><span class="line"><span class="comment">#                precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#          0.0       1.00      0.86      0.93     55318</span></span><br><span class="line"><span class="comment">#          1.0       0.98      1.00      0.99    372097</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#    micro avg       0.98      0.98      0.98    427415</span></span><br><span class="line"><span class="comment">#    macro avg       0.99      0.93      0.96    427415</span></span><br><span class="line"><span class="comment"># weighted avg       0.98      0.98      0.98    427415</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># xgboost model feature contribution visualization</span></span><br><span class="line">feature_importances = xgb.feature_importances_</span><br><span class="line"><span class="comment"># print(feature_importances)</span></span><br><span class="line"><span class="comment"># y=x.argsort()函数是将x中的元素从小到大排列，提取其对应的index(索引)</span></span><br><span class="line">indices = np.argsort(feature_importances)[::<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># 只取贡献度最高的30个特征来作图</span></span><br><span class="line">show_indices = indices[<span class="number">0</span>:<span class="number">30</span>]</span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">f, ax = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">sns.barplot(x=feature_importances[show_indices], y=feature_names[show_indices], ax=ax)</span><br><span class="line">ax.set_title(<span class="string">"xgb model feature importance top30"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">"feature importance score"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">"feature name"</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line">f.savefig(<span class="string">"./pictures/xgb model feature importance top30.jpg"</span>, dpi=<span class="number">200</span>, bbox_inches=<span class="string">"tight"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数据集介绍&quot;&gt;&lt;a href=&quot;#数据集介绍&quot; class=&quot;headerlink&quot; title=&quot;数据集介绍&quot;&gt;&lt;/a&gt;数据集介绍&lt;/h1&gt;&lt;p&gt;该数据集地址: &lt;a href=&quot;https://www.kaggle.com/wendykan/lending-c
      
    
    </summary>
    
    
      <category term="机器学习算法实践" scheme="https://wyg1996.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5/"/>
    
    
      <category term="机器学习算法实践" scheme="https://wyg1996.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>隐马尔可夫模型（HMM）原理</title>
    <link href="https://wyg1996.cn/2019/06/21/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%88HMM%EF%BC%89%E5%8E%9F%E7%90%86/"/>
    <id>https://wyg1996.cn/2019/06/21/隐马尔可夫模型（HMM）原理/</id>
    <published>2019-06-21T04:41:56.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概率图模型与隐马尔可夫模型"><a href="#概率图模型与隐马尔可夫模型" class="headerlink" title="概率图模型与隐马尔可夫模型"></a>概率图模型与隐马尔可夫模型</h1><p>概率图模型是一类用图来表示变量相关关系的模型。可以分为两类:一类是用有向无环图表示变量间的依赖关系，称为有向图模型；另一类是使用无向图表示变量间的相关关系，称为无向图模型。<br>隐马尔可夫模型（HMM）是一种有向图模型，它是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成不可观测的状态的序列称为状态序列；每个状态生成一个观测，再由此产生的观测的随机序列，称为观测序列。序列的每一个位置可以看作是一个时刻。</p><h1 id="隐马尔可夫模型原理"><a href="#隐马尔可夫模型原理" class="headerlink" title="隐马尔可夫模型原理"></a>隐马尔可夫模型原理</h1><h2 id="隐马尔可夫模型定义"><a href="#隐马尔可夫模型定义" class="headerlink" title="隐马尔可夫模型定义"></a>隐马尔可夫模型定义</h2><p>隐马尔可夫模型由初始概率分布、状态转移概率分布、观测概率分布确定。设Q是所有可能的状态的集合，V是所有可能的观测的集合，即:<br>$$<br>Q=(q_{1}, q_{2}, \cdots, q_{N}), \quad V=(v_{1}, v_{2}, \cdots, v_{M})<br>$$<br>其中，N是可能的状态数，M是可能的观测数。<br>I是长度为T的状态序列，O是对应的观测序列，即:<br>$$<br>I=\left(i_{1}, i_{2}, \cdots, i_{T}\right), \quad O=\left(o_{1}, o_{2}, \cdots, o_{T}\right)<br>$$<br>A为状态转移概率矩阵（NXN矩阵）:<br>$$<br>A=\left[a_{i j}\right]<br>$$<br>其中:<br>$$<br>a_{i j}=P\left(i_{t+1}=q_{j} | i_{t}=q_{i}\right), \quad i=1,2, \cdots, N ; j=1,2, \cdots, N<br>$$<br>即在时刻t处于状态qi的条件下在时刻t+1转移到状态qj的概率。<br>B为观测概率矩阵（NXM矩阵）:<br>$$<br>B=\left[b_{j}(k)\right]<br>$$<br>其中:<br>$$<br>b_{j}(k)=P\left(o_{t}=v_{k} | i_{t}=q_{j}\right), \quad k=1,2, \cdots, M ; j=1,2, \cdots, N<br>$$<br>是在时刻t处于状态qj的条件下生成观测vk的概率。<br>记π为初始状态概率向量:<br>$$<br>\pi=\left(\pi_{i}\right)<br>$$<br>其中:<br>$$<br>\pi_{i}=P\left(i_{1}=q_{i}\right), \quad i=1,2, \cdots, N<br>$$<br>表示时刻t=1处于状态qi的概率。<br>因此，HMM模型λ可以用三元符号表示，即：<br>$$<br>\lambda=(A, B, \pi)<br>$$<br>A,B,π称为HMM模型的三要素。<br><strong>举例:</strong><br>假设有4个盒子，每个盒子都有红白两种颜色的球，球的数量如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">盒子        1        2        3        4</span><br><span class="line">红球数      5        3        6        8</span><br><span class="line">白球数      5        7        4        2</span><br></pre></td></tr></table></figure><p>按下面的方法抽取球:<br>开始时，从4个盒子中等概率地抽取一个，再从盒子中随机抽一个球，记录颜色后放回。然后从当前盒子转移到下一个盒子，如果当前为盒子1，下一个盒子一定是2；如果当前为盒子2或3，以概率0.4和0.6转移到左边或右边的盒子；如果当前为盒子4，各以0.5概率停留在盒子4或转移到盒子3。转移后，再从盒子中随机抽一个球，记录颜色后放回。<br>现在假设我们要连续地抽5次。抽取结果如下:<br>$$<br>O=(红,红,白,白,红)<br>$$<br>这个例子中有两个随机序列:<br>盒子序列（状态序列）和球颜色序列（观测序列）。前者是隐藏的，后者是可观测的。<br>则状态集合Q和观测集合V为:<br>$$<br>Q=(盒子1,盒子2,盒子3,盒子4), \quad V=(红,白)<br>$$<br>状态序列和观测序列长度T=5。<br>开始时，从4个盒子中等概率地抽取一个，则初始概率分布π为:<br>$$<br>\pi=(0.25,0.25,0.25,0.25)^{\mathrm{T}}<br>$$<br>状态转移概率分布A为（由盒子转移规则得出）:<br>$$<br>A=\left[\begin{array}{cccc}{0} &amp; {1} &amp; {0} &amp; {0} \\ {0.4} &amp; {0} &amp; {0.6} &amp; {0} \\ {0} &amp; {0.4} &amp; {0} &amp; {0.6} \\ {0} &amp; {0} &amp; {0.5} &amp; {0.5}\end{array}\right]<br>$$<br>观测概率分布B为（由每个盒子红白球比例计算得出）:<br>$$<br>B=\left[\begin{array}{ll}{0.5} &amp; {0.5} \\ {0.3} &amp; {0.7} \\ {0.6} &amp; {0.4} \\ {0.8} &amp; {0.2}\end{array}\right]<br>$$</p><h2 id="两个基本假设和三个基本问题"><a href="#两个基本假设和三个基本问题" class="headerlink" title="两个基本假设和三个基本问题"></a>两个基本假设和三个基本问题</h2><p><strong>隐马尔可夫模型做了两个基本假设:</strong></p><ul><li>齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻t的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻t无关，即:<br>$$<br>P\left(i_{t} | i_{t-1}, o_{t-1}, \cdots, i_{1}, o_{1}\right)=P\left(i_{t} | i_{t-1}\right), \quad t=1,2, \cdots, T<br>$$</li><li>观测独立性假设，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他的观测和状态无关，即:<br>$$<br>P\left(o_{t} | i_{T}, o_{T}, i_{T-1}, o_{T-1}, \cdots, i_{t+1}, o_{t+1}, i_{t-1}, i_{t-1}, \cdots, i_{1}, o_{1}\right)=P\left(o_{t} | i_{t}\right)<br>$$</li></ul><p><strong>隐马尔可夫模型有3个基本问题:</strong></p><ol><li>概率计算问题。给定模型λ和观测序列O，计算在模型λ下观测序列O出现的慨率P（O|λ）。</li><li>学习问题。已知观测序列O，估计模型λ的参数，使得在该模型下观测序列概率P（O|λ）最大。即用极大似然估计的方法估计参数。</li><li>预测问题，也称为解码问题。已知模型λ和观测序列O，求对给定观测序列条件概率P（I|O）最大的状态序列。即给定观测序列，求最有可能的对应的状态序列。</li></ol><h2 id="概率计算问题-P（O-λ）的计算方法"><a href="#概率计算问题-P（O-λ）的计算方法" class="headerlink" title="概率计算问题:P（O|λ）的计算方法"></a>概率计算问题:P（O|λ）的计算方法</h2><p>给定模型λ和观测序列O，计算在模型λ下，观测序列O出现的概率P（O|λ）。</p><h3 id="直接计算方法（概念上可行，计算上不可行）"><a href="#直接计算方法（概念上可行，计算上不可行）" class="headerlink" title="直接计算方法（概念上可行，计算上不可行）"></a>直接计算方法（概念上可行，计算上不可行）</h3><p>列举所有可能的长度为T的状态序列I<br>$$<br>I=\left(i_{1}, i_{2}, \cdots, i_{T}\right)<br>$$<br>求各个状态序列I和给定的观测序列O的联合概率P（O,I∣λ），然后对所有可能的状态序列求和，得到P（O|λ）。<br>对某个状态序列I的概率为:<br>$$<br>P(I | \lambda)=\pi_{i_{1}} a_{i_{1} i_{2}} a_{i_{2} i_{3}} \cdots a_{i_{T-1} i_{T}}<br>$$<br>对上面的状态序列I，输入的观测序列O的概率P（O|I,λ）:<br>$$<br>P(O | I, \lambda)=b_{i_{1}}\left(o_{1}\right) b_{i_{2}}\left(o_{2}\right) \cdots b_{i_{T}}\left(o_{T}\right)<br>$$<br>O和I同时出现的l联合概率为:<br>$$<br>P(O, I | \lambda)=P(O | I, \lambda) P(I | \lambda)=\pi_{i_{1}} b_{i_{1}}\left(o_{1}\right) a_{i_{1} i_{2}} b_{i_{2}}\left(o_{2}\right) \cdots a_{i_{i-1} i_{\tau}} b_{i_{\tau}}\left(o_{T}\right)<br>$$<br>然后，对所有可能的状态序列I求和，得到观测序列O的概率P（O|λ）:<br>$$<br>P(O | \lambda)=\sum_{I} P(O | I, \lambda) P(I | \lambda)=<br>\sum_{i_{1}, i_{2}, \cdots, i_{T}} \pi_{i_{1}} b_{i_{1}}\left(o_{1}\right) a_{i_{1} i_{2}} b_{i_{2}}\left(o_{2}\right) \cdots a_{i_{i-1} i_{\tau}} b_{i_{\tau}}\left(o_{T}\right)<br>$$<br>通过这种计算方式的计算量非常大，其复杂度为:<br>$$<br>O\left(T N^{T}\right)<br>$$<br>实际是不可行的。在真实情况下，一般采用更有效的算法，即前向-后向算法。</p><h3 id="前向算法"><a href="#前向算法" class="headerlink" title="前向算法"></a>前向算法</h3><p>给定隐马尔可夫模型λ和观测序列O，定义到时刻t部分观测序列为:<br>$$<br>o_{1}, o_{2}, \cdots, o_{t}<br>$$<br>且状态为qi的概率为前向概率，记作:<br>$$<br>\alpha_{t}(i)=P\left(o_{1}, o_{2}, \cdots, o_{t}, i_{t}=q_{i} | \lambda\right)<br>$$<br><strong>下面要计算观测序列概率P（O∣λ）。</strong><br>计算初值:<br>$$<br>\alpha_{1}(i)=\pi_{i} b_{i}\left(o_{1}\right), \qquad i=1,2, \cdots, N<br>$$<br>递推，对t=1,2,⋯,T−1，有<br>$$<br>\alpha_{t+1}(i)=\left[\sum_{j=1}^{N} \alpha_{t}(j) a_{j i}\right] b_{i}\left(o_{t+1}\right), \quad i=1,2, \cdots, N<br>$$<br>终止:<br>$$<br>P(O | \lambda)=\sum_{i=1}^{N} \alpha_{T}(i)<br>$$<br>该算法时间复杂度为:<br>$$<br>O\left(N^{2} T\right)<br>$$<br>比直接计算法小很多。<br><strong>计算实例:</strong><br>现在有盒子和球模型λ=（A,B,π），状态集合Q=（1,2,3），观测集合V=（红，白）。<br>状态转移概率分布A、观测概率分布B、初始概率分布π为:<br>$$<br>A=\left[\begin{array}{lll}{0.5} &amp; {0.2} &amp; {0.3} \\ {0.3} &amp; {0.5} &amp; {0.2} \\ {0.2} &amp; {0.3} &amp; {0.5}\end{array}\right]<br>$$<br>$$<br>B=\left[\begin{array}{ll}{0.5} &amp; {0.5} \\ {0.4} &amp; {0.6} \\ {0.7} &amp; {0.3}\end{array}\right]<br>$$<br>$$<br>\pi=(0.2,0.4,0.4)^{\mathrm{T}}<br>$$<br>设T=3, O=（红,白,红），试用前向算法计算P（O|λ）。<br>计算初值:<br>$$<br>\alpha_{1}(1)=\pi_{1} b_{1}\left(o_{1}\right)=0.10 \\ \alpha_{1}(2)=\pi_{2} b_{2}\left(o_{1}\right)=0.16 \\ \alpha_{1}(3)=\pi_{3} b_{3}\left(o_{1}\right)=0.28<br>$$<br>递推计算:<br>$$<br>\alpha_{2}(1)=\left[\sum_{i=1}^{3} \alpha_{1}(i) a_{i 1}\right] b_{1}\left(o_{2}\right)=0.154 \times 0.5=0.077 \\ \alpha_{2}(2)=\left[\sum_{i=1}^{3} \alpha_{1}(i) a_{i 2}\right] b_{2}\left(o_{2}\right)=0.184 \times 0.6=0.1104 \\ \alpha_{2}(3)=\left[\sum_{i=1}^{3} \alpha_{1}(i) a_{13}\right] b_{3}\left(o_{2}\right)=0.202 \times 0.3=0.0606<br>$$<br>$$<br>\alpha_{3}(1)=\left[\sum_{i=1}^{3} \alpha_{2}(i) a_{i 1}\right] b_{1}\left(o_{3}\right)=0.04187 \\ \alpha_{3}(2)=\left[\sum_{i=1}^{3} \alpha_{2}(i) a_{i 2}\right] b_{2}\left(o_{3}\right)=0.03551 \\<br>\alpha_{3}(3)=\left[\sum_{i=1}^{3} \alpha_{2}(i) a_{i 3}\right] b_{3}\left(o_{3}\right)=0.05284<br>$$<br>终止:<br>$$<br>P(O | \lambda)=\sum_{i=1}^{3} \alpha_{3}(i)=0.13022<br>$$</p><h3 id="后向算法"><a href="#后向算法" class="headerlink" title="后向算法"></a>后向算法</h3><p>给定隐马尔可夫模型λ和观测序列O，定义在时刻t状态为qi的条件下，从t+1到T的部分观测序列为:<br>$$<br>o_{t+1}, o_{t+2}, \cdots, o_{T}<br>$$<br>的概率为后向概率，记作:<br>$$<br>\beta_{t}(i)=P\left(o_{t+1}, o_{t+2}, \cdots, o_{T} | i_{t}=q_{i}, \lambda\right)<br>$$<br><strong>下面要计算观测序列概率P（O∣λ）。</strong><br>初值:<br>$$<br>\beta_{T}(i)=1, \quad i=1,2, \cdots, N<br>$$<br>递推，对t=1, 2,…,T-1，有:<br>$$<br>\beta_{t}(i)=\sum_{j=1}^{N} a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j), \quad i=1,2, \cdots, N<br>$$<br>终止:<br>$$<br>P(O | \lambda)=\sum_{i=1}^{N} \pi_{i} b_{i}\left(o_{1}\right) \beta_{1}(i)<br>$$<br><strong>利用前向概率和后向概率的定义可以将观测序列概率P（O∣λ）统一写成:</strong><br>$$<br>P(O | \lambda)=\sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{t}(i) a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j), \quad t=1,2, \cdots, T-1<br>$$<br>此式当t=1和t=T-1时分别为前向算法和后向算法的终止公式。</p><h3 id="一些概率值与期望的计算"><a href="#一些概率值与期望的计算" class="headerlink" title="一些概率值与期望的计算"></a>一些概率值与期望的计算</h3><p><strong>利用前向概率和后向慨率，可以得到关于单个状态和两个状态概率的计算公式。</strong></p><ol><li>给定模型λ和观测O，在时刻t处于状态qi的概率，记为<br>$$<br>\gamma_{t}(i)=P\left(i_{t}=q_{i} | O, \lambda\right)<br>$$<br>可以通过前向后向概率计算。即:<br>$$<br>\gamma_{t}(i)=P\left(i_{t}=q_{i} | O, \lambda\right)=\frac{P\left(i_{t}=q_{i}, O | \lambda\right)}{P(O | \lambda)}<br>$$<br>由前向概率αt（i）和后向概率βt（i）定义可知:<br>$$<br>\alpha_{t}(i) \beta_{t}(i)=P\left(i_{t}=q_{i}, O | \lambda\right)<br>$$<br>故有:<br>$$<br>\gamma_{t}(i)=\frac{\alpha_{t}(i) \beta_{t}(i)}{P(O | \lambda)}=\frac{\alpha_{t}(i) \beta_{t}(i)}{\sum_{j=1}^{N} \alpha_{t}(j) \beta_{t}(j)}<br>$$</li><li>给定模型A和观测序列O，在时刻t处于状态qi且在时刻t+1处于状态qj的概率，记为<br>$$<br>\xi_{t}(i, j)=P\left(i_{t}=q_{i}, i_{t+1}=q_{j} | O, \lambda\right)<br>$$<br>可以通过前向后向概率计算:<br>$$<br>\xi_{i}(i, j)=\frac{P\left(i_{t}=q_{i}, i_{t+1}=q_{j}, O | \lambda\right)}{P(O | \lambda)}=\frac{P\left(i_{t}=q_{i}, i_{t+1}=q_{j}, O | \lambda\right)}{\sum_{i=1}^{N} \sum_{j=1}^{N} P\left(i_{t}=q_{i}, i_{t+1}=q_{j}, O | \lambda\right)}<br>$$<br>又<br>$$<br>P\left(i_{t}=q_{i}, i_{t+1}=q_{j}, O | \lambda\right)=\alpha_{t}(i) a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j)<br>$$<br>于是化简得<br>$$<br>\xi_{t}(i, j)=\frac{\alpha_{t}(i) a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j)}{\sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{t}(i) a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j)}<br>$$</li><li>将γt（i）和ξt（i,j）对各个时刻t求和，可以得到一些有用的期望值:<br>在观测O下状态i出现的期望值:<br>$$<br>\sum_{t=1}^{T} \gamma_{t}(i)<br>$$<br>在观刻O下由状态i转移的期望值:<br>$$<br>\sum_{t=1}^{T-1} \gamma_{t}(i)<br>$$<br>在观测O下由状态i转移到状态j的期望值:<br>$$<br>\sum_{i=1}^{T-1} \xi_{t}(i, j)<br>$$</li></ol><h2 id="学习问题-监督学习方法和非监督学习方法（Baum-Welch算法）"><a href="#学习问题-监督学习方法和非监督学习方法（Baum-Welch算法）" class="headerlink" title="学习问题:监督学习方法和非监督学习方法（Baum-Welch算法）"></a>学习问题:监督学习方法和非监督学习方法（Baum-Welch算法）</h2><p>已知观测序列O，估计模型λ的参数，使得在该模型下观测序列概率P（O|λ）最大。即用极大似然估计的方法估计参数。</p><h3 id="监督学习方法"><a href="#监督学习方法" class="headerlink" title="监督学习方法"></a>监督学习方法</h3><p>假设已给训练数据集包含S个长度相同的观测序列和对应的状态序列<br>$$<br>(\left(O_{1}, I_{1}\right),\left(O_{2}, I_{2}\right), \cdots,\left(O_{S}, I_{S}\right))<br>$$<br>下面利用极大似然估计法来估计隐马尔可夫模型的参数。</p><ol><li>转移概率aij的估计:<br>设样本中时刻t处于状态i时刻t+1转移到状态j的频数为Aij，那么状态转移概率aij的估计是<br>$$<br>\hat a_{i j}=\frac{A_{j j}}{\sum_{j=1}^{N} A_{i j}}, \quad i=1,2, \cdots, N ; j=1,2, \cdots, N<br>$$</li><li>观测概率bj（k）的估计:<br>设样本中状态为j并观测为k的频数是Bjk，那么状态为j观测为k的概率bj（k）的估计是:<br>$$<br>\hat b_{j}(k)=\frac{B_{j k}}{\sum_{k=1}^{M} B_{j k}}, \quad j=1,2, \cdots, N_{i} \quad k=1,2, \cdots, M<br>$$</li><li>初始状态概率π的估计πi为S个样本中初始状态为qi的频率。</li></ol><p>由于监督学习需要使用训练数据， 而人工标注训练数据往往代价很高，有时就会利用非监督学习的方法。</p><h3 id="非监督学习方法——Baum-Welch算法"><a href="#非监督学习方法——Baum-Welch算法" class="headerlink" title="非监督学习方法——Baum-Welch算法"></a>非监督学习方法——Baum-Welch算法</h3><p>由于监督学习需要大量的标注数据，需要耗费很多的人力物力，因此，有时会采用非监督学习方法来进行参数估计。假设给定训练数据集只包含S个长度为T的观测序列而没有对应的状态序列<br>$$<br>(O_{1}, O_{2}, \cdots, O_{s})<br>$$<br>我们的目标是学习隐马尔可夫模型λ=（A,B,π）的参数。我们将观测序列数据看作观测数据O，状态序列数据看作不可观测的隐数据I，那么隐马尔可夫模型实际上是一个含有隐变量的概率模型:<br>$$<br>P(O | \lambda)=\sum_{I} P(O | I, \lambda) P(I | \lambda)<br>$$<br>它的参数学习可以由EM算法实现。</p><ol><li>确定完全数据的对数似然函数:<br>所有观测数据写成:<br>$$<br>O=\left(o_{1}, o_{2}, \cdots, o_{T}\right)<br>$$<br>所有隐数据写成:<br>$$<br>I=\left(i_{1}, i_{2}, \cdots, i_{T}\right)<br>$$<br>完全数据是:<br>$$<br>(O, I)=\left(o_{1}, o_{2}, \cdots, o_{T}, i_{1}, i_{2}, \cdots, i_{T}\right)<br>$$<br>完全数据的对数似然函数是:<br>$$<br>\log P(O, I | \lambda)<br>$$</li><li>EM算法的E步:求Q函数<br>$$<br>Q(\lambda, \overline{\lambda})=\sum_{I} \log P(O, I | \lambda) P(O, I | \overline{\lambda})<br>$$<br>左边等式中第一个λ是要极大化的隐马尔可夫模型参数，第二个λ是隐马尔可夫模型参数的当前估计值。<br>$$<br>P(O, I | \lambda)=\pi_{i_{1}} b_{i_{1}}\left(o_{1}\right) a_{i_{1} i_{2}} b_{i_{2}}\left(o_{2}\right) \cdots a_{i_{1-1} i_{T}} b_{i_{T}}\left(o_{T}\right)<br>$$<br>于是函数Q可以写成:<br>$$<br>Q(\lambda, \overline{\lambda})=\sum_{I} \log \pi_{i1} P(O, I | \overline{\lambda}) \\</li></ol><p>+\sum_{I}\left(\sum_{t=1}^{T-1} \log a_{i, t+1}\right) P(O, I | \overline{\lambda})+\sum_{I}\left(\sum_{t=1}^{T} \log b_{i_{i}}\left(o_{t}\right)\right) P(O, I | \overline{\lambda})<br>$$<br>式中求和都是对所有训练数据的序列总长度T进行的。</p><ol start="3"><li>EM 算法的M步:极大化Q函数，求模型参数A、B、π。<br>由于要极大化的参数在上式中单独地出现在3个项中，所以只需对各项分别极大化。<br>第一项可写为:<br>$$<br>\sum_{I} \log \pi_{i_{0}} P(O, I | \overline{\lambda})=\sum_{i=1}^{N} \log \pi_{i} P\left(O, i_{1}=i | \overline{\lambda}\right)<br>$$<br>πi满足约束条件:<br>$$<br>\sum_{i=1}^{N} \pi_{i}=1<br>$$<br>利用拉格朗日乘子法，写出拉格朗日函数:<br>$$<br>\sum_{i=1}^{N} \log \pi_{i} P\left(O, i_{1}=i | \overline{\lambda}\right)+\gamma\left(\sum_{i=1}^{N} \pi_{i}-1\right)<br>$$<br>对其求偏导数并令结果为0:<br>$$<br>\frac{\partial}{\partial \pi_{i}}\left[\sum_{i=1}^{N} \log \pi_{i} P\left(O, i_{1}=i | \overline{\lambda}\right)+\gamma\left(\sum_{i=1}^{N} \pi_{i}-1\right)\right]=0<br>$$<br>得:<br>$$<br>P\left(O, i_{1}=i | \overline{\lambda}\right)+\gamma \pi_{i}=0<br>$$<br>对i求和得到γ:<br>$$<br>\gamma=-P(O | \overline{\lambda})<br>$$<br>代回偏导数为0的式子中，得<br>$$<br>\pi_{i}=\frac{P\left(O, i_{1}=i | \overline{\lambda}\right)}{P(O | \overline{\lambda})}<br>$$<br>第二项可写为:<br>$$<br>\sum_{I}\left(\sum_{t=1}^{T-1} \log a_{i_{t}i_{t+1}}\right) P(O, I | \overline{\lambda})=\sum_{i=1}^{N} \sum_{j=1}^{N} \sum_{t=1}^{T-1} \log a_{i j} P\left(O, i_{t}=i, i_{t+1}=j | \overline{\lambda}\right)<br>$$<br>类似第一项，应用具有约束条件<br>$$<br>\sum_{j=1}^{N} a_{i j}=1<br>$$<br>的拉格朗日乘了法可以求出<br>$$<br>a_{i j}=\frac{\sum_{i=1}^{T-1} P\left(O, i_{t}=i, i_{t+1}=j | \overline{\lambda}\right)}{\sum_{t=1}^{T-1} P\left(O, i_{t}=i | \overline{\lambda}\right)}<br>$$<br>第三项可写为:<br>$$<br>\sum_{I}\left(\sum_{t=1}^{T} \log b_{i_{t}}\left(o_{t}\right)\right) P(O, I | \overline{\lambda})=\sum_{j=1}^{N} \sum_{t=1}^{T} \log b_{j}\left(o_{t}\right) P\left(O, i_{t}=j | \overline{\lambda}\right)<br>$$<br>同样用拉格朗日乘子法，约束条件是<br>$$<br>\sum_{k=1}^{M} b_{j}(k)=1<br>$$<br>注意只有在ot=vk时bj（ot）对bj（k）的偏导数才不为0，以I（ot=vk）表示。求得:<br>$$<br>b_{j}(k)=\frac{\sum_{t=1}^{T} P\left(O, i_{t}=j | \overline{\lambda}\right) I\left(o_{t}=v_{k}\right)}{\sum_{t=1}^{T} P\left(O, i_{t}=j | \overline{\lambda}\right)}<br>$$<br>将上面第三步中三项最终推出的公式中的各概率分别用γt（i），ξt（i,j）表示，则可将相应的公式写成:<br>$$<br>a_{i j}=\frac{\sum_{t=1}^{T-1} \xi_{t}(i, j)}{\sum_{t=1}^{T-1} \gamma_{t}(i)}<br>$$<br>$$<br>b_{j}(k)=\frac{\sum_{t=1,o_{t}=v_{k}}^{T} \gamma_{t}(j)}{\sum_{t=1}^{T} \gamma_{t}(j)}<br>$$<br>$$<br>\pi_{i}=\gamma_{1}(i)<br>$$<br>上面三式就是Baum-Welch算法。</li></ol><p><strong>Baum-Welch算法的流程如下:</strong></p><ul><li>初始化，对n=0，选取aij（0），bj（k）（0），πi（0），得到模型<br>$$<br>\lambda^{(0)}=\left(A^{(0)}, B^{(0)}, \pi^{(0)}\right)<br>$$</li><li>递推。对n=1,2,…，<br>$$<br>a_{i j}^{(n+1)}=\frac{\sum_{t=1}^{T-1} \xi_{t}(i, j)}{\sum_{t=1}^{T-1} \gamma_{t}(i)}<br>$$<br>$$<br>b_{j}(k)^{(n+1)}=\frac{\sum_{t=1, o_{t}=v_{k}}^{T} \gamma_{t}(j)}{\sum_{t=1}^{T} \gamma_{t}(j)}<br>$$<br>$$<br>\pi_{i}^{(n+1)}=\gamma_{1}(i)<br>$$<br>右端各值按<br>$$<br>O=\left(o_{1}, o_{2}, \cdots, o_{T}\right)<br>$$<br>$$<br>\lambda^{(n)}=\left(A^{(n)}, B^{(n)}, \pi^{(n)}\right)<br>$$<br>计算。</li><li>终止。得到模型参数:<br>$$<br>\lambda^{(n+1)}=\left(A^{(n+1)}, B^{(n+1)}, \pi^{(n+1)}\right)<br>$$</li></ul><h2 id="预测问题（解码问题）-近似算法和维特比（Viterbi）算法"><a href="#预测问题（解码问题）-近似算法和维特比（Viterbi）算法" class="headerlink" title="预测问题（解码问题）:近似算法和维特比（Viterbi）算法"></a>预测问题（解码问题）:近似算法和维特比（Viterbi）算法</h2><p>已知模型λ和观测序列O，求对给定观测序列条件概率P（I|O）最大的状态序列。即给定观测序列，求最有可能的对应的状态序列。</p><h3 id="近似算法"><a href="#近似算法" class="headerlink" title="近似算法"></a>近似算法</h3><p>近似算法的思想是，在每个时刻t选择在该时刻最有可能出现的状态it，从而得到一个状态序列<br>$$<br>I^{\ast}=\left(i_{1}^{\ast}, i_{2}^{\ast}, \cdots, i_{T}^{\ast}\right)<br>$$<br>将它作为预测的结果。<br>给定隐马尔可夫模型λ和观测序列O，在时刻t处于状态qi的概率为：<br>$$<br>\gamma_{t}(i)=\frac{\alpha_{t}(i) \beta_{t}(i)}{P(O | \lambda)}=\frac{\alpha_{t}(i) \beta_{t}(i)}{\sum_{j=1}^{N} \alpha_{t}(j) \beta_{t}(j)}<br>$$<br>在每一时刻t最有可能的状态it*是<br>$$<br>i_{t}^{\ast}=\arg \max_{1 \leqslant i \leqslant N}\left[\gamma_{t}(i)\right], \quad t=1,2, \cdots, T<br>$$<br>从而得到状态序列I。<br>虽然近似计算思想简单，但是预测的序列可能有实际不发生的部分，即有可能出现转移概率为0的相邻状态，没法保证整体上的状态序列是最有可能的。</p><h3 id="维特比（Viterbi）算法"><a href="#维特比（Viterbi）算法" class="headerlink" title="维特比（Viterbi）算法"></a>维特比（Viterbi）算法</h3><p>维特比算法则通过动态规划求概率最大的路径（最优路径），这时每一条路径即对应着一个状态序列。维特比算法从时刻t=1开始，递推地计算在时刻t状态为i的各条部分路径的最大概率，直到得到时刻t=T状态为i的各条路径的最大概率，时刻t=T的最大概率记为最优路径的概率P，最优路径的终结点iT也同时得到，之后，从终结点开始，由后向前逐步求得结点<br>$$<br>i_{T-1}^{\ast}, \cdots, i_{1}^{\ast}<br>$$<br>最终得到最优状态序列（最优路径）:<br>$$<br>I^{\ast}=\left(i_{1}^{\ast}, i_{2}^{\ast}, \cdots, i_{T}^{<em>}\right)<br>$$<br>首先定义两个变量δ和ψ，定义在时刻t状态为i的所有单个路径<br>$$<br>\left(i_{1}, i_{2}, \cdots, i_{t}\right)<br>$$<br>中概率最大值为<br>$$<br>\delta_{t}(i)=\max <em>{i</em>{1}, i_{2}, \cdots, t-1} P\left(i_{t}=i, i_{t-1}, \cdots, i_{1}, o_{t}, \cdots, o_{1} | \lambda\right), \quad i=1,2, \cdots, N<br>$$<br>由定义可得δ的递推公式：<br>$$<br>\delta_{t+1}(i)=\max_{i_{1}, i_{2}, \cdots, i_{t}} P\left(i_{t+1}=i, i_{t}, \cdots, i_{1}, o_{t+1}, \cdots, o_{1} | \lambda\right) \\<br>=\max_{1 \leqslant j \leqslant N}\left[\delta_{t}(j) a_{j i}\right] b_{i}\left(o_{t+1}\right), \quad i=1,2, \cdots, N ; t=1,2, \cdots, T-1<br>$$<br>定义在时刻t状态为i的所有单个路径<br>$$<br>\left(i_{1}, i_{2}, \cdots, i_{t-1}, i\right)<br>$$<br>中概率最大的路径的第t−1个结点为:<br>$$<br>\psi_{t}(i)=\arg \max_{1 \leqslant j \leqslant N}\left[\delta_{t-1}(j) a_{j i}\right], \quad i=1,2, \cdots, N<br>$$<br>*</em>维特比算法流程如下:**</p><ul><li>输入模型λ和观测O；</li><li>初始化<br>$$<br>\delta_{1}(i)=\pi_{i} b_{i}\left(o_{1}\right), \qquad i=1,2, \cdots, N \\<br>\psi_{1}(i)=0, \qquad i=1,2, \cdots, N<br>$$</li><li>递推，对t=2,3,···,T<br>$$<br>\delta_{t}(i)=\max_{1 \leq j \leq N}\left[\delta_{t-1}(j) a_{j i}\right] b_{i}\left(o_{t}\right), \quad i=1,2, \cdots, N \\<br>\psi_{t}(i)=\arg \max_{1 \leqslant j \leqslant N}\left[\delta_{t-1}(j) a_{j i}\right], \quad i=1,2, \cdots, N<br>$$</li><li>终止<br>$$<br>P^{\ast}=\max_{1 \leq i \leqslant N} \delta_{T}(i) \\<br>i_{T}^{\ast}=\arg \max_{1 \leq i \leqslant N}\left[\delta_{T}(i)\right]<br>$$</li><li>最终路径回溯，对t=T-l，T-2，…，1<br>$$<br>i_{t}^{\ast}=\psi_{t+1}\left(i_{t+1}^{\ast}\right)<br>$$<br>得到最优路径<br>$$<br>I^{\ast}=\left(i_{1}^{\ast}, i_{2}^{\ast}, \cdots, i_{T}^{\ast}\right)<br>$$</li></ul><p><strong>用比较通俗的语言来解释以下维特比算法的流程:</strong></p><ul><li><p>首先我们根据上面的监督学习方法从原始训练集数据中计算得到隐马尔可夫模型的三个参数：转移矩阵A，发射矩阵B，初始概率π。然后我们输入一个观测序列（观测1，观测2…观测s）。</p></li><li><p>对观测1:<br>设状态用字母a表示，a从1取到N。根据下面的计算公式，我们分别计算N个P（观测1，状态a）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">P(观测1，状态a)=P(观测1-&gt;状态a)*P(状态a初始概率)=发射矩阵中状态a观测为观测1的概率*初始概率矩阵中初始状态为a的概率</span><br></pre></td></tr></table></figure></li><li><p>对观测2:<br>设状态用字母b表示，b从1取到N。根据下面的计算公式，我们分别计算N个P（观测2，状态b）。注意max中有N项，最终取最大值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">P(观测2，状态b)=max&#123; P(观测1，状态a)*P(状态a-&gt;状态b)，a从1取到N，所以中括号里共N项&#125;*P(观测2-&gt;状态b)=max&#123;上一步计算出的N个P(观测1，状态a)*每一个状态a对应的状态a转移到状态b的概率&#125;* 发射矩阵中状态b观测为观测2的概率</span><br></pre></td></tr></table></figure></li><li><p>对观测3…观测s:<br>设观测序号为s，状态用字母t表示，t从1取到N。m表示观测s的前一个观测可能的状态取值，从1取到N。根据下面的计算公式，对每个观测，我们分别计算N个P（观测s，状态t）。注意max中有N项，最终取最大值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">P(观测s，状态t)=max&#123; P(观测s-1，状态m)*P(状态m-&gt;状态t)，m从1取到N，所以中括号里共N项&#125;*P(观测s-&gt;状态t)=max&#123;上一步的N个P(观测s-1，状态m)*每一个状态m对应的状态m转移到状态t的概率&#125;*发射矩阵中状态t观测为观测s的概率</span><br></pre></td></tr></table></figure></li><li><p>假设s已经是最后一个观测值，从所有概率值中选出最大的那个P（观测s，状态t），则状态t就是我们的观测s的最优状态。由于前面的步骤我们使用了回溯法，在每一步时记录了取得的max值时的P（观测s-1，状态m）的状态m，这样我们就可以通过回溯一步一步从最后一个观测值开始得到每一个观测值的最优状态。最后得到一个和观测序列对应的完整的状态序列。这就是维特比算法。</p></li></ul><p><strong>维特比算法计算举例:</strong><br>假设已知:<br>状态集合:健康，发烧；<br>观测集合:正常、冷、头晕；<br>初始状态概率矩阵:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">健康发烧</span><br><span class="line">0.60.4</span><br></pre></td></tr></table></figure><p>转移矩阵:注意转移矩阵的行是上一个状态，列是下一个状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">状态健康发烧</span><br><span class="line">健康0.70.3</span><br><span class="line">发烧0.40.6</span><br></pre></td></tr></table></figure><p>发射矩阵:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">正常冷头晕</span><br><span class="line">健康0.50.40.1</span><br><span class="line">发烧0.10.30.6</span><br></pre></td></tr></table></figure><p>现在知道某个人三天的观测序列为:正常，冷，头晕，求这个人这三天最有可能的状态序列？<br>对第一个状态：正常</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">P(第一天正常，第一天健康)=P(正常-&gt;健康)*P(健康的初始概率)=0.5*0.6=0.3</span><br><span class="line">P(第一天正常，第一天发烧)=P(正常-&gt;发烧)*P(发烧的初始概率)=0.1*0.4=0.04</span><br><span class="line"></span><br><span class="line">记录每个概率P取的状态，P(第一天正常，第一天健康)取的是健康；P(第一天正常，第一天发烧)取的是发烧。</span><br></pre></td></tr></table></figure><p>对第二个状态:冷</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">P(第二天冷，第二天健康)=max&#123; P(第一天正常，第一天健康)*P(健康-&gt;健康)，P(第一天正常，第一天发烧)*P(发烧-&gt;健康)&#125;* P(观测冷为健康)=max&#123;0.3*0.7,0.04*0.4&#125;*0.4=0.084</span><br><span class="line">P(第二天冷,第二天发烧)= max&#123; P(第一天正常，第一天健康)*P(健康-&gt;发烧)，P(第一天正常，第一天发烧)*P(发烧-&gt;发烧)&#125;* P(观测冷为发烧)=max&#123;0.3*0.3,0.04*0.6&#125;*0.3=0.027</span><br><span class="line"></span><br><span class="line">记录每个P中max取的上一次的概率，P(第二天冷，第二天健康)取的是P(第一天正常，第一天健康)；P(第二天冷,第二天发烧)取的是P(第一天正常，第一天健康)。</span><br></pre></td></tr></table></figure><p>对第三个状态:头晕</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">P(第三天头晕，第三天健康)= max&#123; P(第二天冷，第二天健康)*P(健康-&gt;健康)，P(第二天冷,第二天发烧)*P(发烧-&gt;健康)&#125;* P(观测头晕为健康)=max&#123;0.084*0.7,0.027*0.4&#125;*0.1=0.00588</span><br><span class="line">P(第三天头晕，第三天发烧)= max&#123; P(第二天冷，第二天健康)*P(健康-&gt;发烧)，P(第二天冷,第二天发烧)*P(发烧-&gt;发烧)&#125;* P(观测头晕为发烧)=max&#123;0.084*0.3,0.027*0.6&#125;*0.6=0.01512</span><br><span class="line"></span><br><span class="line">记录每个P中max取的上一次的概率，P(第三天头晕，第三天健康)取的是P(第二天冷，第二天健康)；P(第三天头晕，第三天发烧)取的是P(第二天冷，第二天健康)。</span><br></pre></td></tr></table></figure><p>回溯:<br>最后一个状态最大概率是P（第三天头晕，第三天发烧）= 0.01512，记录对应状态是发烧。max中取的是P（第二天冷，第二天健康）。即倒数第二个观测取的状态是健康。然后继续回溯，P（第二天冷，第二天健康）max中取的是P（第一天正常，第一天健康），所以第一个观测取的状态也是健康。<br>所以最终的最优状态序列为:健康、健康、发烧。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;概率图模型与隐马尔可夫模型&quot;&gt;&lt;a href=&quot;#概率图模型与隐马尔可夫模型&quot; class=&quot;headerlink&quot; title=&quot;概率图模型与隐马尔可夫模型&quot;&gt;&lt;/a&gt;概率图模型与隐马尔可夫模型&lt;/h1&gt;&lt;p&gt;概率图模型是一类用图来表示变量相关关系的模型。可以分
      
    
    </summary>
    
    
      <category term="机器学习原理推导" scheme="https://wyg1996.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86%E6%8E%A8%E5%AF%BC/"/>
    
    
      <category term="机器学习原理推导" scheme="https://wyg1996.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86%E6%8E%A8%E5%AF%BC/"/>
    
  </entry>
  
  <entry>
    <title>八度卷积Octave Convolution原理</title>
    <link href="https://wyg1996.cn/2019/06/03/%E5%85%AB%E5%BA%A6%E5%8D%B7%E7%A7%AFOctave-Convolution%E5%8E%9F%E7%90%86/"/>
    <id>https://wyg1996.cn/2019/06/03/八度卷积Octave-Convolution原理/</id>
    <published>2019-06-03T10:04:11.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Octave-Convolution介绍"><a href="#Octave-Convolution介绍" class="headerlink" title="Octave Convolution介绍"></a>Octave Convolution介绍</h1><p>论文:Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution<br>论文地址:<a href="https://export.arxiv.org/pdf/1904.05049" target="_blank" rel="noopener">https://export.arxiv.org/pdf/1904.05049</a> 。<br>代码地址:<a href="https://github.com/facebookresearch/OctConv" target="_blank" rel="noopener">https://github.com/facebookresearch/OctConv</a> 。</p><p>在本文的Octave Convolution方法之前，传统的CNN卷积神经网络是直接在图像上（也称为空域）进行卷积的。<br>对于数字图像这种离散的空域信号，频率大小表示信号变化的剧烈程度。频率越大，变化越剧烈，频率越小，信号越平缓，对应到图像中，高频信号往往是图像中的边缘信号和噪声信号，而低频信号包含图像中的物体轮廓及背景等信号。<br>因此，在传统的图像处理中，我们可以借助傅里叶变换将图像（空间域）转为频域图（频率域）。一张图像转换为频域图后可分为高频部分和低频部分。其中低频部分表示图像对应的灰度图中变化平缓的部分（图片中物体的整体结构），而高频部分表示图像对应的灰度图中变化剧烈的部分（图片中各个物体的边缘细节和噪声），通过只保留频域图的低频部分（理想低通滤波、Butterworth低通滤波）或只保留频域图的高频部分（理想高通滤波、Butterworth高通滤波），我们将保留后的频域图通过逆傅里叶变换还原成图像（空间域），可以实现对图像的平滑（理想低通滤波、Butterworth低通滤波）或边缘提取（理想高通滤波、Butterworth高通滤波）。比如，一张企鹅的图片，其频域图的低频部分代表图像上企鹅这个物体内部的白色大肚皮、黑色的北部以及图片的背景；其频域图的高频部分代表图像上企鹅这个物体的边缘线条部分。<br>如果对传统图像处理中的频域变换这块还是不太清楚，建议看这本书中相应章节:数字图像处理（第三版）（美）冈萨雷斯，（美）伍兹。<br><strong>在本文中，作者受传统图像处理中的频域变换的启发，认为特征图也有对应的频域图，其频域图也分为低频部分和高频部分。显然，低频分量是存在冗余的，在编码过程中可以节省。为了降低空间冗余，作者将CNN中的空域上的特征图映射为频域图，并设计了一种全新的卷积运算：Octave Convolution (OctConv)，使用低维度的张量来储存和处理特征图对应的频域图中的低频部分，通过降低低频特征的分辨率，降低了内存和计算成本。Octave一词表示”八音阶”或”八度”，在音乐里降8个音阶表示频率减半。</strong></p><p>作者认为卷积层的输出特征映射也可以分解为不同空间频率的特征，并提出了一种新的多频特征表示方法，将高频和低频特征映射存储到不同的组中。显然，低频分量中存在大量冗余，在编码过程中可以节省。为了适应新的特征表示，本文提出Octave Convolution（OctConv）方法，它接收包含两个频率的特征输入，对应地输出两个频率的特征图。作为传统卷积的替代，OctConv消耗的内存和计算资源都大大减少。此外，OctConv利用相应的（低频）卷积处理低频信息，有效地扩大了原始像素空间的感受野，从而提高识别性能。<br>由于OctConv主要侧重于处理多空间频率的特征映射并减少其空间冗余，它与现有的方法是相交且互补的，现有的方法侧重于构建更好的CNN拓扑结构，减少卷积特征映射中的信道冗余和密集模型参数中的冗余。此外，与利用多尺度信息的方法不同，OctConv 可以很容易地部署为即插即用单元，以替代卷积，而不需要改变网络结构或需要超参数调优。<br>我们的实验证明，通过简单地用OctConv代替传统卷积，可以持续提高流行的2D CNN模型的ImageNet图像识别性能，包括ResNet ResNeXt, DenseNet, MobileNet，以及 SE-Net。采用OctConv的Oct-ResNet-152超过了手工设计的state-of-the-art网络，并且所需的内存和计算成本更低。<br><strong>本文的贡献可以总结如下:</strong></p><ul><li>将原始卷积特征映射分解成不同空间频率的两组特征图，并分别以相应的频率处理不同的卷积，相隔一个八度 (octave)。由于可以降低低频图的分辨率，因此能够节省存储和计算。这也有助于每一层获得更大的感受野，以捕获更多的上下文信息。</li><li>设计了一种即插即用的运算，名为OctConv，用来代替传统的卷积运算。OctConv直接对新的特征表示进行运算，减少了空间冗余。更重要的是，OctConv在实践中速度很快，接近了理论的极限。</li><li>我们广泛研究了所提出的OctConv在用于图像和视频任务的各种骨干CNN上的特性，并获得了显著的性能提高，甚至可以与最好的AutoML网络相媲美。</li></ul><h1 id="Octave-Feature-Representation（八度特征表示）"><a href="#Octave-Feature-Representation（八度特征表示）" class="headerlink" title="Octave Feature Representation（八度特征表示）"></a>Octave Feature Representation（八度特征表示）</h1><p>对于普通卷积而言，所有输入和输出特征图的通道都有着一样的分辨率。而本文提出的八度特征表示中，低频特征图的分辨率仅有高频特征图的一半。<br>使用:<br>$$<br>X \in R^{c\times h \times w}<br>$$<br>表示输入的特征图。作者将输入的特征图X分解为高频特征图XH和低频特征图XL（其实就是原始特征图的c个通道，拿出(1-αin)c个通道作为高频特征图输入XH，剩余αin x c个通道作为低频特征图输入XL）:<br>$$<br>X=(X^{H}, X^{L})<br>$$<br>高频部分:<br>$$<br>X^{H} \in R^{(1-\alpha) \times c\times h \times w}<br>$$<br>表示物体边缘细节。<br>低频部分:<br>$$<br>X^{L} \in R^{\alpha \times c\times h \times w}<br>$$<br>其中，α∈[0,1]表示channel被分配到低频部分的比率。</p><p>由于输入特征的空间分辨率不同，传统卷积不能直接对这种表示进行操作。避免这个问题的一种简单方法是将低频部分XL上采样到原始的空间分辨率，将它与XH连接起来，然后进行卷积，这将导致额外的计算和内存开销。为了充分利用紧凑的多频特征表示，我们提出Octave Convolution，它可以直接在分解后的X张量上运行，而不需要任何额外的计算或内存开销。</p><h1 id="Octave-Convolution（八度卷积）"><a href="#Octave-Convolution（八度卷积）" class="headerlink" title="Octave Convolution（八度卷积）"></a>Octave Convolution（八度卷积）</h1><p><strong>传统卷积（Vanilla Convolution）:</strong><br>令:<br>$$<br>W \in R^{c \times k \times k}<br>$$<br>表示一个kxk，c个通道的卷积核。<br>$$<br>X, Y \in R^{c \times h \times w}<br>$$<br>表示输入张量和输出张量。<br>$$<br>Y_{p, q} \in R^{c}<br>$$<br>中的每个feature map可以下面的公式计算:<br>$$<br>Y_{p, q}=\sum_{i, j \in N_{k}} W_{i+\frac{k-1}{2}, j+\frac{k-1}{2}}^{\top} X_{p+i, q+j}<br>$$<br>其中（p, q）为位置坐标。<br>$$<br>N_{k}=\left[(i, j) : i=\left(-\frac{k-1}{2}, \ldots, \frac{k-1}{2}\right), j=\left(-\frac{k-1}{2}, \ldots, \frac{k-1}{2}\right)\right]<br>$$<br>即对应卷积核大小的特征图上（p, q）的局部邻域。为简单起见，在所有的方程中我们省略填充，我们假设k是一个奇数，并且输入和输出数据具有相同的维数，即:<br>$$<br>c_{i n}=c_{o u t}=c<br>$$<br><strong>八度卷积（Octave Convolution）:</strong><br>设八度卷积的输入为Y，那么Y的八度特征表示为:<br>$$<br>Y=(Y^{H}, Y^{L})<br>$$<br>用:<br>$$<br>Y^{A \rightarrow B}<br>$$<br>表示从特征图A到B的卷积更新过程。则有:<br>$$<br>Y^{H}=Y^{H \rightarrow H}+Y^{L \rightarrow H},Y^{L}=Y^{H \rightarrow L}+Y^{L \rightarrow L}<br>$$<br>其中<br>$$<br>Y^{H \rightarrow H}, Y^{L \rightarrow L}<br>$$<br>表示高频率特征和低频率特征的频率内信息更新。<br>$$<br>Y^{L \rightarrow H}, Y^{H \rightarrow L}<br>$$<br>表示低频率与高频率间信息交流。<br>为了完成卷积运算，本文将卷积核也分为两部分WH、WL，分别用于卷积XH、XL。每个部分又可以进一步分为频率内和频率间两个部分:<br>$$<br>\left[W^{H}, W^{L}\right],W^{H}=\left[W^{H \rightarrow H}, W^{L \rightarrow L}\right],<br>W^{L}=\left[W^{L \rightarrow L}, W^{H \rightarrow L}\right]<br>$$<br>WH→H是传统卷积，因为输入、输出图像尺寸一样大；对于WL→H部分，我们先对输入图像进行升采样（upsample），再执行传统卷积。WL→L也是传统卷积，WH→L先执行的是降采样，然后再执行传统卷积。<br>为了控制输入和输出特征图的低频信息部分的比例，作者令第一层和最后一层八度卷积层的超参数:<br>$$<br>\alpha_{i n}=0, \alpha_{o u t}=\alpha<br>$$<br>而中间的八度卷积层超参数则设为:<br>$$<br>\alpha_{i n}=\alpha_{o u t}=\alpha<br>$$<br>如此一来，即可完成即插即用的替换。 </p><p>现在设输入的八度特征为:<br>$$<br>Y=(Y^{H}, Y^{L})<br>$$<br>与之相对应的输出也由两部分组成，即高频特征输出与低频特征输出，如下:<br>$$<br>Y_{p, q}^{H}=Y_{p, q}^{H \rightarrow H}+Y_{p, q}^{L \rightarrow H},Y_{p, q}^{L}=Y_{p, q}^{L \rightarrow L}+Y_{p, q}^{H \rightarrow L}<br>$$<br>其中第一个等式求得为高频输出特征，第二个等式求得为低频输出特征。对于高频特征图，它的频率内信息更新过程就是普通卷积过程，而频率间的信息交流过程，则可以对使用上采样操作然后再进行普通卷积。类似地，对于低频特征图，它的频率内信息更新过程就是普通卷积过程，而频率间的信息交流过程则通过对进行平均池化操作（下采样）然后再进行普通卷积。<br>具体计算公式如下:<br>$$<br>Y_{p, q}^{H}=Y_{p, q}^{H \rightarrow H}+Y_{p, q}^{L \rightarrow H}<br>$$<br>$$<br>=\sum_{i, j \in N_{k}} W_{i+\frac{k-1}{2}, j+\frac{k-1}{2}}^{\top} X_{p+i, q+j}^{H}+\sum_{i, j \in N_{k}} W_{i+\frac{k-1}{2}, j+\frac{k-1}{2}}^{\top} X_{\left(\left\lfloor\frac{p}{2}\right]+i\right),\left(\left\lfloor\frac{q}{2}\right]+j\right)}^{L}<br>$$<br>$$<br>Y_{p, q}^{L}=Y_{p, q}^{L \rightarrow L}+Y_{p, q}^{H \rightarrow L}<br>$$<br>$$<br>=\sum_{i, j \in N_{k}} W_{i+\frac{k-1}{2}, j+\frac{k-1}{2}}^{\top} X_{p+i, q+j}^{L}+\sum_{i, j \in N_{k}} W_{i+\frac{k-1}{2}, j+\frac{k-1}{2}}^{\top} X_{(2 \ast p+0.5+i),(2 \ast q+0.5+j)}^{H}<br>$$<br>在八度卷积中，高频特征图卷积需要经过下采样，随后才能卷积到低频特征图。在这里作者分析了两种降采样方式：stride=2的convolution与average pooling。作者发现，使用步长为2的卷积之后（高频到低频），再经过上采样（低频到高频）会导致出现中心偏移的错位情况（misalignment），如果此时继续进行特征图融合中会造成特征不对齐，进而影响性能。所以作者最终选择了average pooling来进行下采样。<br>（2p + 0.5 +i）,（2q + 0.5 +j）中的0.5是因为让从H到L下采样之后的特征图与input一致以消除不对齐。<br>最终输出的高频输出特征与低频输出特征如下:<br>$$<br>Y^{H}=f\left(X^{H} ; W^{H \rightarrow H}\right)+\text { upsample }\left(f\left(X^{L} ; W^{L \rightarrow H}\right), 2\right)<br>$$<br>$$<br>Y^{L}=f\left(X^{L} ; W^{L \rightarrow L}\right)+f\left(\text{average pool}\left(X^{H}, 2\right) ; W^{H \rightarrow L}\right) )<br>$$<br><strong>Octave卷积核:</strong><br>Octave卷积核的尺寸如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">WH→H                            WH→L</span><br><span class="line">k x (1-αin)cin x (1-αout)cout   k x (1-αin)cin x αoutcout</span><br><span class="line">WL→H                            WL→L</span><br><span class="line">k x αincin x (1-αout)cout       k x αincin x αoutcout</span><br><span class="line">WH→H和WL→H一起产生高频特征图</span><br><span class="line">WL→L和WH→L一起产生低频特征图</span><br></pre></td></tr></table></figure><p>对于八度卷积而言，由于低频特征图的分辨率变小，实际上八度卷积的感受野反而变大了，所以在使用卷积核去卷积低频特征图情况下，八度卷积有着几乎等价于普通卷积2倍普通卷积感受野的能力，这可以进一步帮助八度卷积层捕捉远距离的上下文信息从而提升性能。<br>低频特征所使用的低频所占比例α的值不同，则网络需要的计算力和内存消耗也不同。当α=0时（即没有低频成分），OctConv就会退化为普通卷积。α=1.0时，计算力和内存消耗只有α=0时的25%。需要注意的是，无论比例α选择是多少，OctConv卷积核的参数数量都与同尺寸的普通卷积核相同（kxk的Octave卷积核与普通的kxk卷积核具有完全相同的参数量）。</p><h1 id="实验和结论"><a href="#实验和结论" class="headerlink" title="实验和结论"></a>实验和结论</h1><p>在实验和评估部分，我们验证了Octave Convolution在2D和3D网络中的有效性和效率。我们分别进行了ImageNet上图像分类的研究，然后将其与目前最先进的方法进行了比较。然后，我们用Kinetics-400和dynamics 600数据集，证明所提出的OctConv也适用于3D CNN。采用OctConv的模型比基线模型更有效、更准确。<br>本文针对传统CNN模型中普遍存在的空间冗余问题，提出了一种新颖的Octave Convolution运算，分别存储和处理低频和高频特征，提高了模型的效率。Octave卷积具有足够的通用性，可以代替常规的卷积运算，可以在大多数二维和三维CNNs中使用，无需调整模型结构。除了节省大量的计算和内存外，Octave Convolution还可以通过在低频段和高频段之间进行有效的通信，增大接收域的大小，从而获得更多的全局信息，从而提高识别性能。我们在图像分类和视频动作记录方面进行了广泛的实验验证了我们的方法在识别性能和模型效率之间取得更好权衡的优越性，不仅在失败的情况下，而且在实践中也是如此。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Octave-Convolution介绍&quot;&gt;&lt;a href=&quot;#Octave-Convolution介绍&quot; class=&quot;headerlink&quot; title=&quot;Octave Convolution介绍&quot;&gt;&lt;/a&gt;Octave Convolution介绍&lt;/h1&gt;&lt;
      
    
    </summary>
    
    
      <category term="深度学习原理推导" scheme="https://wyg1996.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86%E6%8E%A8%E5%AF%BC/"/>
    
    
      <category term="深度学习原理推导" scheme="https://wyg1996.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86%E6%8E%A8%E5%AF%BC/"/>
    
  </entry>
  
  <entry>
    <title>人脸检测模型FaceBoxes原理</title>
    <link href="https://wyg1996.cn/2019/06/01/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8BFaceBoxes%E5%8E%9F%E7%90%86/"/>
    <id>https://wyg1996.cn/2019/06/01/人脸检测模型FaceBoxes原理/</id>
    <published>2019-06-01T09:49:24.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="FaceBoxes介绍"><a href="#FaceBoxes介绍" class="headerlink" title="FaceBoxes介绍"></a>FaceBoxes介绍</h1><p>论文:FaceBoxes: A CPU Real-time Face Detector with High Accuracy<br>论文地址:<a href="https://arxiv.org/pdf/1708.05234.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1708.05234.pdf</a> 。<br>代码地址:<a href="https://github.com/sfzhang15/FaceBoxes" target="_blank" rel="noopener">https://github.com/sfzhang15/FaceBoxes</a> caffee版；<a href="https://github.com/zisianw/FaceBoxes.PyTorch" target="_blank" rel="noopener">https://github.com/zisianw/FaceBoxes.PyTorch</a> PyTorch版。</p><p>人脸识别是计算机视觉和模式识别的基础问题，在过去几十年取得了长足进步。但是由于计算量较大，在CPU上的实时检测一直没有很好的被解决。挑战主要来自于人脸探测器的两个要求：杂乱背景中人脸的大视觉变化要求人脸探测器准确地解决复杂的人脸和非人脸分类问题; 可能的面部位置和面部尺寸的大搜索空间进一步提出了时间效率要求。为了满足这两个相互矛盾的要求，人脸检测主要以两种方式进行了深入的研究。早期的方法是基于手动构建的特征，这种方法在CPU上的速度尚可，但是面对种类繁多的图像变体精确度不足。另一种是基于CNN的方法，它们的性能很好，但是在CPU上过于耗时，很难达到实时效果。 这两种方式各有优势。前者速度快，后者具有高精度。为了在速度和准确度上表现良好，一个自然的想法是结合这两种方法的优点。<br>因此，提出了基于CNN的级联方法，将CNN学习的特性放入级联框架中，以提高性能并保持高效。然而，在基于CNN的级联方法中存在三个问题：它们的速度与图像上的面部数量负相关。随着面部数量的增加，速度会急剧下降；基于级联的探测器分别优化每个组件，使训练过程极其复杂，最终模型次优；对于VGA分辨率图像，它们在CPU上的运行时效率约为14FPS，这不足以达到实时速度。<br>在本文中，受到Fast R-CNN中的RPN以及SSD中的多尺度机制的启发，我们开发了一种具有CPU实时速度的最先进的人脸检测器。具体来说，我们提出了一种名为FaceBoxes的新型人脸检测器，它只包含一个完全卷积的神经网络，并且可以进行端到端的训练。所提出的方法具有轻量且强大的网络结构，其由快速消化的卷积层（RDCL）和多尺度卷积层（MSCL）组成。 RDCL旨在使FaceBoxes能够在CPU上实现实时速度，而MSCL旨在丰富不同层上的感知域和离散锚点，以处理各种面部比例。此外，我们提出了一种新的锚点致密化策略，使输入图像上不同类型的锚点具有相同的密度，从而显着提高了小脸部的召回率。<br>因此，对于VGA分辨率图像，我们的人脸检测器在单个CPU内核上运行速度为20FPS，使用GPU运行速率为125FPS。更重要的是，FaceBoxes的速度在图像上的人脸数变化时是不变的。我们全面评估了这种方法，并在几个面部检测基准数据集上展示了最先进的检测性能，包括AFW，PASCAL面和FDDB。</p><h1 id="RDCL-Rapidly-Digested-Convolutional-Layers（快速消化的卷积层）"><a href="#RDCL-Rapidly-Digested-Convolutional-Layers（快速消化的卷积层）" class="headerlink" title="RDCL:Rapidly Digested Convolutional Layers（快速消化的卷积层）"></a>RDCL:Rapidly Digested Convolutional Layers（快速消化的卷积层）</h1><p>大多数基于CNN的面部检测方法通常受到时间成本的限制，特别是在CPU设备上。 更准确地说，当输入，内核和输出的大小很大时，CPU的卷积操作非常耗时。 我们的RDCL（Rapidly Digested Convolutional LayersRDCL）旨在通过适当的内核大小快速缩小输入空间大小，同时减少输出通道的数量，使FaceBox在CPU设备上达到实时速度。<br><strong>具体措施如下:</strong></p><ul><li>缩小输入的空间大小：为了快速缩小输入的空间大小，我们的RDCL为其卷积和池化层设置了一系列大步幅。Conv1、Pool1、Conv2和Pool2的步幅分别为4、2、2和2。 RDCL的总步幅大小为32，这意味着输入空间大小快速减少了32倍；</li><li>选择合适的内核大小：一个网络中前几个层的内核大小应该很小以便加速，同时它也应该足够大以减轻空间大小减小带来的信息损失。为了保持高效和有效，我们分别为Conv1，Conv2和所有Pool层选择7×7、5×5和3×3内核大小。</li><li>减少输出通道的数量：我们利用CReLU激活功能来减少输出通道的数量。 CReLU的动机来自CNN中的观察，即较低层中的滤波器形成对（即，具有相反相位的滤波器）。 根据这一观察，CReLU可以通过在应用ReLU之前简单地连接否定输出来使输出通道的数量加倍。 使用CReLU可显着提高速度，精度下降可忽略不计。</li></ul><h1 id="MSCL-Multiple-Scale-Convolutional-Layers（多尺度卷积层）"><a href="#MSCL-Multiple-Scale-Convolutional-Layers（多尺度卷积层）" class="headerlink" title="MSCL:Multiple Scale Convolutional Layers（多尺度卷积层）"></a>MSCL:Multiple Scale Convolutional Layers（多尺度卷积层）</h1><p>Faster R-CNN网络中的RPN中的锚点仅与最后的卷积层相关联，其最终卷积层的特征和分辨率太弱而不能处理各种大小的特征图。 其次，anchor相应的层使用一系列不同的尺度来检测人脸，但只有单一的感受野，不能匹配不同尺度的人脸。<br>为解决上述两个问题，我们的MSCL（Multiple Scale Convolutional Layers）作了以下改进:</p><ul><li>沿网络深度维度的多尺度设计。我们设计的MSCL由几层组成。 这些层逐渐减小尺寸并形成多尺度特征图。我们的默认锚点与多尺度特征图（即Inception3、Conv3 2和Conv4 2）相关联。我们设置不同尺度的anchor，分别与不同层级的layer关联，在不同尺度分别检测。</li><li>沿网络宽度维度的多尺度设计。 为了学习不同比例的面部的视觉模式，锚相关层的输出特征应该对应于各种尺寸的感受野，这可以通过初始模块轻松实现。 Inception模块由具有不同内核的多个卷积分支组成。 这些分支作为沿网络宽度维度的多尺度设计，能够丰富感受野。MSCL中的前三层基于Inception模块。使用inception模块，内部使用不同大小的卷积核，可以捕获到更多的尺度信息。</li></ul><h1 id="Anchor-densification-strategy（anchor密度策略）"><a href="#Anchor-densification-strategy（anchor密度策略）" class="headerlink" title="Anchor densification strategy（anchor密度策略）"></a>Anchor densification strategy（anchor密度策略）</h1><p>本文使用了一些小技巧使得anchor在不同层特征图上密度相同，有效提高了小型人脸的召回率。在人脸识别中，我们一般把anchor的长宽比置为1，因为一般方框可以正好框住一张人脸。anchor的间隔对应的就是stride size，比如某一层的stride size为64，anchor是256x256，意味着每64个像素就有一个256x256的anchor。Inception3层的锚点比例为32、64和128像素，Conv3 2层和Conv4 2层分别为256和512像素。定义anchor密度为:<br>$$<br>A_{\text {density}}=A_{\text {scale}} / A_{\text {interval}}<br>$$<br>这里，Ascale是锚的尺度，Ainterval是锚的平铺间隔。 默认锚点的平铺间隔分别为32、32、32、64和128。 根据上式，相应的密度为1、2、4、4和4，显然在不同尺度上anchor的密度不均衡。相比大的anchor（128-512），小的anchor（32和64）过于稀疏，将会导致在小脸检测中低的召回率。<br>为消除这种不平衡，我们提出了一种新的锚点密度化策略。 具体来说，为了使一种类型的锚点密集n次，我们在一个感受野的中心周围均匀地平铺n的平方个（本来是1个）锚点。在论文中，为了提高小锚的平铺密度，我们的策略用于将32×32锚4次和64×64锚2次加密，这样就可以保证不同尺度的anchor有相同的密度。</p><h1 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h1><p>本小节介绍了训练数据集，数据增强，匹配策略，损失函数，难负样本挖掘和其他实现细节。 训练数据集。 我们的模型训练WIDER FACE训练子集的880张图像。<br><strong>数据增强策略。每个训练图像按以下数据增强策略顺序处理：</strong></p><ul><li>颜色失真：应用一些照片度量失真。</li><li>随机裁剪：我们从原始图像中随机裁剪五个方形补丁：一个是最大的方形补丁，其他的大小介于原始图像尺寸的[0.3,1]之间。 然后我们随意选择一个补丁用于后续操作。</li><li>缩放变换：随机裁剪后，所选方形拼贴的大小调整为1024×1024。</li><li>水平翻转：调整大小的图像以0.5的概率水平翻转。 </li><li>人脸bbox过滤器：如果人脸bbox的中心位于上面处理的图像中，我们会保留bbox的重叠部分，然后过滤掉这些高度或宽度小于20像素的bbox。</li></ul><p><strong>匹配策略:</strong><br>在训练时需要判断哪个anchor是和哪个face bounding box相关的。首先使用jaccard overlap将每个脸和anchor对应起来，然后对anchor和任意脸jaccard overlap高于阈值（0.35）的匹配起来。<br><strong>损失函数:</strong><br>和Faster R-CNN中的RPN用同样的loss,一个2分类的softmax loss用来做分类，smooth L1用来做回归。<br><strong>难负样本挖掘:</strong><br>在anchor匹配后，大多数anchor都是负样本，导致正样本和负样本严重不均衡。为了更快更稳定的训练，将他们按照loss值排序并选取最高的几个，保证正样本和负样本的比例最高不超过3:1。<br><strong>其他实施细节:</strong><br>使用Xavier随机初始化。优化器SGD，momentum:0.9，weight decay:5e-4，batch size:32，迭代最大次数:120k，初始80k迭代learning rate:1e-3，80-100k迭代用1e-4，,100-120k迭代用1e-5，使用caffe实现。我们的方法在Caffe库中实现。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>在这项工作中，我们提出了一种新颖的人脸检测器，它在速度和准确性方面都具有卓越的性能。 所提出的方法具有轻量且强大的网络结构，其由RDCL和MSCL组成。 前者使FaceBoxes能够实现实时速度，后者旨在丰富感知领域和不同层次上的锚点以处理各种尺度的人脸。 此外，提出了一种新的锚点密集化策略，以提高小脸的召回率。 实验表明，我们的贡献使Face Boxes在常见的人脸检测基准测试中具有最先进的性能。 所提出的探测器非常快，在CPU上实现了VGA分辨率图像的20FPS，并且可以在GPU上加速到125FPS。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;FaceBoxes介绍&quot;&gt;&lt;a href=&quot;#FaceBoxes介绍&quot; class=&quot;headerlink&quot; title=&quot;FaceBoxes介绍&quot;&gt;&lt;/a&gt;FaceBoxes介绍&lt;/h1&gt;&lt;p&gt;论文:FaceBoxes: A CPU Real-time Face
      
    
    </summary>
    
    
      <category term="人脸检测与识别" scheme="https://wyg1996.cn/categories/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="人脸检测与识别" scheme="https://wyg1996.cn/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>基于关键点的Anchor Free目标检测算法：CornerNet、CornerNet-Lite、两种CenterNet、FCOS原理</title>
    <link href="https://wyg1996.cn/2019/05/31/%E5%9F%BA%E4%BA%8E%E5%85%B3%E9%94%AE%E7%82%B9%E7%9A%84Anchor%20Free%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%EF%BC%9ACornerNet%E3%80%81CornerNet-Lite%E3%80%81%E4%B8%A4%E7%A7%8DCenterNet%E3%80%81FCOS%E5%8E%9F%E7%90%86/"/>
    <id>https://wyg1996.cn/2019/05/31/基于关键点的Anchor Free目标检测算法：CornerNet、CornerNet-Lite、两种CenterNet、FCOS原理/</id>
    <published>2019-05-31T10:25:45.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于关键点的Anchor-Free目标检测算法"><a href="#基于关键点的Anchor-Free目标检测算法" class="headerlink" title="基于关键点的Anchor Free目标检测算法"></a>基于关键点的Anchor Free目标检测算法</h1><p>2018到2019年间，出现了许多基于关键点的one stage目标检测算法。这类算法的特点是不使用Anchor  boxes作为先验框，所以又叫做Anchor-Free目标检测算法。<br><strong>本文主要介绍五种有代表性的Anchor-Free目标检测算法:</strong><br>CornerNet:使用左上角和右下角的两个角点来表示一个目标；<br>CornerNet-Lite:CornetNet-Lite是对CornetNet进行优化，具体分为两种算法CornerNet-Saccade（高准确率优先）和CornerNet-Squeeze（高实时性优先）；<br>CenterNet:Keypoint Triplets for Object Detection:使用中心点、左上角点和右下角点三个关键点来表示一个目标；<br>CenterNet:Objects as Points:用一个中心点+长宽值来表示一个目标；<br>FCOS:训练集中目标用左上角点和右下角点表示，特征图每个点映射回原图得到原图中的一个点，使用该点+点到框的四个距离来表示一个目标。</p><p>注意上面有两个CenterNet，但是它们是两种Anchor-Free目标检测模型，请注意区分。</p><h1 id="CornerNet"><a href="#CornerNet" class="headerlink" title="CornerNet"></a>CornerNet</h1><p>论文:CornerNet: Detecting Objects as Paired Keypoints<br>论文地址:<a href="https://arxiv.org/pdf/1808.01244.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1808.01244.pdf</a> 。<br>代码地址:<a href="https://github.com/umich-vl/CornerNet" target="_blank" rel="noopener">https://github.com/umich-vl/CornerNet</a> 。<br>这篇文章中提出了一种新的目标检测方法CornerNet，使用单个卷积神经网络将目标边界框检测为一对关键点（即边界框的左上角和右下角）。通过将目标检测为成对关键点，我们消除了现有的one stage检测器设计中对一组anchors的需要。除此之外文章还引入了corner pooling，这是一种新型的池化层，可以帮助网络更好地定位边界框的角点。CornerNet在MS COCO上实现了42.1％的AP，优于所有现有的one stage检测器。<br>以往的YOLOv3、SSD等one stage检测器使用anchor boxes作为先验框，检测器将anchor boxes密集地分布在图像上，通过对anchor boxes进行评分，并通过回归来改进其坐标来生成最终的边界框预测。<br><strong>但anchor boxes的使用有两个缺点:</strong></p><ul><li>首先，我们通常需要非常多的anchor boxes以确保与大多数ground truth充分重叠。 但实际只有一小部分anchor boxes与ground truth重叠，这在正负样本之间造成了巨大的不平衡，同时也减慢了训练速度；</li><li>其次，anchor boxes的使用引入了许多超参数和设计选择。 这些包括多少个box，大小和宽高比。 这些选择主要是通过ad-hoc启发式方法进行的，并且当与多尺度架构相结合时可能会变得更加复杂，其中单个网络在多个分辨率下进行单独预测，每个尺度使用不同的特征和它自己的一组anchor boxes。</li></ul><p>CornerNet不使用anchor boxes，而将一个目标的位置检测化为检测边界框的左上角和右下角这对关键点的问题。我们使用单个卷积网络来预测同一物体类别的所有实例的左上角的热图，所有右下角的热图，以及每个检测到的角点的嵌入向量。 嵌入用于对属于同一目标的一对角点进行分组——训练网络以预测它们的类似嵌入。 这种方法极大地简化了网络的输出，并且无需设计anchor boxes。<br><strong>作者认为基于关键点的目标检测要优于anchor的检测方法主要有两方面的原因:</strong><br>由于框的中心依赖于四个边，很难进行定位。而定位角点只需要定位两条边，同时引入了coner pool的先验，因此，定位更加简单；角点高效的离散了框的解空间，只需要O（wh）的角点可以表示O（w2h2）的anchor box的数量。</p><h2 id="CornerNet网络结构"><a href="#CornerNet网络结构" class="headerlink" title="CornerNet网络结构"></a>CornerNet网络结构</h2><p>首先1个7×7的卷积层将输入图像尺寸缩小为原来的1/4（论文中输入图像大小是511×511，缩小后得到128×128大小的输出）。<br>然后通过Hourglass Network网络进行特征提取，该网络通过串联2个hourglass module组成。每个hourglass module都是先通过一系列的降采样操作缩小输入的大小，然后通过上采样恢复到输入图像大小，因此该部分的输出特征图大小还是128×128，整个hourglass network的深度是104层。<br>然后将网络得到的特征输入到两个模块Top-left Corner pooling和Bottom-right Corner pooling提取关键点的特征。对于每个Corner Pooling模块，后面接一个预测模块，包括三个部分：目标框的左上角关键点和右下角关键点的类别分类（Heatmaps），每个目标的一对关键点（Embeddings），以及基于坐标回算目标目标位置时的偏置（offsets）。有了两个角点的heatmaps，embeding vectors，及Offset，我们在后面可以通过后处理的方式得到最终的边框。<br>heatmaps是输出预测角点信息，可以用维度为CHW的特征图表示，其中C表示目标的类别（注意没有背景类），这个特征图的每个通道都是一个mask，mask的每个值范围为0到1，表示该点是角点的分数；embeddings用来对预测的corner点做group，也就是找到属于同一个目标的左上角角点和右下角角点；offsets用来对预测框做微调，这是因为从输入图像中的点映射到特征图时有量化误差，offsets就是用来输出这些误差信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">                                                          --&gt;Heatmaps</span><br><span class="line">                      |</span><br><span class="line">                               -&gt;Top-left Corner pooling--&gt;-&gt;Embeddings</span><br><span class="line">                              /                           |</span><br><span class="line">                             /                            --&gt;Offsets</span><br><span class="line">    /</span><br><span class="line">输入图片-&gt;Hourglass Network--&gt;</span><br><span class="line">\</span><br><span class="line"> \                                --&gt;Heatmaps</span><br><span class="line">  \                               |</span><br><span class="line">   -&gt;Bottom-right Corner pooling--&gt;-&gt;Embeddings</span><br><span class="line">                                  |</span><br><span class="line">                                  --&gt;Offsets</span><br></pre></td></tr></table></figure><p>CornerNet使用Hourglass Network作为CornerNet的骨干网络。 Hourglass Network之后是两个预测模块。 一个模块预测左上角角点，另一个模块预测右下角角点，每个模块都有自己的corner pooling模块，在预测热图、嵌入和偏移之前，池化来自沙漏网络的特征。corner pooling后包括三部分：目标框的左上角关键点和右下角关键点的类别分类（Heatmaps），每个目标的一对关键点（Embeddings），以及基于坐标回算目标目标位置时的偏置（offsets）。 与许多其他探测器不同，我们不使用不同尺度的特征来检测不同大小的物体。 Heatmaps表示不同物体类别的角的位置，一组为左上角角点，另一组为右下角角点。 Embeddings预测每个检测到的角的嵌入向量，使得来自同一目标的两个角的嵌入之间的距离很小。 为了产生更紧密的边界框，网络还预测offsets以稍微调整角的位置。 通过预测的热图（ Heatmaps），嵌入（Embeddings）和偏移（offsets），我们应用一个简单的后处理算法来获得最终的边界框。</p><h2 id="Heatmaps"><a href="#Heatmaps" class="headerlink" title="Heatmaps"></a>Heatmaps</h2><p>两个corner pooling模块后各接了一个预测模块。预测模块中包含Heatmaps、Embeddings、offsets三个模块。通过Heatmaps模块，我们预测两组热图，一组用于预测左上角角点，另一组用于预测右下角角点。 每组热图具有C个通道，其中C是分类的类别数，并且大小为H×W。注意没有背景这个类别。这个特征图的每个通道都是一个mask，mask的每个值为0-1之间的值，表示该点是角点的分数。<br>对于每个角点，有一个ground-truth正位置，其他所有的位置都是负值。 在训练期间，我们没有同等地惩罚负位置，而是减少对正位置半径内的负位置给予的惩罚。 这是因为如果一对假角点检测器靠近它们各自的ground-truth位置，它仍然可以产生一个与ground-truth充分重叠的边界框。我们通过确保半径内的一对点生成的边界框与ground-truth的IoU ≥ t（实验中t=0.7）来确定物体的大小，从而确定半径。给定半径，惩罚的减少量由非标准化的2D高斯函数产生:<br>$$<br>e^{-\frac{x^{2}+y^{2}}{2 \sigma^{2}}}<br>$$<br>其中心即位置，其σ是半径的1/3。</p><p><strong>Heatmaps的损失函数:</strong><br>$$<br>L_{d e t}=\frac{-1}{N} \sum_{c=1}^{C} \sum_{i=1}^{H} \sum_{j=1}^{W} \begin{cases}{\left(1-p_{c i j}\right)^{\alpha} \log \left(p_{c i j}\right)} &amp; {\text { if } y_{c i j}=1} \\ {\left(1-y_{c i j}\right)^{\beta}\left(p_{c i j}\right)^{\alpha} \log \left(1-p_{c i j}\right)} &amp; {\text { otherwise }}\end{cases}<br>$$<br>上式整体上是改良版的focal loss。pcij表示预测的heatmaps在第c个通道（类别c）的（i,j）位置的值，ycij为用非标准化高斯增强的“ground-truth”热图。N表示目标的数量。利用ycij中编码的高斯凸点，（1−ycij）项减少了ground-truth周围的惩罚。<br>ycij=1时候的损失函数容易理解，就是focal loss，α参数用来控制难易分类样本的损失权重；ycij等于其他值时表示（i,j）点不是类别c的目标角点，照理说此时ycij应该是0（大部分算法都是这样处理的），但是这里ycij不是0，而是用基于ground truth角点的高斯分布计算得到，因此距离ground truth比较近的（i,j）点的ycij值接近1，这部分通过β参数控制权重，这是和focal loss的差别。<br><strong>为什么对不同的负样本点用不同权重的损失函数呢？</strong><br>这是因为靠近ground truth的误检角点组成的预测框仍会和ground truth有较大的重叠面积，仍能基本框住目标，因此仍然是有效的预测框。</p><h2 id="Offsets"><a href="#Offsets" class="headerlink" title="Offsets"></a>Offsets</h2><p>这个值和目标检测算法中预测的offset完全不一样，在目标检测算法中预测的offset是表示预测框和anchor之间的偏置，而这里的offset是表示在取整计算时丢失的精度信息。即下面的公式:<br>$$<br>o_{k}=\left(\frac{x_{k}}{n}-\left\lfloor\frac{x_{k}}{n}\right\rfloor, \frac{y_{k}}{n}-\left\lfloor\frac{y_{k}}{n}\right\rfloor\right)<br>$$<br>从输入图像到特征图之间尺寸会缩小，假设缩小倍数是n，那么输入图像上的（x,y）点对应到特征图上就如下式：<br>$$<br>\left(\left\lfloor\frac{x}{n}\right\rfloor,\left\lfloor\frac{y}{n}\right\rfloor\right)<br>$$<br>式中的符号是向下取整，取整会带来精度丢失，这尤其影响小尺寸目标的回归，Faster RCNN中的 ROI Pooling也是有类似的精度丢失问题。我们通过上面计算ok的公式计算offset，然后通过下面的smooth L1损失函数监督学习该参数（使用L1损失与原图标注的位置对其进行修正），和常见的目标检测算法中的回归支路类似。<br>下式中ok是偏移量，xk和yk是角点k的x和y坐标。我们预测所有类别的左上角共享一组偏移，另一组由右下角共享。 对于训练，我们在ground-truth角点位置应用平滑的L1损失。<br>$$<br>L_{o f f}=\frac{1}{N} \sum_{k=1}^{N} SmoothL1Loss\left(o_{k}, \hat o_{k}\right)<br>$$</p><h2 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h2><p>一张图中可能会存在多个目标，因此，可能会检测到多组角点。这里使用embedding模块来确定一组左上角及右下角的点是否是来自同一个目标的边界框。通过基于左上角点的embeding vectors及右下角点embeding vectors的距离来决定是否将两个点进行组合。重要的是二者之间的距离，而向量中的具体数值却不是很重要。本文使用1-D的embeding 向量，etk代表目标k左上角点的embeding ,ebk代表其右下角点的embeding。定义”pull”损失用于组合角点，“push”损失用于分离角点。<br><strong>Embeddings的损失函数:</strong><br>$$<br>L_{p u l l}=\frac{1}{N} \sum_{k=1}^{N}\left[\left(e_{t_{k}}-e_{k}\right)^{2}+\left(e_{b_{k}}-e_{k}\right)^{2}\right]<br>$$<br>$$<br>L_{p u s h}=\frac{1}{N(N-1)} \sum_{k=1}^{N} \sum_{j=1 \atop j \neq k}^{N} \max \left(0, \Delta-\left|e_{k}-e_{j}\right|\right)<br>$$<br>etk表示属于k类目标的左上角角点的embedding vector，ebk表示属于k类目标的右下角关键点的embedding vector，ek表示etk和ebk的均值。我们在所有实验中将Δ设为1。与偏移损失类似，我们仅在ground-truth角点位置应用损失。<br>第一个公式用来缩小属于同一个目标（k类目标）的两个关键点的embedding vector（etk和ebk）距离。第二个公式用来扩大不属于同一个目标的两个角点的embedding vector距离。</p><h2 id="Corner-Pooling"><a href="#Corner-Pooling" class="headerlink" title="Corner Pooling"></a>Corner Pooling</h2><p>CornerNet使用了两个Corner Pooling模块，分别是Top-left Corner pooling和Bottom-right Corner pooling，分别预测左上角关键点和右下角关键点。<br>CornerNet要预测左上角和右下角两个角点，但是这两个角点在不同目标上没有相同规律可循，如果采用普通池化操作，那么在训练预测角点支路时会比较困难。考虑到左上角角点的右边有目标顶端的特征信息（第一张图的头顶），左上角角点的下边有目标左侧的特征信息（第一张图的手），因此如果左上角角点经过池化操作后能有这两个信息，那么就有利于该点的预测，这就有了corner pooling。<br>每个corner pooling模块有2个输入特征图，特征图的宽高分别用W和H表示，假设接下来要对特征图上（i,j）点做左上角的corner pooling，那么就计算（i,j）到（i,H）的最大值（最大池化）；同时计算（i,j）到（W,j）的最大值（最大池化），然后将这两个最大值相加（就是普通的加法）得到（i,j）点的值。右下角点的corner pooling操作类似，只不过计算最大值变成从（0,j）到（i,j）和从（i,0）到（i,j）。<br>用公式表示即为：<br>$$<br>t_{i j}=\begin{cases}{\max \left(f_{t_{ij}}, t_{(i+1) j}\right)} &amp; {\text { if } i&lt;H} \\ {f_{t_{H j}}} &amp; {\text { otherwise }}\end{cases}<br>$$<br>$$<br>l_{i j}=\begin{cases} \max \left(f_{l_{i j}}, l_{i(j+1)}\right) &amp; \text { if } j&lt;W \\ f_{l i w} &amp; \text { otherwise } \end{cases}<br>$$<br><strong>Corner Pooling计算举例:</strong><br>假如做Top-left Corner pooling:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-  -  -  -  -          -  -  -  -  -</span><br><span class="line">2  1  3  0  2          3  3  3  2  2</span><br><span class="line">5  4  1  1  6  -------&gt;6  6  6  6  6</span><br><span class="line">-  -  -  -  -          -  -  -  -  -</span><br><span class="line">-  -  -  -  -          -  -  -  -  -</span><br><span class="line"></span><br><span class="line">-  3  1  -  -          -  3  4  -  -</span><br><span class="line">-  1  1  -  -          -  3  4  -  -</span><br><span class="line">-  3  4  -  -  -------&gt;-  3  4  -  - </span><br><span class="line">-  2  2  -  -          -  2  2  -  -</span><br><span class="line">-  0  2  -  -          -  0  2  -  -</span><br><span class="line">最后将两个最大值矩阵同样位置的元素相加，得:</span><br><span class="line">-  -  -  -  -</span><br><span class="line">-  6  7  -  -</span><br><span class="line">-  9  10 -  -</span><br><span class="line">-  -  -  -  -</span><br><span class="line">-  -  -  -  -</span><br></pre></td></tr></table></figure><h2 id="Hourglass-Network"><a href="#Hourglass-Network" class="headerlink" title="Hourglass Network"></a>Hourglass Network</h2><p>CornerNet使用沙漏网络（Hourglass Network）作为其骨干网络。沙漏网络首次被提到是用于人体姿态估计任务。它是一个完全卷积神经网络，由一个或多个Hourglass组成。Hourglass首先通过一系列卷积层和最大池化层对输入特性进行下采样。然后通过一系列的上采样和卷积层将特征上采样回原来的分辨率。由于细节在最大池化层中丢失，因此添加了跳过层用来将细节带回到上采样的特征。沙漏模块在一个统一的结构中捕获全局和局部特征。当多个Hourglass堆积在网络中时，Hourglass可以重新处理特征以获取更高级别的信息。这些特性使沙漏网络成为目标检测的理想选择。事实上，许多现有的检测器已经采用了类似沙漏网络的网络。<br>我们的沙漏网络由两个Hourglass组成，我们对Hourglass的结构做了一些修改。我们不使用最大池化，而是使用步长2来降低特征分辨率。我们减少了5倍的特征分辨率，并增加了特征通道的数量（256,384,384,384,512）。当我们对特征进行上采样时，我们应用了两个残差模块，然后是一个最近的相邻上采样。每个跳跃连接还包含两个残差模块。沙漏模块中间有4个512通道的残差模块。在沙漏模块之前，我们使用128个通道7×7的卷积模块，步长为2，4倍减少的图像分辨率，后跟一个256个通道，步长为2的残差块。<br>在沙漏网络基础上，我们还在训练时增加了中间监督。但是，我们没有向网络中添加反向中间预测，因为我们发现这会损害网络的性能。我们在第一个沙漏模块的输入和输出，应用了一个3×3的Conv-BN模块。然后，我们通过元素级的加法合并它们，后跟一个ReLU和一个具有256个通道的残差块，然后将其用作第二个沙漏模块的输入。沙漏网络的深度为104。与许多其他最先进的检测器不同，我们只使用整个网络最后一层的特征来进行预测。</p><h2 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h2><p>我们在PyTorch中实现了CornerNet。网络是在默认的PyTorch设置下随机初始化的，没有在任何外部数据集上进行预训练。在训练期间，我们设置了网络的输入分辨率511×511，输出分辨率为128×128。为了减少过拟合，我们采用了标准的数据增强技术，包括随机水平翻转、随机缩放、随机裁剪和随机色彩抖动，其中包括调整图像的亮度，饱和度和对比度。 最后，我们将PCA应用于输入图像。<br><strong>完整的损失函数:</strong><br>$$<br>L=L_{d e t}+\alpha L_{p u l l}+\beta L_{p u s h}+\gamma L_{o f f}<br>$$<br>其中α，β和γ分别是pull，push和offset的权重。 我们将α和β都设置为0.1，将γ设置为1。我们发现，1或更大的α和β值会导致性能不佳。 我们使用49的batch size，并在10个Titan X（PASCAL）GPU上训练网络（主GPU4个图像，其余GPU每个GPU5个图像）。 为了节省GPU资源，在我们的ablation experiments（即模型简化测试，去掉该结构的网络与加上该结构的网络所得到的结果进行对比）中，我们训练网络，进行250k次迭代，学习率为2.5×10−4。当我们将我们的结果与其他检测器进行比较时，我们额外训练网络，进行250k次迭代，并到最后50k次迭代时，将学习速率降低至2.5×10−5。</p><h2 id="测试细节"><a href="#测试细节" class="headerlink" title="测试细节"></a>测试细节</h2><p>在测试期间，我们使用简单的后处理算法从热图，嵌入和偏移生成边界框。 我们首先通过在角点热图上使用3×3最大池化层来应用非极大值抑制（NMS）。然后我们从热图中选择前100个左上角和前100个右下角。 角点位置由相应的偏移调整。 我们计算左上角和右下角嵌入之间的L1距离。距离大于0.5或包含不同类别的角点对将被剔除。 左上角和右下角的平均得分用作检测分数。<br>我们不是将图像大小调整为固定大小，而是保持图像的原始分辨率，并在将其输入给CornerNet之前用0填充。 原始图像和翻转图像都用于测试。 我们将原始图像和翻转图像的检测结合起来，并应用soft-max来抑制冗余检测。 仅记录前100个检测项。 Titan X（PASCAL）GPU上的每个图像的平均检测时间为244ms。</p><h1 id="CornerNet-Lite"><a href="#CornerNet-Lite" class="headerlink" title="CornerNet-Lite"></a>CornerNet-Lite</h1><p>论文:CornerNet-Lite: Efficient Keypoint Based Object Detection<br>论文地址:<a href="https://arxiv.org/pdf/1904.08900.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.08900.pdf</a> 。<br>代码地址:<a href="https://github.com/princeton-vl/CornerNet-Lite" target="_blank" rel="noopener">https://github.com/princeton-vl/CornerNet-Lite</a> 。<br>CornetNet-Lite是对CornetNet的优化，文章中提出了CornerNet的两种改进算法：CornerNet-Saccade和CornerNet-Squeeze。<br>CornerNet-Saccade引入了Saccade思想，在追求高准确率（mAP）的同时，尽可能提高速度（FPS），即准确率优先，其对标于CornerNet等算法。CornerNet-Squeeze引入SqueezeNet优化思想，在追求高实时性（FPS）的同时，尽可能提高准确率（mAP），即速度优先，其对标于YOLOv3等算法。<br>CornerNet-Saccade可以用于线下处理，将 CornerNet 的效率提升6倍，将COCO的效率提高1.0％。CornerNet-Squeeze适合用于实时检测，比YOLOv3的效率和准确性更高（CornerNet-Squeenze的AP值是34.4%，速度是34ms，而YOLOv3的AP值是33.0%，速度是39ms）。<br>CornerNet-Saccade通过减少像素的个数来加速推理的速度。它使用了类似于人眼的注意力机制。首先缩小一幅图像，产生一个attention map，然后再通过模型进一步放大和处理。原始的CornerNet在多个尺度上进行全卷积操作，这和CornerNet-Saccade不同。CornerNet-Saccade 选取若干个高分辨率的裁剪区域来检测，提升检测速度和精度。<br>CornerNet-Squeeze减少每个像素点上需要处理的步骤，以此来加速推理。它融合了SqueezeNet和 MobileNet的思想，加入了一个精炼的Hourglass主干网络，这个主干网络中大量使用了1×1的卷积，bottleneck层，以及深度可分离卷积。<br><strong>我们是否能将CornerNet-Squeeze和CornerNet-Saccade网络结合起来使用提升效率呢？</strong><br>文章的实验结果表明是不提倡的：CornerNet-Squeeze-Saccade速度和准确率都要比CornerNet-Squeeze差。这是因为，要用Saccade，网络要能产生足够准确的attention maps，但是我们的CornerNet-Squeeze过于精炼，不具备这样的能力。此外，原来的CornerNet 应用在多个不同的尺度上，提供了足够的空间来进行saccade，减少要处理的像素数量。相反，CornerNet-Squeeze由于推理成本的限制，只能用在单尺度上，供saccade操作的空间就很小。</p><h2 id="意义和新颖性"><a href="#意义和新颖性" class="headerlink" title="意义和新颖性"></a>意义和新颖性</h2><p>上述两个CornerNet-Lite使得基于关键点的检测方法更具竞争力，覆盖了两个主要的使用场景：CornerNet-Saccade用于线下处理，无需牺牲准确率也可提升效率，CornerNet-Squeeze用于实时处理，提升准确率而无需牺牲效率。<br>这两个变体都很有创新。CornerNet-Saccade 是第一个在基于关键点的目标检测方法中使用saccade的方法。它和之前工作的关键区别就是，每个裁剪区域（像素点或特征图）的处理方式。其它使用了类似saccade机制的工作要么在每个裁剪区域内检测单个物体，要么用一个双阶段网络在每个裁剪区域内产生多个子裁剪区域，然后再产生若干个检测对象。而 CornerNet-Saccade 只使用单阶段网络在每个裁剪区域内输出多个检测对象。<br>CornerNet-Squeeze是第一篇将SqueezeNet和Hourglass结构整合起来用于目标检测任务的论文。之前用了Hourglass结构的方法优于获取高准确率，但是我们不清楚它是否/如何能获得高效率。我们的设计和结果显示，这也是可能的，尤其在目标检测的任务上。</p><h2 id="CornerNet-Saccade"><a href="#CornerNet-Saccade" class="headerlink" title="CornerNet-Saccade"></a>CornerNet-Saccade</h2><p>人类视觉中的Saccades（扫视运动）是指用于固定不同图像区域的一系列快速眼动。在目标检测算法中，我们广义地使用该术语来表示在预测期间选择性地裁剪（crop）和处理图像区域（顺序地或并行地，像素或特征）。<br>在一张图片中，在物体可能出现的位置附近，CornerNet-Saccade在较小的区域范围内检测物体。它利用缩小后的图片来预测attention maps以及大概的边框，这俩都能提供物体可能的位置。然后CornerNet-Saccade在高分辨率的图像中，在位置中心附近区域内检测物体。它也可以通过调节每张图片上物体位置的最大个数来平衡精度和速度。<br><strong>估计目标位置:</strong><br>CornerNet-Saccade的第一步就是获取图像中可能的物体位置。我们使用缩小的图像预测attention maps，它能指出物体的位置以及物体大致的尺寸。给定输入图像，我们将图像缩小至长边为255像素或者192像素。192像素的图像在边缘位置填充0，使得它的大小达到255像素，这样它们就可以并行处理。我们使用这样的低分辨率图有2个原因。首先，这一步不应该成为前向推理时的瓶颈。其次，网络应该很容易就可以利用图像的全局信息预测attention maps。<br>对每一个缩小后的图片，CornerNet-Saccade预测3个 attention maps，一个针对小物体，一个针对中等物体，一个针对大物体。如果一个物体边框的长边小于32像素，它就被认为是小物体，超过96像素的就被认为是大物体，中间的就是中等物体。对不同大小的物体分开预测位置，让我们能更好地控制 CornerNet-Saccade在每个位置应该放大多少。我们在小物体位置可以放大的多一些，在大物体位置可以放大的少一些。<br>我们利用不同比例的特征图来预测attention maps。从CornerNet-Saccade的主干网络（Hourglass网络）中获取特征图。每一个Hourglass模块都使用了多个卷积和下采样层来降低输入特征图的大小。然后再将特征图通过多个上采样层和卷积层上采样至原始输入的分辨率。上采样层输出的特征图用于预测attention maps。比例较细致的特征图用于预测小物体，而比例较粗糙的用于预测大物体。我们在每个特征图上应用一个3×3卷积-ReLU 模块，后面跟着一个1×1Conv-Sigmoid模块，以此来预测attention maps。在测试时，我们仅处理得分高于阈值t的位置，在所有实验中t=0.3。<br>当 CornerNet-Saccade处理缩小后的图像，它就可能会检测到图像中的物体并生成边框。从缩小后的图像上获取的边框可能不那么准确。因此，我们需要在高分辨率的图像上再检测一次，来获得更准确的边框。<br>在训练时，我们将attention map上每个边框对应的中心位置设为正，其余都为负。然后我们再使用α=2的Focal Loss。<br><strong>目标的检测:</strong><br>CornerNet-Saccade使用缩小后图像上得到的位置来决定到底在哪个位置进行处理。如果我们直接在缩小后的图像上进行裁剪，有一些物体可能就会变得很小，使检测变得不准确。因此，我们应该在更高分辨率的图像上进行检测。<br>对于从attention maps得到的位置，可以针对不同尺寸的目标设置不同的放大尺寸。Ss代表小目标的缩放尺寸，Sm代表中等目标的缩放尺寸，Sl代表大目标的缩放尺寸。整体三者之间存在一种关系，Ss&gt;Sm&gt;sl，因为，我们需要对小目标进缩放的成都要大一些。本文设置如下,Ss=4,sm=2,sl=1。对于可能存在的位置（x,y），根据大致的目标尺寸，按照si的比例对downsized图片进行放大，然后，将CornerNet-Saccade应用到255x255窗口的中心位置处。<br>从预测的边界框中得到的位置包含更多目标物的尺寸信息。可以利用得到的边界框的尺寸来确定缩放大小。确定缩放比例后，使小目标的长边为24，中等目标的为64，大目标的为192。<br>为了让处理更加地高效，我们加了一些重要的实现细节。首先，我们以批次来处理所有区域，这样能更好地利用GPU。其次，我们将原始图片保存在GPU 显存里，在GPU里面进行缩放和裁剪，降低CPU 和 GPU 之间转移图像数据带来的消耗。<br>在可能的位置处检测到目标物后，基于soft-NMS处理对于的检测结果。在对图片进行裁剪时，裁剪区域的边界可能会包含目标物的部分区域，如下图所示。产生的边界框可能包含目标物很少的区域，而无法被soft-NMS处理掉，因此，删除了距离裁剪边界很近的边界框。训练时，采用与CornerNet相似的损失，用于预测corner heatmaps,embedings及offsets。<br><strong>准确率及效率的权衡:</strong><br>通过控制每张图片上物体位置的最大个数，我们可以平衡效率和准确率。为了平衡准确率和效率，我们优先处理那些更可能包含物体的位置。因此，当我们得到了物体的位置后，根据它们的得分将它们排序，然后优先处理那些从边框中得到的位置。给定要处理的最大裁剪个数kmax，我们在最高的kmax个位置上进行物体检测。<br><strong>抑制冗余对象位置:</strong><br>当物体之间距离很近时，我们可能会得到高度重叠的物体。我们并不想把这两个框都检测一遍，因为检测其中一个框时就可能会检测到另一个框中的物体。<br>我们采取了一个类似于NMS的方法，去除多余的位置。首先，我们将目标物体的位置进行排序，优先处理边框内的位置，然后再处理attention maps上的位置。我们保留最佳的物体位置，去除那些距离最佳位置过于近的位置。我们重复以上操作，直到没有物体位置剩余。<br><strong>骨干网络:</strong><br>我们设计了一个新的 Hourglass 主干网络，更适合用在CornerNet-Saccade。新的Hourglass网络由3个Hourglass模块组成，深度是54层，而原CornerNet中的Hourglass-104由2个Hourglass模块组成，深度是104层。我们称新的主干网络为Hourglass-54。<br>Hourglass-54中每一个 Hourglass 模块的参数量更少，也要更浅。按照Hourglass-104中的尺寸缩小策略，我们以步长2来缩小特征图。我们在每个下采样层后面使用了一个残差模块。每个Hourglass 模块降低输入特征尺寸3倍，增加它的通道数（384,384,512 384, 384, 512384,384,512）。在模块的中间位置有一个512通道的残差模块，在每个上采样层后面有一个残差模块。我们同样在Hourglass模块之前降低图像的尺寸2倍。<br><strong>训练细节:</strong><br>我们使用Adam方法来优化attention maps和目标检测的损失函数，并且使用和CornerNet中一样的训练超参数。网络的输入大小是255×255，这也是测试时的输入大小。我们在4张1080ti GPU上训练，batch size是48。为了避免过拟合，我们使用了CornerNet中的数据增强。当我们要在目标物体附近随机裁剪一个区域，目标物体要么是随机选取的，要么是在中心位置的附近。这确保了训练和测试是一致的，因为网络检测物体的范围是在一个以物体位置为中心的裁剪区域内。</p><h2 id="CornerNet-Squeeze"><a href="#CornerNet-Squeeze" class="headerlink" title="CornerNet-Squeeze"></a>CornerNet-Squeeze</h2><p>CornerNet-Saccade是减少要处理像素的数量，而CornerNet-Squeeze则是研究了一个替换方案，降低每个像素点上要处理的成本。在CornerNet中，绝大多数的计算资源都耗费在Hourglass-104上。Hourglass-104由残差模块组成，每个残差模块由2 个3×3的卷积层外加一个skip连接构成。尽管Hourglass-104获得了不错的效果，但是就它的参数个数和推理时间来说，它是非常耗时的。为了降低Hourglass-104的复杂度，我们引入了SqueezeNet和MobileNet中的思想，设计了一个轻量级Hourglass架构。<br><strong>来自SqueezeNet和MobileNet中的想法:</strong><br>SqueezeNet提出了3个降低网络复杂度的策略：</p><ul><li>将3×3的卷积核替换为1×1的卷积核；</li><li>降低输入通道为3×3卷积核；</li><li>晚点进行下采样；</li></ul><p>SqueezeNet中的构建模块fire module，首先通过由1×1卷积组成的squeeze层降低输入通道数。然后将结果送入由1×1和3×3卷积混合组成的expand层。<br>基于SqueezeNet的想法，我们在CornerNet-Squeeze中使用了fire module，没有用残差模块。而且，受MobileNet的启发，我们将第二层中的标准3×3卷积替换为3×3深度可分离卷积，这进一步加快了推理速度。<br>我们没有继续探究SqueezeNet中的第三个策略。因为Hourglass网络有一个对称的结构，晚点进行下采样会导致在上采样时得到更高分辨率的特征图。在高分辨率特征图上进行卷积操作，计算成本更高，这就使我们没法进行实时检测。<br>除了替换残差模块，我们也做了其它的一些改动。我们在Hourglass模块之前增加了一个下采样层，以此降低Hourglass模块特征图的最大分辨率，并且在每个Hourglass模块内去掉了一个下采样层。CornerNet-Squeeze在Hourglass模块前相应地将图像尺寸缩小了3倍，但是CornerNet仅将图像尺寸缩小了2倍。我们在CornerNet的预测模块中，将3×3卷积替换为1×1卷积。最后，我们将hourglass网络中最相邻的上采样层替换为4x4的反卷积。<br><strong>训练细节:</strong><br>我们使用了与CornerNet中同样的损失函数和超参数来训练CornerNet-Squeeze。唯一的改变就是 batch size。CornerNet-Squeeze面对同样的图像分辨率，在Hourglass模块之前缩小图像大小可以降低内存消耗4倍。我们在4个1080ti GPU上以batch size=55来训练网络，在主GPU上训练13张图片，剩余的GPU每个训练14张图片。</p><h1 id="CenterNet-Keypoint-Triplets-for-Object-Detection"><a href="#CenterNet-Keypoint-Triplets-for-Object-Detection" class="headerlink" title="CenterNet:Keypoint Triplets for Object Detection"></a>CenterNet:Keypoint Triplets for Object Detection</h1><p>论文:CenterNet: Keypoint Triplets for Object Detection<br>论文地址:<a href="https://arxiv.org/pdf/1904.08189.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.08189.pdf</a> 。<br>代码地址:<a href="https://github.com/Duankaiwen/CenterNet" target="_blank" rel="noopener">https://github.com/Duankaiwen/CenterNet</a> 。<br>在目标检测中，由于缺乏对相关剪裁区域的额外监督，基于关键点的方法通常会得到一大堆错误的物体边框。本文提出了一个有效的方法，在每个裁剪区域内以最小的代价去探索它的视觉模式。我们构建了一个单阶段基于关键点的检测器，叫做CornerNet。CornerNet 用每个目标物体的三个关键点来检测，而不是一对关键点，提升识别精度和召回率。因此，本文设计了两个模块，分别是 cascade corner pooling 和 center pooling，前者能丰富左上角和右下角搜集到的信息，后者在中间区域能提供更具辨识度的信息。在MS-COCO数据集上，CenterNet 获得的AP值是47%，比所有的单阶段检测器至少高出4.9%。同时，它的前向推理速度更快，CenterNet 的性能和双阶段检测器相比也很具竞争力。<br>深度学习出现之后，目标检测得到了明显的提升。目前最流行的方法都是基于ancho 的，在要识别物体上放置预先定义好的anchor boxes，通过ground truth boxes回归出相应的位置。这些方法通常需要一堆anchors来保证预测的边框和ground truth有较高的IoU，anchors的大小、宽高比都需要提前人为设计好。此外，anchors经常会和ground truth边框不一致，降低边框分类的准确率。<br>为了解决anchor的缺点，人们提出了一个基于关键点的目标检测方法CornerNet。它用一对角点来表示每个物体，无需anchor boxes，在one stage检测器中取得了state of art的检测准确率。但是，CornerNet仍有局限性，就是它缺乏对物体全局信息的参考。也就是说，由于每个物体都是用两个角点表示，算法对识别物体的边界框很敏感，而同时又无法确定哪两个关键点属于同一个物体。因此，经常会产生一些错误的边框，绝大多数都可以很容易地通过辅助信息（如宽高比）去除。<br>为了解决这个问题，我们让CornerNet可以识别每个候选区域内的视觉模式，这样它就能自己识别每个边框的正确性。在这篇论文中，我们提出了一个低成本但是很高效的办法叫做CenterNet，通过增加一个关键点来探索候选框内中间区域（靠近几何中心的位置）的信息。我们的想法就是，如果一个预测边框和ground truth边框有着很高的 IoU，则该边框的中心关键点预测出相同类别的概率要高，反之亦然。所以，在推理时，通过一对关键点产生了一个边框，如果同类别物体的中心关键点落在该候选框的中心区域，那么我们就认为该候选框包含那个物体。如果目标边框是准确的，那么在其中心区域能够检测到目标物体中心点的概率就会很高。 若有则保留该目标框，若无则删除该目标框。如图1，即使用三个关键点来表示目标物体。<br><strong>为了更好的检测中心关键点和角点，我们提出了两个方法来分别增强中心和角点信息:</strong></p><ul><li>第一个方法叫center pooling，用于预测中心关键点的分支。Center pooling 有助于中心关键点取得物体内部辨识度更高的视觉信息，让候选框中心部分的感知更简单。实现方式是，在预测中心关键点的特征图上，取中心关键点横向和纵向上响应和的最大值。</li><li>第二个方法就是cascade corner pooling，增加原始 corner pooling 感知候选框内部信息的功能。实现方式是，在预测角点的特征图上，计算物体边框和内部方向上响应和的最大值。实验证明，这样一个双指向的池化方法面对噪声更加稳定，鲁棒性更强，有助于提升精度和召回。</li></ul><p>我们在MS-COCO数据集上评估了CenterNet。在center pooling和cascade corner pooling都使用的情况下，在测试集上AP值能达到47%，超过了现有的单阶段检测器一大截。使用了52层的Hourglass主干网络时，推理时间平均为270毫秒每张图片；使用104层的Hourglass主干网络时，推理时间为340毫秒每张图片。CenterNet效率很高，和现有的two stage检测器相比也不弱。</p><h2 id="基准和动机"><a href="#基准和动机" class="headerlink" title="基准和动机"></a>基准和动机</h2><p>这篇论文使用CornerNet作为基准。为了检测角点，CornerNet产生两个热力图：一个左上角的热力图，一个右下角的热力图。热力图代表不同类别关键点的位置，对每个关键点赋一个置信度分数。此外，CornerNet 也对每个角点预测一个 embedding 和一组偏移量。Embeddings 用于判断两个角点是否来自同一个目标物体。偏移量学习如何将角点从热力图重新映射回输入图像上，为了产生物体的边框，我们依据它们的分数从热力图上分别选取 top−k top-ktop−k 个左上角点和右下角点。然后，我们计算这一对角点的 embedding 向量的距离，以此来判断这一对角点是否属于同一个物体。如果距离小于某阈值，则会生成一个物体边框。该边框会得到一个置信度分数，等于这一对角点的平均分数。<br><strong>为了能够量化分析误检问题，研究人员提出了一种新的衡量指标，称为FD（false discovery，错误的检测边框的比例），能够很直观的反映出误检情况。FD的计算方式为:</strong><br>$$<br>F D_{i}=1-A P_{i}<br>$$<br>APi表示IOU阈值为i/100时对应的平均准确率。<br>结果显示在IoU阈值较低时，错误检测边框占了很大的比例，比如当IoU为0.05时，FD rate是32.7%。也就是平均下来，每一百个物体边框，有32.7个边框和ground truth边框的IoU是低于0.05的。小的错误边框就更多了，FD rate是60.3%。一个可能原因是，CornerNet无法深入边框内部一窥究竟。为了让CornerNet感知边框内的视觉信息，一个方案就是将CornerNet改为two stage检测器，使用RoI池化来深入了解边框内的视觉信息。但是，这种操作带来的计算成本很高。<br>在这篇论文，我们提出了一个非常有效的替代方案CenterNet，可以发掘每个边框内的视觉信息。为了检测物体，我们的方法使用了一个三元组关键点，而非一对关键点。这样做后，我们的方法仍然是一个单阶段检测器，但是部分继承了RoI池化的功能。此方法仅关注中心位置信息，计算成本是很小的。同时通过center pooling和cascade corner pooling，我们在关键点检测过程中进一步加入了物体内部的视觉信息。</p><h2 id="CenterNet的网络结构"><a href="#CenterNet的网络结构" class="headerlink" title="CenterNet的网络结构"></a>CenterNet的网络结构</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">                 --&gt;cascade corner pooling-&gt;corner heatmaps-&gt;embeddings and offsets--&gt;</span><br><span class="line">                 |                                                                   |</span><br><span class="line">输入图片-&gt;骨干网络--&gt;                                           ---------------------------&gt;输出</span><br><span class="line">                 |                                           |       </span><br><span class="line">                 --&gt;center pooling-&gt;center heatmap-&gt;offsets--&gt;</span><br></pre></td></tr></table></figure><h2 id="基于三元组关键点的目标检测"><a href="#基于三元组关键点的目标检测" class="headerlink" title="基于三元组关键点的目标检测"></a>基于三元组关键点的目标检测</h2><p><strong>抑制误检的原理:</strong><br>如果目标框是准确的，那么在其中心区域能够检测到目标中心点的概率就会很高，反之亦然。因此，首先利用左上和右下两个角点生成初始目标框，对每个预测框定义一个中心区域，然后判断每个目标框的中心区域是否含有中心点，若有则保留该目标框，若无则删除该目标框。<br><strong>CenterNet的原理:</strong><br>我们用一个中心关键点和一对角点来表示每个物体。我们在CornerNet的基础上加入一个中心关键点的 heatmap，同时预测中心关键点的offsets。然后，基于CornerNet提出的方法产生top−k个候选框。同时，为了剔除错误的边框，利用检测到的中心点位置，我们对其按如下过程进行排序操作：<br>根据它们的分数，选择top−k个中心关键点；</p><ul><li>使用相应的偏移量将中心关键点重新映射回输入图像中；</li><li>为每个边框定义一个中心区域，确保该中心区域存在中心关键点。同时确保该中心关键点的类别和边框的类别一致。如果在中心区域检测到中心关键点，我们就保留这个边框。用左上角，右下角和中心关键点分数的平均值更新边框的分数，并保存该边框。如果在该中心区域没有检测到中心关键点，则移除此边框。</li></ul><p><strong>中心区域大小的确定方式:</strong><br>中心区域的大小影响会边界框的检测结果。比如，小中心区域对于小的边界框具有较低的召回率，而大区域相对于大的目标造成较低的精度。因此，本文提出了尺度敏感区域用于适应不同尺寸大小的目标物。其一般会生成相对小目标较大，相对大目标较小的中心区域，假设我们需要判断一个边界框I是否需要被保留，tlx,tly代表框左上角的点，brx,bry代表框右下角的点。定义一个中心区域j，定义左上角的点的坐标为(ctlx,ctly),右下角点(cbrx,cbry)。这些参数满足如下定义：<br>$$<br>\begin{cases} ctl_{x}=\frac{(n+1)tl_{x}+(n-1)br_{x}}{2n} \\ c t l_{y}=\frac{(n+1) t l_{y}+(n-1) b r_{y}}{2 n} \\ cbr_{x}=\frac{(n-1) t l_{x}+(n+1) b r_{x}}{2 n} \\ c b r_{y}=\frac{(n-1) t l_{y}+(n+1) b r_{y}}{2 n} \end{cases}<br>$$<br>n是个奇数，决定中心区域j的大小。在这篇论文中，当边框小于150时，n=3，否则n=5。根据上面的公式，我们可以得到自适应的中心区域，然后在里面检测中心区域是否包含中心关键点。</p><h2 id="角点及中心点信息的丰富"><a href="#角点及中心点信息的丰富" class="headerlink" title="角点及中心点信息的丰富"></a>角点及中心点信息的丰富</h2><p><strong>Center Pooling:</strong><br>物体的几何中心不一定能传达出recognizable的视觉信息（例如，人的头部有很强的视觉模式，但中心关键点通常位于人体的中间）。为了解决这个问题，作者在corner pooling基础上实现了center pooling。为了取得一个方向的最大值比如水平方向上，先使用从左至右的Corner Pooling，再跟着一个从右至左的Corner Pooling，即可直接得到水平方向的最大值。同理，使用top pooling和bottom pooling也可以得到竖直方向的最大值，再将水平Pooling和竖直Pooling的结果相加即可。<br><strong>Cascade corner pooling:</strong><br>物体bbox的两个角点往往在物体外部，缺少对物体局部特征的描述。因为Corner Pooling目的是找到物体边界部分的最大值来确定bbox，因此其对边缘非常敏感。作者为了解决这个问题，让物体在关注目标边界信息的同时也能关注目标内部信息。首先和Corner Pooling一样，首先沿边界查找边界最大值，然后沿边界最大值的位置查找内部最大值，最后将两个最大值相加。通过这种方式，使得角点可以同时获得物体的边界信息和内部视觉信息。Cascade Top Pooling的具体实现是首先使用Left Corner Pooling，获得每个点右边的最大值，然后使用Top Corner Pooling。</p><h2 id="训练和推理"><a href="#训练和推理" class="headerlink" title="训练和推理"></a>训练和推理</h2><p>输入图片尺寸为511x511,heatmap大小为128x128，训练损失如下，参数定义同CornerNet。<br>$$<br>L=L_{det}^{co}+L_{det}^{ce}+\alpha L_{pull}^{co}+\beta L_{push}^{co}+\gamma \left(L_{off}^{co}+L_{off}^{ce}\right)<br>$$<br>第一项和第二项分别代表预测角点和中心点的Focal Loss。第三项用于最小化属于同一物体的角点组合向量之间的距离，第四项用于最大化不同物体的角点组合向量之间的距离。第五项括号内的两项都是L1 Loss，用于训练预测角点和中心点的偏移。前向时，选取top-70的角点和中心点，经过soft-nms，最后选取top100的检测框。<br>我们在8块 Tesla V100 GPUs 上训练，batch size 设为48。Iterations 的最大个数设为48万。在前45万个iterations中，学习率设为2.5×10的-4次方。最后3万个iterations，学习率为2.5×10的−5次方。<br>接着CornerNet论文，对于单一尺度测试，我们输入原图和经过水平翻转的图片，分辨率与原始分辨率一样。对于多尺度测试，我们输入原图和水平翻转的图片，分辨率分别为0.6、1.2、1.5、1.8。我们从热力图上选取前70个中心关键点，前70个左上角点，前70个右下角点，以此检测边框。在水平翻转的图片上，我们翻转检测到的边框，将它们和原来的边框进行混合。我们也用了 Soft-NMS 来去除多余的边框。最终，根据得分，选择前100个边框作为最终的检测结果。</p><h1 id="CenterNet-Objects-as-Points"><a href="#CenterNet-Objects-as-Points" class="headerlink" title="CenterNet:Objects as Points"></a>CenterNet:Objects as Points</h1><p>论文:CenterNet:Objects as Points<br>论文地址:<a href="https://arxiv.org/pdf/1904.07850.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.07850.pdf</a> 。<br>代码地址:<a href="https://github.com/xingyizhou/CenterNet" target="_blank" rel="noopener">https://github.com/xingyizhou/CenterNet</a> 。<br>目标检测识别往往在图像上将目标以轴对称的框形式框出。大多成功的目标检测器都先穷举出潜在目标位置，然后对该位置进行分类，这种做法浪费时间，低效，还需要额外的后处理。本文中，我们采用不同的方法，构建模型时将目标作为一个点——即目标BBox的中心点。我们的检测器采用关键点估计来找到中心点，并回归到其他目标属性，例如尺寸，3D位置，方向，甚至姿态。我们基于中心点的方法，称为：CenterNet，相比较于基于BBox的检测器，我们的模型是端到端可微的，更简单，更快，更精确。我们的模型实现了速度和精确的最好权衡，以下是其性能：<br>MS COCO dataset, with 28:1% AP at 142 FPS, 37:4% AP at 52 FPS, and 45:1% AP with multi-scale testing at 1.4 FPS.<br>用同个模型在KITTI benchmark 做3D bbox，在COCO keypoint dataset做人体姿态检测。同复杂的多阶段方法比较，我们的取得了有竞争力的结果，而且做到了实时。<br><strong>One stage detectors在图像上滑动复杂排列的可能bbox（即锚点）,然后直接对框进行分类，而不会指定框中内容。</strong><br><strong>Two-stage detectors对每个潜在框重新计算图像特征，然后将那些特征进行分类。</strong></p><p><strong>后处理，即NMS（非极大值抑制），通过计算Bbox间的IOU来删除同个目标的重复检测框。这种后处理很难区分和训练，因此现有大多检测器都不是端到端可训练的。</strong><br>本文通过目标中心点来呈现目标，然后在中心点位置回归出目标的一些属性，例如：size, dimension, 3D extent, orientation, pose。 而目标检测问题变成了一个标准的关键点估计问题。我们仅仅将图像传入全卷积网络，得到一个热力图，热力图峰值点即中心点，每个特征图的峰值点位置预测了目标的宽高信息。<br><strong>本文的模型训练采用标准的监督学习，推理仅仅是单个前向传播网络，不存在NMS这类后处理。</strong><br><strong>对我们的模型做一些拓展，可在每个中心点输出3D目标框，多人姿态估计所需的结果:</strong></p><ul><li>对于3D BBox检测，我们直接回归得到目标的深度信息，3D框的尺寸，目标朝向；</li><li>对于人姿态估计，我们将关节点（2D joint）位置作为中心点的偏移量，直接在中心点位置回归出这些偏移量的值。</li></ul><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><strong>本文的CenterNet方法和anchor-based的one-stage目标检测方法类似，中心点可以看做是shape-agnostic（形状未知）的锚点，可以看做是一种隐式的anchors。</strong></p><ul><li>第一，我们分配的锚点仅仅是放在位置上，没有尺寸框。没有手动设置的阈值做前后景分类（像Faster RCNN会将与GT IOU &gt;0.7的作为前景，&lt;0.3的作为背景，其他不管）；</li><li>第二，每个目标仅仅有一个正的锚点，因此不会用到NMS，我们提取关键点特征图上局部峰值点（local peaks）；</li><li>第三，CenterNet 相比较传统目标检测而言（缩放16倍尺度），使用更大分辨率的输出特征图（缩放了4倍），因此无需用到多重特征图锚点。</li></ul><p><strong>通过关键点估计做目标检测:</strong><br>我们并非第一个通过关键点估计做目标检测的。CornerNet将bbox的两个角作为关键点；ExtremeNet 检测所有目标的 最上，最下，最左，最右，中心点；所有这些网络和我们的一样都建立在鲁棒的关键点估计网络之上。但是它们都需要经过一个关键点grouping阶段，这会降低算法整体速度；而我们的算法仅仅提取每个目标的中心点，无需对关键点进行grouping 或者是后处理。<br><strong>单目3D目标检测:</strong><br>3D BBox检测为自动驾驶赋能。Deep3Dbox使用一个slow-RCNN风格的框架，该网络先检测2D目标，然后将目标送到3D估计网络；3D RCNN在Faster-RCNN上添加了额外的head来做3D projection；Deep Manta使用一个coarse-to-fine的Faster-RCNN，在多任务中训练。而我们的模型同one-stage版本的Deep3Dbox 或3D RCNN相似，同样，CenterNet比它们都更简洁，更快。</p><h2 id="初步工作"><a href="#初步工作" class="headerlink" title="初步工作"></a>初步工作</h2><p>输入图像的宽W，高H。形式如下:<br>$$<br>I \in R^{W \times H \times 3}<br>$$<br>我们目标是生成关键点热力图:<br>$$<br>\hat Y \epsilon[0,1]^{\frac{W}{R} \times \frac{H}{R} \times C}<br>$$<br>其中R是下采样因子，这里采用R=4。C表示关键点类别，C=17时为人关节点，用于人姿态估计； C= 80为目标类别数（COCO数据集中），用于目标检测。<br>在预测的heatmaps中:<br>$$<br>\hat Y_{x, y, c}=1<br>$$<br>表示检测到的关键点。<br>$$<br>\hat Y_{x, y, c}=0<br>$$<br>表示为背景。<br>在整个训练的流程中，CenterNet学习了CornerNet的方法。对于每个标签图(ground truth)中的某一 C 类，我们要将真实关键点p计算出来计算出来用于训练，中心点的计算方式为:<br>$$<br>p=\left(\frac{x_{1}+x_{2}}{2}, \frac{y_{1}+y_{2}}{2}\right)<br>$$<br>下采样后对应的关键点为:<br>$$<br>\tilde{p}=\left\lfloor\frac{p}{R}\right\rfloor<br>$$<br>R是上文中提到的下采样因子4。计算出来的是对应低分辨率图像中的中心点。<br>然后我们利用<br>$$<br>Y \in[0,1]^{\frac{W}{R} \times \frac{H}{R} \times C}<br>$$<br>来对图像进行标记。在下采样的[128,128]图像中将ground truth point以<br>$$<br>Y \in[0,1]^{\frac{W}{R} \times \frac{H}{R} \times C}<br>$$<br>的形式输入下面的高斯核:<br>$$<br>Y_{x y c}=\exp \left(-\frac{\left(x-\tilde p_{x}\right)^{2}+\left(y-\tilde p_{y}\right)^{2}}{2 \sigma_{p}^{2}}\right)<br>$$<br>其中σp是一个与目标大小（也就是w和h）相关的标准差。这样我们就将关键点分布到特征图上。如果对于同个类c（同个关键点或是目标类别）有两个高斯函数发生重叠，我们选择元素级最大的。<br>也就是说，每个点<br>$$<br>Y \in[0,1]^{\frac{W}{R} \times \frac{H}{R} \times C}<br>$$<br>的范围是0-1,而1则代表这个目标的中心点，也就是我们要预测要学习的点。<br><strong>损失函数:</strong><br>在CenterNet中，作者使用了三种全卷积encoder-decoder网络：hourglass，Resnet和DLA来预测<br>$$<br>\hat Y<br>$$<br>关键点损失函数采用的是像素级逻辑回归的focal loss，如下公式所示:<br>$$<br>L_{k}=\frac{1}{N} \sum_{x y c} \begin{cases}{\left(1-\hat Y_{x y c}\right)^{\alpha} \log \left(\hat Y_{x y c}\right)} &amp; {\text { if } Y_{x y c}=1} \\ {\left(1-Y_{x y c}\right)^{\beta}\left(\hat Y_{x y c}\right)^{\alpha} \log \left(1-\hat Y_{x y c}\right)} &amp; {\text { otherwise }} \end{cases}<br>$$<br>其中α和β是focal loss的超参数，实验中两个数分别设置为2和4， N是图像中的关键点个数，除以N主要为了将所有focal loss归一化。<br>和Focal Loss类似，对于easy example的中心点，适当减少其训练比重也就是loss值，当<br>$$<br>\hat Y_{x y c}=1<br>$$<br>时， log前面的括号项就充当了矫正的作用。假如上式接近1的话，说明这个是一个比较容易检测出来的点，那么第二项前面的括号项就相应比较低了。而当上式接近0的时候，说明这个中心点还没有学习到，所以要加大其训练的比重，因此第二项前面的括号项就会很大。<br><strong>因为上文中对图像进行了R=4的下采样，这样的特征图重新映射到原始图像上的时候会带来精度误差，因此对于每一个中心点，额外采用了一个local offset来补偿误差:</strong><br>$$<br>\hat O \in \mathcal{R}^{\frac{W}{R} \times \frac{H}{R} \times 2}<br>$$<br>所有类 c 的中心点共享同一个offset prediction，这个偏置值(offset)用L1 loss来训练:<br>$$<br>L_{o f f}=\frac{1}{N} \sum_{p}\left|\hat O_{\tilde p}-\left(\frac{p}{R}-\tilde p\right)\right|<br>$$<br>绝对值项中第一项是我们预测出来的偏置，第二项是在训练过程中提前计算出来的数值。<br>事实上，这个偏置损失是可选的，我们不使用它也可以，只不过精度会下降一些。</p><h2 id="目标看作点"><a href="#目标看作点" class="headerlink" title="目标看作点"></a>目标看作点</h2><p>令<br>$$<br>\left(x_{1}^{(k)}, y_{1}^{(k)}, x_{2}^{(k)}, y_{2}^{(k)}\right)<br>$$<br>代表类别为ck的目标k，其中心点为:<br>$$<br>p_{k}=\left(\frac{x_{1}^{(k)}+x_{2}^{(k)}}{2}, \frac{y_{1}^{(k)}+y_{2}^{(k)}}{2}\right)<br>$$<br>我们使用关键点:<br>$$<br>\hat Y<br>$$<br>来预测所有中心点。<br>此外，为每个目标k回归出目标的尺寸<br>$$<br>s_{k}=\left(x_{2}^{(k)}-x_{1}^{(k)}, y_{2}^{(k)}-y_{1}^{(k)}\right)<br>$$<br>sk这个值是在训练前提前计算出来的，是进行了下采样之后的长宽值。<br>为了减少计算负担，我们为每个目标种类使用单一的尺寸预测:<br>$$<br>\hat S \in R^{\frac{W}{R} \times \frac{H}{R} \times 2}<br>$$<br>因此我们可以在中心点位置添加L1 Loss:<br>$$<br>L_{s i z e}=\frac{1}{N} \sum_{k=1}^{N}\left|\hat s_{p k}-s_{k}\right|<br>$$<br>我们不将scale进行归一化，直接使用原始像素坐标。<br><strong>整个训练的损失函数如下:</strong><br>$$<br>L_{d e t}=L_{k}+\lambda_{s i z e} L_{s i z e}+\lambda_{o f f} L_{o f f}<br>$$<br>整体的损失函数为物体损失、大小损失与偏置损失的和，每个损失都有相应的权重。在论文中 λsize=0.1 ，λoff=1 ，论文中所使用的backbone都有三个head layer，分别产生[1,80,128,128]、[1,2,128,128]、[1,2,128,128]，也就是每个坐标点产生C+4个数据（即关键点类别C, 偏移量的x,y，尺寸的w,h）。<br><strong>从点到回归框:</strong><br>在预测阶段，我们首先针对一张图像进行下采样，随后对下采样后的图像进行预测，对于每个类在下采样的特征图中预测中心点，然后将输出图中的每个类的热点单独地提取出来。如何提取呢？我们将热力图上的所有响应点与其连接的8个临近点进行比较，如果该点响应值大于或等于其八个临近点值则保留，最后我们保留所有满足之前要求的前100个峰值点。<br>假设<br>$$<br>\hat  P_{c}<br>$$<br>表示类别c的n个中心点的集合。<br>$$<br>\hat P<br>$$<br>代表c类中检测到的一个点。<br>每个关键点的位置用整型坐标表示:<br>$$<br>\left(x_{i}, y_{i}\right)<br>$$<br>使用<br>$$<br>\hat Y_{x_{i} y_{i} c}<br>$$<br>表示当前点的置信度。<br>然后我们使用下面的公式来产生目标框:<br>$$<br>(\hat x_{i}+\delta \hat x_{i}-\hat w_{i} / 2, \hat y_{i}+\delta \hat y_{i}-\hat h_{i} / 2, \hat x_{i}+\delta \hat x_{i}+\hat w_{i} / 2, \hat y_{i}+\delta \hat y_{i}+\hat h_{i} / 2)<br>$$<br>其中:<br>$$<br>\left(\delta \hat x_{i}, \delta \hat y_{i}\right)=\hat O \hat x_{i}, \hat y_{i}<br>$$<br>是当前点对应原始图像的偏置点。<br>$$<br>\left(\hat w_{i}, \hat h_{i}\right)=\hat S \hat x_{i}, \hat y_{i}<br>$$<br>是预测出来当前点对应目标的长宽。<br>最终根据模型预测出来的<br>$$<br>\hat Y \in[0,1]^{\frac{W}{R} \times \frac{H}{R} \times C }<br>$$<br>即就是当前中心点存在物体的概率值，代码中设置的阈值为0.3，也就是从上面选出的100个结果中选出大于该阈值的中心点作为最终的结果。<br><strong>3D检测:</strong><br>3D检测是对每个目标进行3维bbox估计，每个中心点需要3个附加信息：depth，3D dimension，orientation（深度、3D维度和方向）。因此对其中每个部分增加一个单独的部分检测头。<br> 对于每个中心点，深度值depth是一个维度的。然后depth很难直接回归，我们参考Depth map prediction from a single image using a multi-scale deep network这篇文章对输出做了变换:<br>$$<br>d=1 / \sigma(\hat d)-1<br>$$<br>其中σ是sigmoid函数。<br>我们在特征点估计网络上添加了一个深度估计器:<br>$$<br>\hat D \in[0,1]^{\frac{W}{R} \times \frac{H}{R}}<br>$$<br>该通道使用了两个卷积层，然后做ReLU 。我们用L1 loss来训练该深度估计器。<br>目标的3D维度是三个标量值。我们直接回归出它们（长宽高）的绝对值，单位为米。<br>$$<br>\hat \Gamma \in[0,1]^{\frac{W}{R} \times \frac{H}{R} \times 3}<br>$$<br>该3D维度估计器也使用L1 loss来训练。<br>方向默认是单标量的值，然而其也很难回归。我们参考3d bounding box estimation using deep learning and geometry这篇文章的做法，使用两个bins来呈现方向，且i做n-bin回归。方向用8个标量值来编码的形式，每个bin有4个值。对于一个bin,两个值用作softmax分类，其余两个值回归到在每个bin中的角度。<br><strong>人体姿态估计:</strong><br>人体姿态估计估计出每个人体的k个关节点位置（COCO数据集中k=17，即每个人有17个关节点），我们令中心点的姿态是2k维的，然后将每个关键点（关节点对应的点）参数化为相对于中心点的偏移（L1 Loss）:<br>$$<br>\hat J=R^{\frac{W}{R} \times \frac{H}{R} \times 2}<br>$$<br>为了精修关键点，估计k个人体部位热力图 （Focal Loss）:<br>$$<br>\hat \Phi \in R^{\frac{W}{R} \times \frac{H}{R} \times k}<br>$$<br>我们使用标准的bottom-up多人体姿态估计，我们训练人的关节点热力图使用focal loss和像素偏移量，这块的思路和中心点的训练雷同。<br>我们将初始预测映射到特征图上检测到的最近的关键点。然后将中心偏移作为分组标志，将各个检测到的关键点分配给最近的人体。<br>具体来说，令:<br>$$<br>(\hat x, \hat y)<br>$$<br>代表检测到的中心点。<br>第一次回归得到的关节点为:<br>$$<br>l_{j}=(\hat x, \hat y)+\hat J_{\hat x \hat y \hat j}(j=1,2, \ldots, k)<br>$$<br>我们提取到所有关键点（关节点，此处是类似中心点检测用热力图回归得到的，对于热力图上值小于0.1的直接略去），然后将每个回归（第一次回归，通过偏移方式）位置lj与最近的检测关键点（关节点）进行分配:<br>$$<br>\arg \min_{l \in L_{j}} (l-l_{j})^{2}<br>$$</p><h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><p>我们实验了4个结构：ResNet-18, ResNet-101, DLA-34， Hourglass-104。我们用deformable卷积层来更改ResNets和DLA-34，按照原样使用Hourglass网络。<br><strong>Hourglass:</strong><br>堆叠的Hourglass网络通过两个连续的hourglass模块对输入进行了4倍的下采样，每个hourglass模块是个对称的5层下和上卷积网络，且带有skip连接。该网络较大，但通常会生成最好的关键点估计。<br><strong>ResNet:</strong><br>Xiao等人对标准的ResNet做了3个up-convolutional网络来dedao更高的分辨率输出（最终stride为4）。为了节省计算量，我们改变这3个up-convolutional的输出通道数分别为256,128,64。up-convolutional核初始为双线性插值。<br><strong>DLA:</strong><br>即Deep Layer Aggregation（DLA），是带多级跳跃连接的图像分类网络，我们采用全卷积上采样版的DLA，用deformable卷积来跳跃连接低层和输出层；将原来上采样层的卷积都替换成3x3的deformable卷积。在每个输出head前加了一个3x3x256的卷积，然后做1x1卷积得到期望输出。<br><strong>Training:</strong><br>训练输入图像尺寸：512x512；输出分辨率：128x128（即4倍stride）；采用数据增强方式：随机flip, 随机scaling（比例在0.6到1.3），裁剪，颜色jittering；采用Adam优化器。</p><p>在3D估计分支任务中未采用数据增强（scaling和crop会影响尺寸）。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>CenterNet通过预测一个中心点解决了2D目标检测，3D目标检测以及姿态估计任务，完美的把这三个任务统一到一起；<br>与另一篇CenterNet:Keypoint Triplets for Object Detection相比较，Keypoint Triplets则是通过中心点预测抑制CornerNet中存在的大量误检，而本篇则是使用目标中心点来预测目标；<br>从使用关键点来进行的目标检测方法在coco上训练耗时来看，这类方法普遍存在训练耗时较长的问题。<br>在实际训练中，如果在图像中两个目标经过下采样后中心点重叠了，那么CenterNet会将这两个物体的当成一个物体来训练（因为只有一个中心点）。同理，在预测过程中，如果两个同类的物体在下采样后的中心点也重叠了，那么CenterNet也只能检测出一个中心点。</p><h1 id="FCOS"><a href="#FCOS" class="headerlink" title="FCOS"></a>FCOS</h1><p>论文:FCOS: Fully Convolutional One-Stage Object Detection<br>论文地址:<a href="https://arxiv.org/pdf/1904.01355.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.01355.pdf</a> 。<br>代码地址:<a href="https://github.com/tianzhi0549/FCOS" target="_blank" rel="noopener">https://github.com/tianzhi0549/FCOS</a> 。<br>本文提出了一种全卷积的one-stage目标检测器（FCOS），以逐像素预测方式解决目标检测，类似于语义分割。相比于RetinaNet，SSD，YOLOv3和Faster R-CNN等依赖于预定义的锚框（anchor boxes）的目标检测模型，FCOS不需要锚框，因此FCOS完全避免了与锚框相关的复杂计算，且避免了与锚框相关的所有超参数，这些参数通常对最终检测性能非常敏感。FOCS凭借唯一的后处理非极大值抑制（NMS），达到了比以往one-stage检测模型更好的性能。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>全卷积网络FCN在密集预测的任务如语义分割，深度估计，关键点检测上取得了不错的效果。但是在以往的目标检测任务中，由于anchor boxes的使用，并没有应用全卷积逐像素点预测的目标检测模型。如果我们能像语义分割中的FCN那样使用逐像素点预测的方式来解决目标检测问题，那么视觉任务中所有的问题都可以用一个框架来解决。这篇论文证明这是可以的。而且，和基于anchors的检测器相比，基于FCN的检测器更加简单，也可以取得更好的效果。<br>以往的DenseBox和UnitBox等方法也曾尝试将全卷积框架用于目标检测。这些基于FCN的框架在每层特征图的每个空间位置上，直接预测一个4D向量加一个类别。4D向量表示像素点到4个边框的距离，这样每一个像素点都要预测一个4D向量。但是为了应付不同大小的边框，DenseBox将图像缩放到一个固定尺寸。这样DenseBox不得不在图像金字塔上进行检测，这和FCN的一次处理完所有卷积的方式相悖，而且这些方法应用在通用目标检测任务上效果不会很好，往往它们具有高度重叠的边框。高度重叠的边框会造成界限不明确，很难理清重叠部分的像素点应该属于哪一个边框。<br>接下来我们证明了FPN能有效地解决这种不明确的问题。我们发现FCOS会在远离目标物体中心的位置上产生一些效果不好的预测边框。为了降低这些不好的检测结果，我们引入了一个 “center-ness” 分支（只有一层），预测像素点到目标边框中心的距离。这个分数然后用于降低效果不好的边框的权重，然后用NMS将检测结果合并。Center-ness分支很简单，也很有效。有了它，在同样的训练和测试环境下，我们基于FCN的检测器就能超过基于anchor的检测器。<br><strong>FCOS与anchor-based检测器的区别:</strong></p><ul><li>anchor-based算法将输入图像上的位置作为锚框的中心店，并且对这些锚框进行回归。FCOS直接对feature map中每个位置对应原图的边框都进行回归，换句话说FCOS直接把每个位置都作为训练样本，这一点和FCN用于语义分割相同。FCOS算法feature map中位置与原图对应的关系，如果feature map中位置为（x,y），映射到输入图像的位置是:<br>$$<br>\left(\left\lfloor\frac{s}{2}\right\rfloor+ x s,\left\lfloor\frac{s}{2}\right\rfloor+ y s\right)<br>$$</li><li>在训练过程中，anchor-based算法对样本的标记方法是，如果anchor对应的边框与真实边框（ground truth）的IOU大于一定阈值，就设为正样本，并且把交并比最大的类别作为这个位置的类别。而在FCOS中，如果位置 (x,y) 落入任何真实边框，就认为它是一个正样本，它的类别标记为这个真实边框的类别。</li><li>以往的anchor-based算法训练一个多元分类器，而FCOS训练C个二元分类器（C是类别数）。</li><li>在多尺度FPN的检测上，anchor-based算法将不同尺寸的锚框分配到不同级别的特征层，而FCOS通过直接限定不同特征级别的边界框的回归范围来进行分配。</li></ul><p><strong>FCOS模型的优点:</strong><br>FCOS模型使用语义分割的思想来解决目标检测问题，它摒弃了目标检测中常见的anchor boxes和object proposal，使得不需要调优涉及anchor boxes和object proposal的超参数；<br>在训练过程中避免大量计算GT boxes和anchor boxes 之间的IoU，使得训练过程占用内存更低；<br>FCOS可以作为two stage检测器的区域建议网络（RPN），其性能明显优于基于锚点的RPN算法；<br>FCOS可以经过最小的修改便可扩展到其他的视觉任务，包括实例分割、关键点检测。<br><strong>FCOS算法步骤:</strong><br>对输入的图片进行预处理操作；<br>搭建下图所示的网络架构，将输入数据送入backbone网络中获取输入数据的feature_map，在feature_map的每一点上面进行回归操作，进行网络训练获取网络模型；<br>将预训练的网络模型应用到测试图片中，从特征金字塔的多个Head中获得预测的结果；<br>使用NMS等后处理操作获得最终的结果。</p><h2 id="FCOS网络结构"><a href="#FCOS网络结构" class="headerlink" title="FCOS网络结构"></a>FCOS网络结构</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">输入</span><br><span class="line"> |</span><br><span class="line">C1</span><br><span class="line"> |</span><br><span class="line">C2</span><br><span class="line"> |</span><br><span class="line">C3——&gt;P3——&gt;head</span><br><span class="line"> |   |</span><br><span class="line">C4——&gt;P4——&gt;head  </span><br><span class="line"> |   |</span><br><span class="line">C5——&gt;P5——&gt;head</span><br><span class="line">     |</span><br><span class="line">     P6——&gt;head</span><br><span class="line">     |</span><br><span class="line">     P7——&gt;head</span><br><span class="line">每一个head的结构:</span><br><span class="line">                                                --&gt;Classification HxWxC</span><br><span class="line">                                                |</span><br><span class="line">      --&gt;HxWx256--&gt;HxWx256--&gt;HxWx256--&gt;HxWx256--&gt;</span><br><span class="line">      |                                         |</span><br><span class="line">      |                                         --&gt;Center-ness HxWx1</span><br><span class="line">      |</span><br><span class="line">head--&gt;</span><br><span class="line">      |</span><br><span class="line">      --&gt;HxWx256--&gt;HxWx256--&gt;HxWx256--&gt;HxWx256--&gt;Regression HxWx4</span><br></pre></td></tr></table></figure><p>P3-P7是FPN特征金字塔，head是一个三分支的头检测网络。</p><h2 id="全卷积one-stage检测器"><a href="#全卷积one-stage检测器" class="headerlink" title="全卷积one stage检测器"></a>全卷积one stage检测器</h2><p>设<br>$$<br>F_{i} \in \mathbb{R}^{H \times W \times C}<br>$$<br>为CNN的第i层特征图，s是该层之前的总步长。<br>输入图像的ground truth边框定义为:<br>$$<br>B_{i}=\left(x_{0}^{(i)}, y_{0}^{(i)}, x_{1}^{(i)} y_{1}^{(i)}, c^{(i)}\right) \in R^{4} \times{1,2, \ldots, C}<br>$$<br>上式中:<br>$$<br>\left(x_{0}^{(i)}, y_{0}^{(i)}\right) 和 \left(x_{1}^{(i)} y_{1}^{(i)}\right)<br>$$<br>分别表示边框左上角和右下角的坐标。<br>$$<br>c^{(i)}<br>$$<br>表示边框中目标的类别。<br>C是类别的总数，对于COCO数据集而言，C=80。<br>对特征图Fi上的每个位置（x,y），我们可以将其映射回输入图像:<br>$$<br>\left(\left\lfloor\frac{s}{2}\right\rfloor+ x s,\left\lfloor\frac{s}{2}\right\rfloor+ y s\right)<br>$$<br>基于anchor的检测器将输入图像上的位置作为anchor boxes的中心，然后对这些anchor boxes回归出目标边框。而我们的方法是直接在特征图的每个位置上回归出目标边框。也就是说，我们的检测器直接将每个点看作训练样本，而不是将anchor boxes看作训练样本，这和语义分割中的FCN一样。<br>如果（x,y）落入一个ground truth边框内，它就被标注为正样本，该位置的标签<br>$$<br>c^{\ast}<br>$$<br>就是Bi的标签。否则它就是负样本（背景类），有:<br>$$<br>c^{\ast}=0<br>$$<br>除了分类的标签外我们也有一个4D的向量:<br>$$<br>t^{\ast}=\left(l^{\ast}, t^{\ast}, r^{\ast}, b^{\ast}\right)<br>$$<br>作为每一个样本回归的目标。四个变量分别代表该位置到边框四条边的距离。如果一个点落入多个边框之中，它就被视作模糊样本。就目前来说，我们只选取最小面积的边框作为回归的目标。如果位置（x,y）与边框Bi相关联，该位置的回归目标可定义为:<br>$$<br>l^{\ast}=x-x_{0}^{(i)}, t^{\ast}=y-y_{0}^{(i)}, r^{\ast}=x_{1}^{(i)}-x, b^{\ast}=y_{1}^{(i)}-y<br>$$<br>FCOS模型能够利用尽可能多的前景样本来训练回归器。这和基于anchor boxes的检测器不同，它们只将那些和ground truth边框IOU足够高的anchor boxes当作正样本。我们认为也许这是FCOS比基于 anchor的检测器效果好的原因之一。<br><strong>网络输出:</strong><br>与训练目标对应，最后一层预测一个类别标签的80维的向量p，以及一个4维的向量t=（l,t,r,b），即中心点距离边框的left、top、right和bottom边之间的距离。我们训练C个二元分类器，而不是一个多类别分类器。我们在主干网络特征图之后增加4个卷积层，分别对应分类和回归分支。而且，由于回归目标通常是正的，我们在回归分支上面用exp（x）将任意实数映射到（0,正无穷）之内。FCOS的参数个数要比基于anchor的检测器少9倍，因为一般基于anchor的方法在每个位置上会有9个anchor boxes。<br><strong>损失函数:</strong><br>$$<br> L\left(p_{x, y}t_{x, y}\right) =\frac{1}{N_{pos}} \sum_{x, y} L_{cls}\left(p_{x, y}, c_{x, y}^{\ast}\right) +\frac{\lambda}{N_{pos}} \sum_{x, y} 1_{(c_{x, y}^{\ast}&gt;0)} L_{reg}\left(t_{x, y},t_{x, y}^{\ast}\right)<br>$$<br>该loss函数包含两部分，Lcls表示分类loss，本文使用的是Focal_loss（类别损失）；Lreg表示回归loss，本文使用的是IOU loss。<br>px,y表示特征图的位置（x,y）处的分类概率，tx,y表示特征图的位置（x,y）处的回归坐标。Npos表示正样本的个数，在这篇论文中λ=1用于平衡Lreg的权重。对特征图Fi上的各个位置的结果进行求和。<br>$$<br>1_{c^{\ast}&gt;0}<br>$$<br>是指标函数，当<br>$$<br>c_{i}^{\ast}&gt;0<br>$$<br>指标函数值为1，否则为0。<br><strong>前向推理:</strong><br>FCOS 的前向推理很直接。给定输入图片，前向通过整个网络，获得特征图Fi上每个位置的分类得分px,y以及回归预测tx,y。如果一个位置的px,y&gt;0.05，则它被列为正样本，然后通过上面的公式计算l，t，r，b获得预测边框。</p><h2 id="用FPN对FCOS进行多尺度的预测"><a href="#用FPN对FCOS进行多尺度的预测" class="headerlink" title="用FPN对FCOS进行多尺度的预测"></a>用FPN对FCOS进行多尺度的预测</h2><p><strong>FCOS可能遇到的两个问题:</strong></p><ul><li>最后一个特征图上较大的步长可能导致低召回率。对于基于anchor的检测器，因步长较大而导致召回率低的问题，可以通过降低判断正样本的IOU阈值来弥补。对于FCOS，我们证明即使步长很大，基于FCN的FCOS检测器也能产生足够好的召回率。而且，它甚至要比基于anchor的RetinaNet要好。而且，利用多层级FPN预测，能够进一步提升召回率；<br>能被进一步提升，达到 RetinaNet 的最好成绩。</li><li>Ground truth边框的重叠区域会造成训练中的不明确，到底重叠区域内的位置应该回归到哪个边框里去？这个问题会导致基于FCN的检测器性能降低。我们证明这种不明确问题可以通过FPN多层级预测解决，和基于anchor的检测器相比较，基于FCN的检测器能取得更优的成绩。</li></ul><p>在FCOS中，我们在特征图的不同层级上检测不同大小的物体，我们使用了特征图的5种层级，即P3、P4、P5、P6、P7。P3、P4、P5是通过CNN 的特征图C3、C4、C5后接一个1×1的卷积层而产生。P6、P7通过在P5、P6上分别应用一个步长为2的卷积层而得到。特征层P3、P4、P5、P6、P7的步长分别为8、16、32、64、128。<br>基于anchor的检测器在不同特征层上分配不同大小的anchor boxes，而我们直接限定边框回归的范围。更具体点，我们首先在所有特征层上的每个位置计算回归目标:<br>$$<br>l^{\ast}, t^{\ast}, r^{\ast}, b^{\ast}<br>$$<br>如果一个位置满足:<br>$$<br>\max \left(l^{\ast}, t^{\ast}, r^{\ast}, b^{\ast}\right)&gt;m_{i} 或\max \left(l^{\ast}, t^{\ast}, r^{\ast},    b^{\ast}\right)&lt;m_{i-1}<br>$$<br>那么它就被设为负样本，就不需要回归边框。mi是第i个特征层需要回归的最大距离。在论文中，m2、m3、m4、m5、m6、m7分别被设为0、64、128、256、512、∞。因为不同大小的物体被分配到不同的特征层，而绝大多数的重叠物体彼此间的大小很不一样，多层级预测能极大地缓解前面提到的重叠区域模糊问题，因而提升FCN检测器的精度。<br>最后，我们在不同的特征层级间共享 heads，提升了检测器的效率和性能。但是我们发现不同特征层级需要回归不同的大小范围（比如对P3是[0,64]，对P4是[64,128] ），因而对不同的特征层级使用一样的heads是不合理的。所以，除了使用标准的exp（x），我们也使用exp（six） ，其中si是一个可训练的标量，自动调节特征层Pi的指数函数的底数，从而提升性能。</p><h2 id="Center-ness"><a href="#Center-ness" class="headerlink" title="Center-ness"></a>Center-ness</h2><p>通过FPN多尺度预测之后发现FCOS和基于anchor的检测器之间仍然存在着一定的性能差距，主要原因是距离目标中心较远的位置产生很多低质量的预测边框。<br>Center-ness的作用就是用来很好的抑制这些低质量的预测边框的产生，它的优点是比较简单。不需要引入其它的超参数。它的位置是在Head网络的分类网络分支下面，与分类分支平行。对于给定的一个位置的回归目标:<br>$$<br>l^{\ast}, t^{\ast}, r^{\ast}, b^{\ast}<br>$$<br>center-ness目标的定义如下:<br>$$<br>centerness ^{\ast}=\sqrt{\frac{\min \left(l^{\ast}, r^{\ast}\right)}{\max \left(l^{\ast}, r^{\ast}\right)} \times \frac{\min \left(t^{\ast}, b^{\ast}\right)}{\max \left(t^{\ast}, b^{\ast}\right)}}<br>$$<br>使用根号是为了降低centerness衰减的速度。center-ness（中心度）取值为0到1之间，通过二元交叉熵损失来训练。并把这个损失加入前面提到的损失函数中。测试时，将预测的center-ness和对应的分类得分相乘，得到最终的得分，再用这个得分对检测边框进行排名。因此center-ness可以降低那些远离物体中心边框的得分。在最后的NMS过程中，这些低质量的边框就会很大概率上被剔除，从而显着提高了检测性能。<br>基于anchor的检测器使用2个IOU阈值Tlow,Thigh来将anchor box标为负样本、忽略和正样本。而 center-ness可以看作为一个soft阈值。Center-ness通过模型训练来学习，而无需手动去调。而且依据此方法，我们的检测器仍可以将任意落入ground truth边框的点看作正样本，除了那些在多层级预测中已经被标注为负样本的点，在回归器中就可以使用尽可能多的训练样本。</p><h2 id="算法细节"><a href="#算法细节" class="headerlink" title="算法细节"></a>算法细节</h2><p>在训练阶段，文中使用ResNet-50作为backbone网络，使用SGD优化器，初始学习率为0.01，batch_size=16，在迭代60K和80K时的weight_decay分别为0.0001和0.9，使用ImagNet预训练权重进行初始化，将输入图片裁剪为短边不小于800，长边不小于1333大小。整个网络是在COCO数据集上面训练得到的。</p><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>在COCO数据集上，各种目标检测算法PK。FCOS已经超越 Two-stage的Faster R-CNN，还超越了 One-stage的YOLOv2、SSD、RetinaNet，以及很新的CornerNet。<br>相比于YOLOV1算法，YOLOV1只利用了目标的中心区域的点做预测，因此召回率较低。而FCOS利用了目标的整个区域内的点，召回率和基于anchor-based的算法相当；尽管centerness确实带来效果上的明显提升，但是缺乏理论可解释性；作为一种新的one stage算法，论文中未题算法的推理的速度，可见该算法的速度并不算快。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基于关键点的Anchor-Free目标检测算法&quot;&gt;&lt;a href=&quot;#基于关键点的Anchor-Free目标检测算法&quot; class=&quot;headerlink&quot; title=&quot;基于关键点的Anchor Free目标检测算法&quot;&gt;&lt;/a&gt;基于关键点的Anchor Free
      
    
    </summary>
    
    
      <category term="目标检测" scheme="https://wyg1996.cn/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
    
      <category term="目标检测" scheme="https://wyg1996.cn/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>目标跟踪概念、多目标跟踪算法SORT和deep SORT原理</title>
    <link href="https://wyg1996.cn/2019/05/29/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E6%A6%82%E5%BF%B5%E3%80%81%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95SORT%E5%92%8Cdeep-SORT%E5%8E%9F%E7%90%86/"/>
    <id>https://wyg1996.cn/2019/05/29/目标跟踪概念、多目标跟踪算法SORT和deep-SORT原理/</id>
    <published>2019-05-29T11:52:43.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目标跟踪、单目标跟踪、多目标跟踪的概念"><a href="#目标跟踪、单目标跟踪、多目标跟踪的概念" class="headerlink" title="目标跟踪、单目标跟踪、多目标跟踪的概念"></a>目标跟踪、单目标跟踪、多目标跟踪的概念</h1><p><strong>目标跟踪分为静态背景下的目标跟踪和动态背景下的目标跟踪。</strong><br><strong>静态背景下的目标跟踪:</strong><br>静态背景下的目标跟踪指摄像头是固定的，其采集的视野中背景是静止的，如在十字路口的固定摄像头。<br><strong>动态背景下的目标跟踪:</strong><br>摄像头采集的视野中背景和目标都是在变化的。</p><p><strong>目标跟踪又分为单目标跟踪和多目标跟踪。</strong><br><strong>单目标跟踪:</strong><br>在视频的初始帧画面上框出单个目标，预测后续帧中该目标的大小与位置。典型算法有Mean shift（用卡尔曼滤波、粒子滤波进行状态预测）、TLD（基于在线学习的跟踪）、KCF（基于相关性滤波）等。<br><strong>多目标追踪:</strong><br>不像单目标追踪一样先在初始帧上框出单个目标，而是追踪多个目标的大小和位置，且每一帧中目标的数量和位置都可能变化。此外，多目标的追踪中还存在下列问题:<br>处理新目标的出现和老目标的消失；<br>跟踪目标的运动预测和相似度判别，即上一帧与下一帧目标的匹配；<br>跟踪目标之间的重叠和遮挡处理；<br>跟踪目标丢失一段时间后再重新出现的再识别。</p><h1 id="欧氏距离、马氏距离、余弦距离"><a href="#欧氏距离、马氏距离、余弦距离" class="headerlink" title="欧氏距离、马氏距离、余弦距离"></a>欧氏距离、马氏距离、余弦距离</h1><h2 id="欧氏距离"><a href="#欧氏距离" class="headerlink" title="欧氏距离"></a>欧氏距离</h2><p>在数学中，欧几里得距离或欧几里得度量是欧几里得空间中两点间“普通”（即直线）距离。<br>假设二维空间中有点（x1,y1）和（x2,y2），则这两点的欧氏距离为:<br>$$<br>\rho=\sqrt{\left(x_{2}-x_{1}\right)^{2}+\left(y_{2}-y_{1}\right)^{2}}<br>$$</p><h2 id="马氏距离"><a href="#马氏距离" class="headerlink" title="马氏距离"></a>马氏距离</h2><p>马氏距离（Mahalanobis distance）数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法。与欧氏距离不同，马氏距离考虑到各种特性之间的联系，并且与测量尺度无关。<br>对于一个均值为:<br>$$<br>\mu=\left(\mu_{1}, \mu_{2}, \mu_{3}, \dots, \mu_{p}\right)^{T}<br>$$<br>协方差矩阵为Σ的多变量矢量:<br>$$<br>x=\left(x_{1}, x_{2}, x_{3}, \dots, x_{p}\right)^{T}<br>$$<br>其马氏距离为:<br>$$<br>D_{M}(x)=\sqrt{(x-\mu)^{T} \Sigma^{-1}(x-\mu)}<br>$$<br><strong>马氏距离也可以定义为两个服从同一分布并且其协方差矩阵为Σ的随机变量x与y的差异程度:</strong><br>$$<br>d(\vec x, \vec y)=\sqrt{(\vec x-\vec y)^{T} \Sigma^{-1}(\vec x-\vec y)}<br>$$<br>如果协方差矩阵为单位矩阵（或者说去掉协方差矩阵），马氏距离就退化为欧氏距离。如果协方差矩阵为对角阵，其也可称为正规化的马氏距离:<br>$$<br>d(\vec x, \vec y)=\sqrt{\sum_{i=1}^{p} \frac{\left(x_{i}-y_{i}\right)^{2}}{\sigma_{i}^{2}}}<br>$$<br>其中σi是xi的标准差。<br><strong>协方差的物理意义:</strong><br>在概率论中，两个随机变量X与Y之间的相互关系有3种情况:正相关、负相关、不相关（这里的相关都是指线性相关）。<br>我们可以定义一个表示X, Y 相互关系的数字特征，也就是协方差:<br>$$<br>cov(X, Y)=E(X-E X)(Y-E Y)<br>$$<br>当cov（X, Y）&gt;0时，表明X与Y正相关；当cov（X, Y）&lt;0时，表明X与Y负相关；当cov（X, Y）=0时，表明X与Y不相关。<br><strong>使用欧式距离衡量两个变量，距离近就一定相似吗？</strong><br>如果两个变量的度量尺度不同，如身高和体重，身高用毫米计算，而体重用千克计算。显然差10mm的身高与差10kg的体重是完全不同的。但在普通的欧氏距离中，这将会算作相同的差距。<br><strong>如果使用归一化后的欧氏距离，两个变量的欧氏距离近就一定相似吗？</strong><br>归一化可以消除不同变量间的度量尺度不同的问题，但是不同变量之间的方差还是不一样。第一个类别均值为0，方差为0.1，第二个类别均值为5，方差为5。那么一个值为2的点属于第一类的概率大还是第二类的概率大？距离上说应该是第一类，但是直觉上显然是第二类，因为第一类不太可能到达2这个位置。因此，在一个方差较小的维度下很小的差别就有可能成为离群点。<br><strong>如果维度间不独立同分布，样本点与欧氏距离近的样本点同类的概率一定会更大吗？</strong><br>如果维度间不是独立同分布的，那么两个点即使距离均值点距离相同，但显然更接近整体分布点集的点与该点集同类的概率更大。<br><strong>马氏距离的几何意义:</strong><br>马氏距离就是将变量按照主成分进行旋转，让维度间相互独立，然后进行标准化，使不同的维度独立同分布。由于主成分就是特征向量方向，每个方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值的倍数。这样，离群点就被成功分离，这时候的新坐标系下的欧式距离就是马氏距离。</p><h2 id="余弦距离"><a href="#余弦距离" class="headerlink" title="余弦距离"></a>余弦距离</h2><p>余弦距离，也称为余弦相似度，是用N维空间中两点与原点连接线段之间夹角的余弦值作为衡量两个个体间差异的大小的度量。余弦距离越大，表示夹角越小，那么两点越相似。如果余弦距离为1（最大值），那么表示两者非常相似。注意这里只能说明两点非常相似，并不一定相同。<br><strong>余弦距离公式:</strong><br>$$<br>sim(X, Y)=\cos \theta=\frac{\vec x \cdot \vec y}{||x|| \cdot ||y||}<br>$$<br><strong>向量a和向量b点乘的公式:</strong><br>$$<br>a \cdot b=a_{1} b_{1}+a_{2} b_{2}+\ldots+a_{\mathrm{n}} b_{n}<br>$$<br><strong>余弦距离的意义:</strong><br>当两点夹角为零时，表示两点的各个维度的值所占的比例相同。比如（2，2，2）和（6，6，6），（1，2，3）和（3，6，9）。</p><h1 id="SORT算法原理"><a href="#SORT算法原理" class="headerlink" title="SORT算法原理"></a>SORT算法原理</h1><p>论文:Simple Online and Realtime Tracking<br>论文地址:<a href="https://arxiv.org/pdf/1602.00763.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1602.00763.pdf</a> 。<br>代码地址:<a href="https://github.com/abewley/sort" target="_blank" rel="noopener">https://github.com/abewley/sort</a> 。</p><p>在sort算法中，目标检测模型的性能是影响追踪效果的一个关键因素。SORT算法全称为Simple Online And Realtime Tracking, 对于tracking-by-detection的多目标跟踪方法，更多依赖的是其目标检测模型的性能的好坏。尽管只是简单的结合了Kalman滤波追踪和匈牙利指派算法，效果却可以匹配2016年的SOTA算法。另外，由于本文的算法复杂度低，追踪器可以实现260Hz的速度，比前者快了20倍。<br>多目标追踪问题可以被看成是数据关联问题，目的是在视频帧序列中进行跨帧检测结果的关联。作者没有在目标追踪过程中使用任何的目标外观特征，而是仅使用检测框的位置和大小进行目标的运动估计和数据关联。另外，没有考虑遮挡问题，也没有通过目标的外观特征进行目标重识别，作者一切的核心就是围绕处理速度要快，要能够实时应用。<br>作者使用CNN进行目标检测，使用kalman滤波进行目标运动状态估计，使用匈牙利匹配算法进行位置匹配。文章主要关注行人目标的追踪。</p><h2 id="SORT算法中的匈牙利匹配算法"><a href="#SORT算法中的匈牙利匹配算法" class="headerlink" title="SORT算法中的匈牙利匹配算法"></a>SORT算法中的匈牙利匹配算法</h2><h3 id="最大匹配的匈牙利算法"><a href="#最大匹配的匈牙利算法" class="headerlink" title="最大匹配的匈牙利算法"></a>最大匹配的匈牙利算法</h3><p>该算法详细原理可以看我的另一篇专门介绍匈牙利算法最大匹配原理的博客。<br>我们知道一个二分图可以用矩阵的形式来表示，如:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">graph_1 = [(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">           (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)]</span><br></pre></td></tr></table></figure><p>上例表示这个二分图的U集合有8个点，V集合也有8个点，当两点之间有边时对应位置的值为1，否则为0。<br>匈牙利算法的目标是从二分图中找出一个最大匹配，即匹配边最多的匹配方式。</p><h3 id="指派问题中的匈牙利算法"><a href="#指派问题中的匈牙利算法" class="headerlink" title="指派问题中的匈牙利算法"></a>指派问题中的匈牙利算法</h3><p>进一步地，我们可以将二分图变成下面的形式:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">     A    B    C    D</span><br><span class="line">甲   <span class="number">2</span>    <span class="number">15</span>   <span class="number">13</span>   <span class="number">4</span></span><br><span class="line">乙   <span class="number">10</span>   <span class="number">4</span>    <span class="number">14</span>   <span class="number">15</span></span><br><span class="line">丙   <span class="number">9</span>    <span class="number">14</span>   <span class="number">16</span>   <span class="number">13</span></span><br><span class="line">丁   <span class="number">7</span>    <span class="number">8</span>    <span class="number">11</span>   <span class="number">9</span></span><br></pre></td></tr></table></figure><p>此时U集合中任意点和V集合中任意点都有边，但边的代价不同。此时我们的目标是，在矩阵中选取n个元素（即n条不同代价的边），使得每行每列各有1个元素（U集合和V集合中的每一个点都有配对点），且边的代价和最小。<br>我们将上述矩阵赋予一个实际问题的含义：有n项不同的任务，需要n个人分别完成其中的1项，每个人完成任务的时间不一样。于是就有一个问题，如何分配任务使得花费时间最少。<br><strong>最优解性质:</strong><br>若从矩阵的一行（列）各元素中分别减去该行（列）的最小元素，得到一个归约矩阵，这个规约矩阵的最优解与原矩阵的最优解相同。</p><p><strong>指派问题的匈牙利算法的基本思路:</strong></p><ul><li>通过行/列变换让规约（费用）矩阵的每行和每列都出现0；</li><li>找出不同行不同列的n个0；</li><li>这些0对应的边就是最优指派（代价最少）。</li></ul><p><strong>指派问题的匈牙利算法的主要步骤:</strong></p><ul><li>先对规约（费用）矩阵先作行变换，再作列变换。行变换即费用矩阵的每一行的各个元素分别减去该行的最小元素。列变换即费用矩阵的每一列的各个元素分别减去该列的最小元素，有0的列则无需作列变换；</li><li>在经过行变换和列变换的费用矩阵中寻找n个不同行不同列的0元素。如果找到，则这n个不同行不同列的0元素位置即对应最优指派。否则，进行下一步骤。一般使用标记法来寻找n个不同行不同列的0元素：<br>依次检查新费用矩阵的各行，找出只有一个没有加标记的0元素的行，并将这个0元素加上标记，而与这个0元素在同一列的0元素全划去；<br>依次检查新费用矩阵的各列，找出只有一个没有加标记的0元素的列，并将这个0元素加上标记，而与这个0元素在同一行的0元素全划去。</li><li>对新费用矩阵进行调整：对每一个加了标记的0元素画一条横线或竖线，使得这些横线和竖线覆盖全部0元素；在这些横线和竖线没有经过的元素中找出最小的元素；未画横线的各行元素减去这个最小的数，画竖线的各列元素加上这个最小的数；重新在费用矩阵中找出n个不同行不同列的0元素，从而找出最优指派（代价最少）。</li></ul><p><strong>指派问题的匈牙利算法求解举例:</strong><br>原始矩阵如下，该矩阵U集合的点为甲、乙、丙、丁，V集合的点为A、B、C、D。矩阵中每个值是每条边的代价。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    A    B    C    D</span><br><span class="line">甲  <span class="number">90</span>   <span class="number">75</span>   <span class="number">75</span>   <span class="number">80</span></span><br><span class="line">乙  <span class="number">35</span>   <span class="number">85</span>   <span class="number">55</span>   <span class="number">65</span></span><br><span class="line">丙  <span class="number">125</span>  <span class="number">95</span>   <span class="number">90</span>   <span class="number">105</span></span><br><span class="line">丁  <span class="number">45</span>   <span class="number">110</span>  <span class="number">95</span>   <span class="number">115</span></span><br></pre></td></tr></table></figure><p>首先每行减去每行的最小值，矩阵变为:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    A    B    C    D</span><br><span class="line">甲  <span class="number">15</span>   <span class="number">0</span>    <span class="number">0</span>    <span class="number">5</span></span><br><span class="line">乙  <span class="number">0</span>    <span class="number">50</span>   <span class="number">20</span>   <span class="number">30</span></span><br><span class="line">丙  <span class="number">35</span>   <span class="number">5</span>    <span class="number">0</span>    <span class="number">15</span></span><br><span class="line">丁  <span class="number">0</span>    <span class="number">65</span>   <span class="number">50</span>   <span class="number">70</span></span><br></pre></td></tr></table></figure><p>然后每列减去每列的最小值，矩阵变为:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    A    B    C    D</span><br><span class="line">甲  <span class="number">15</span>   <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">乙  <span class="number">0</span>    <span class="number">50</span>   <span class="number">20</span>   <span class="number">25</span></span><br><span class="line">丙  <span class="number">35</span>   <span class="number">5</span>    <span class="number">0</span>    <span class="number">10</span></span><br><span class="line">丁  <span class="number">0</span>    <span class="number">65</span>   <span class="number">50</span>   <span class="number">65</span></span><br></pre></td></tr></table></figure><p>现在查找行或列中含有元素0的行或列，用最少数量的水平+垂直线覆盖所有的0。发现只要第一行、第一列、第三列就可以覆盖所有的0，线数量为3，小于U集合中点个数4。没有被覆盖的元素有50，5，65，25，10，65，其中最小元素为5。那么我们让没有被覆盖的每行减去最小值5，被覆盖的每列加上最小值5，然后继续寻找用最少数量的水平+垂直线覆盖所有的0。<br>第二、三、四行没有被覆盖，每行减去最小值5。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    A    B    C    D</span><br><span class="line">甲  <span class="number">15</span>   <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">乙  <span class="number">-5</span>   <span class="number">45</span>   <span class="number">15</span>   <span class="number">20</span></span><br><span class="line">丙  <span class="number">30</span>   <span class="number">0</span>    <span class="number">-5</span>   <span class="number">5</span></span><br><span class="line">丁  <span class="number">-5</span>   <span class="number">60</span>   <span class="number">45</span>   <span class="number">60</span></span><br></pre></td></tr></table></figure><p>第一、三列被覆盖，每行加上最小值5。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    A    B    C    D</span><br><span class="line">甲  <span class="number">20</span>   <span class="number">0</span>    <span class="number">5</span>    <span class="number">0</span></span><br><span class="line">乙  <span class="number">0</span>    <span class="number">45</span>   <span class="number">20</span>   <span class="number">20</span></span><br><span class="line">丙  <span class="number">35</span>   <span class="number">0</span>    <span class="number">0</span>    <span class="number">5</span></span><br><span class="line">丁  <span class="number">0</span>    <span class="number">60</span>   <span class="number">50</span>   <span class="number">60</span></span><br></pre></td></tr></table></figure><p>现在我们可以用第一行、第三行、第一列覆盖所有的0，线数量为3，仍小于U集合中点个数4。没被覆盖的元素有45，20，20，60，50，60，最小值元素为20。那么我们让没有被覆盖的每行减去最小值20，被覆盖的每列加上最小值20，然后继续寻找用最少数量的水平+垂直线覆盖所有的0。<br>第二、四行没有被覆盖，每行减去最小值20。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    A    B    C    D</span><br><span class="line">甲  <span class="number">20</span>   <span class="number">0</span>    <span class="number">5</span>    <span class="number">0</span></span><br><span class="line">乙  <span class="number">-20</span>  <span class="number">25</span>   <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">丙  <span class="number">35</span>   <span class="number">0</span>    <span class="number">0</span>    <span class="number">5</span></span><br><span class="line">丁  <span class="number">-20</span>  <span class="number">40</span>   <span class="number">30</span>   <span class="number">40</span></span><br></pre></td></tr></table></figure><p>第一列被覆盖，每行加上最小值20。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    A    B    C    D</span><br><span class="line">甲  <span class="number">40</span>   <span class="number">0</span>    <span class="number">5</span>    <span class="number">0</span></span><br><span class="line">乙  <span class="number">0</span>    <span class="number">25</span>   <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">丙  <span class="number">55</span>   <span class="number">0</span>    <span class="number">0</span>    <span class="number">5</span></span><br><span class="line">丁  <span class="number">0</span>    <span class="number">40</span>   <span class="number">30</span>   <span class="number">40</span></span><br></pre></td></tr></table></figure><p>现在我们用第一行、第二行、第三行、第四行可以覆盖所有的0。线数量为4等于U集合中点个数4。找到不同行不同列的n个0。即丁A、丙B、乙C、D甲位置的4个0。<br>上面矩阵找到的最优解和原始矩阵的最优解等同。原始矩阵的最优指派（最小代价）就是这四个位置上的代价之和，即45，95，55，80。</p><p><strong>在SORT算法中，二分图的边权值即前一帧的M个目标与后一帧的N个目标中，两两目标之间的IOU。</strong></p><h2 id="预测模型（卡尔曼滤波器）"><a href="#预测模型（卡尔曼滤波器）" class="headerlink" title="预测模型（卡尔曼滤波器）"></a>预测模型（卡尔曼滤波器）</h2><p>作者近似地认为目标的不同帧间地运动是和其他物体及相机运动无关的线性运动。每一个目标的状态可以表示为：<br>$$<br>x=[u, v, s, r, \dot{u}, \dot{v}, \dot{s}]^{T}<br>$$<br>其中u和v分别代表目标的中心坐标，而s和r分别代表目标边界框的比例（面积）和长宽比，长宽比被认为是常数，需要保持不变。<br>当进行目标关联时，使用卡尔曼滤波器，用上一帧中目标的位置信息预测下一帧中这个目标的位置。若上一帧中没有检测到下一帧中的某个目标，则对于这个目标，重新初始化一个新的卡尔曼滤波器。关联完成后，使用新关联的下一帧中该目标的位置来更新卡尔曼滤波器。</p><h2 id="数据关联（匈牙利匹配）"><a href="#数据关联（匈牙利匹配）" class="headerlink" title="数据关联（匈牙利匹配）"></a>数据关联（匈牙利匹配）</h2><p>SORT中匈牙利匹配的原理见上面指派问题中的匈牙利匹配算法。SORT算法中的代价矩阵为上一帧的M个目标与下一帧的N个目标两两目标之间的IOU。当然，小于指定IOU阈值的指派结果是无效的（源码中阈值设置为0.3）。<br>此外，作者发现使用IOU能够解决目标的短时被遮挡问题。这是因为目标被遮挡时，检测到了遮挡物，没有检测到原有目标，假设把遮挡物和原有目标进行了关联。那么在遮挡结束后，因为在相近大小的目标IOU往往较大，因此很快就可以恢复正确的关联。这是建立在遮挡物面积大于目标的基础上的。</p><h2 id="目标丢失问题的处理"><a href="#目标丢失问题的处理" class="headerlink" title="目标丢失问题的处理"></a>目标丢失问题的处理</h2><p>如果连续Tlost帧没有实现已追踪目标预测位置和检测框的IOU匹配，则认为目标消失。实验中设置 Tlost=1，文中指出是因为没有匹配的目标所使用的均速运动假设模型效果很差，并且帧数过多的re-id问题超出了本文讨论的范围（作者主要关注逐帧的目标追踪，而不关注长时间的目标丢失再重识别问题）。另外，尽早删除已丢失的目标有助于提升追踪效率。但是这样容易导致目标ID会频繁切换，造成跟踪计数的不准确。</p><h2 id="SORT算法过程"><a href="#SORT算法过程" class="headerlink" title="SORT算法过程"></a>SORT算法过程</h2><p>对第一帧使用目标检测模型进行目标检测，得到第一帧中所有目标的分类和位置（假设有M个目标），并标注一个独有id。对每个目标初始化卡尔曼滤波跟踪器，预测每个目标在下一帧的位置；<br>对第二帧使用目标检测模型进行目标检测，得到第二帧中所有目标的分类和位置（假设有N个目标），求第一帧M个目标和第二帧N个目标两两目标之间的IOU，建立代价矩阵，使用匈牙利匹配算法得到IOU最大的唯一匹配（数据关联部分），再去掉匹配值小于iou_threshold的匹配对；<br>用第二帧中匹配到的目标的位置去更新卡尔曼跟踪器，计算第二帧时的卡尔曼增益Kk，状态估计值xk，估计误差协方差Pk。并输出状态估计值xk用来计算下一帧中的预测位置。对于本帧中没有匹配到的目标重新初始化卡尔曼滤波跟踪器；<br>后面每一帧图像都按第一帧和第二帧的做法进行类似处理即可。</p><h1 id="deep-SORT算法原理"><a href="#deep-SORT算法原理" class="headerlink" title="deep SORT算法原理"></a>deep SORT算法原理</h1><p>论文:Simple Online and Realtime Tracking With a Deep Association Metric<br>论文地址:<a href="https://arxiv.org/pdf/1703.07402.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.07402.pdf</a> 。<br>代码地址:<a href="https://github.com/nwojke/deep_sort" target="_blank" rel="noopener">https://github.com/nwojke/deep_sort</a> 。</p><h2 id="状态估计"><a href="#状态估计" class="headerlink" title="状态估计"></a>状态估计</h2><p>使用一个8维空间去刻画轨迹在某时刻的状态：<br>$$<br>(u, v, \gamma, h, \dot{x}, \dot{y}, \dot{\gamma}, \dot{h})<br>$$<br>使用一个kalman滤波器预测更新轨迹，该卡尔曼滤波器采用匀速模型和线性观测模型。通过卡尔曼估计对(u, v, r, h)进行估计，u，v是物体中心点的位置，r是长宽比，h是高。运动估计对于运动状态变化不是很剧烈和频繁的物体能取得比较好的效果。<br>其观测变量为:<br>$$<br>(u, v, \gamma, h)<br>$$</p><h2 id="轨迹处理"><a href="#轨迹处理" class="headerlink" title="轨迹处理"></a>轨迹处理</h2><p>对于每一个追踪目标，都有一个阈值ak用于记录轨迹从上一次成功匹配到当前时刻的时间（即连续没有匹配的帧数），我们称之为轨迹。当该值大于提前设定的阈值Amax则认为该轨迹终止，直观上说就是长时间匹配不上的轨迹则认为该轨迹已经结束。<br>在匹配时，对于没有匹配成功的目标都认为可能产生新的轨迹。但由于这些检测结果可能是一些错误警告，所以对这种情形新生成的轨迹标注状态’tentative’，然后观查在接下来的连续若干帧（论文中是3帧）中是否连续匹配成功，是的话则认为是新轨迹产生，标注为’confirmed’，否则则认为是假性轨迹,状态标注为’deleted’。</p><h2 id="分配问题的评价指标"><a href="#分配问题的评价指标" class="headerlink" title="分配问题的评价指标"></a>分配问题的评价指标</h2><p><strong>在位置度量上，使用马氏距离（Mahalanobis distance）来评价卡尔曼滤波预测的状态和实际状态的匹配程度（运动匹配程度）:</strong><br>$$<br>d^{(1)}(i, j)=\left(d_{j}-y_{i}\right)^{T} S_{i}^{-1}\left(d_{j}-y_{i}\right)<br>$$<br>上式左边表示第j个检测到的目标和第i条轨迹之间的运动匹配度，其中Si是第i条轨迹由kalman滤波器预测得到的在当前时刻观测空间的协方差矩阵，yi是轨迹在当前时刻的预测观测量，dj是第j个目标的实际状态（u,v,r,h）。<br>考虑到运动的连续性，可以通过该马氏距离对目标进行筛选，文中使用卡方分布的0.95分位点作为阈值 t^{(1)} =0.4877,我们可以定义一个门限函数：<br>$$<br>b_{i j}^{(1)}=\mathbf{1}\left[d^{(1)(i, j)} \leq t^{(1)}\right]<br>$$<br>当目标运动不确定性较低时，马氏距离是一个很好的关联度量。但在实际中，如相机运动时会造成马氏距离大量不能匹配，也就会使这个度量失效。因此，我们整合第二个度量标准，对每一个BBox检测框dj我们计算一个表面特征描述子：<br>$$<br>r_{j},\left|r_{j}\right|=1<br>$$<br><strong>我们保存最新的Lk=100个轨迹的描述子，然后我们计算使用第i个轨迹和第j个轨迹的最小余弦距离（cosine distance）来衡量检测和轨迹之间的外观相似程度：</strong><br>$$<br>d^{(2)}(i, j)=\min \left(1-r_{j}^{T} r_{k}^{(i)} | r_{k}^{(i)} \in R_{i}\right)<br>$$<br>同样的，该度量同样可以确定一个门限函数:<br>$$<br>b_{i, j}^{(2)}=\mathbb{1}\left[d^{(2)}(i, j) \leq t^{(2)}\right]<br>$$<br>最后的评价指标是上面两种距离的加权和:<br>$$<br>c_{i, j}=\lambda d^{(1)}(i, j)+(1-\lambda) d^{(2)}(i, j)<br>$$<br>$$<br>b_{i, j}=\prod_{m=1}^{2} b_{i, j}^{(m)}<br>$$<br>其中是λ是超参数，用于调整不同项的权重。<br>总之，马氏距离对于短期的预测和匹配效果很好，而最小余弦距离对于长时间丢失的轨迹而言，匹配度度量的比较有效。超参数的选择要看具体的数据集，比如文中说对于相机运动幅度较大的数据集，直接不考虑运动匹配程度。</p><h2 id="级联匹配"><a href="#级联匹配" class="headerlink" title="级联匹配"></a>级联匹配</h2><p>如果一条轨迹被遮挡了一段较长的时间，那么在kalman滤波器的不断预测中就会导致概率弥散。那么假设现在有两条轨迹竞争同一个目标，那么那条遮挡时间长的往往得到马氏距离更小，使目标倾向于匹配给丢失时间更长的轨迹，但是直观上，该目标应该匹配给时间上最近的轨迹。<br>导致这种现象的原因正是由于kalman滤波器连续预测没法更新导致的概率弥散。假设本来协方差矩阵是一个正态分布，那么连续的预测不更新就会导致这个正态分布的方差越来越大，那么离均值欧氏距离远的点可能和之前分布中离得较近的点获得同样的马氏距离值。<br>所以本文中才引入了级联匹配的策略将遮挡时间按等级分层，遮挡时间越小的匹配等级更高，即更容易被匹配。<br>首先是得到追踪框集合T和检测框集合D，设置最大的Amax为轨迹最大允许丢失匹配的帧数。通过计算上面的评价指标（两种度量的加权和）得到成本矩阵，再通过级联条件，设定阈值分别对外观和位置因素进行计算，满足条件则返回1，否则返回0。然后初始化匹配矩阵为空，初始化未匹配矩阵等于D。通过匈牙利算法，对于每个属于追踪框集合的元素T，在检测框里面查找成本最低且满足阈值过滤条件的检测框作为匹配结果，同时更新匹配矩阵和非匹配矩阵。<br>在匹配的最后阶段还对unconfirmed和age=1的未匹配轨迹进行基于IOU的匹配。这可以缓解因为表观突变或者部分遮挡导致的较大变化。当然有好处就有坏处，这样做也有可能导致一些新产生的轨迹被连接到了一些旧的轨迹上。但这种情况较少。</p><h2 id="深度表观描述子"><a href="#深度表观描述子" class="headerlink" title="深度表观描述子"></a>深度表观描述子</h2><p>预训练的网络时一个在大规模ReID数据集上训练得到的，这个ReID数据集包含1261个人的1100000幅图像，使得学到的特征很适合行人跟踪。<br>然后使用该预训练网络作为基础网络，构建wide ResNet，用来提取bounding box的表观特征。该网络在Nvidia GeForce GTX 1050 mobile GPU下提取出32个bounding boxes大约花费30ms，可以满足实时性要求。</p><h2 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a>算法总结</h2><p>使用wide ResNet提取的特征进行匹配，大大减少了SORT中的ID switches, 经作者实验证明减少了大约45%, 在高速率视频流中也达到了很好的水准。该模型的速度主要取决于目标检测模型的速度，在匹配上面耗时很短。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;目标跟踪、单目标跟踪、多目标跟踪的概念&quot;&gt;&lt;a href=&quot;#目标跟踪、单目标跟踪、多目标跟踪的概念&quot; class=&quot;headerlink&quot; title=&quot;目标跟踪、单目标跟踪、多目标跟踪的概念&quot;&gt;&lt;/a&gt;目标跟踪、单目标跟踪、多目标跟踪的概念&lt;/h1&gt;&lt;p&gt;&lt;s
      
    
    </summary>
    
    
      <category term="目标追踪" scheme="https://wyg1996.cn/categories/%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AA/"/>
    
    
      <category term="目标追踪" scheme="https://wyg1996.cn/tags/%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AA/"/>
    
  </entry>
  
  <entry>
    <title>匈牙利匹配算法原理</title>
    <link href="https://wyg1996.cn/2019/05/27/%E5%8C%88%E7%89%99%E5%88%A9%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/"/>
    <id>https://wyg1996.cn/2019/05/27/匈牙利匹配算法原理/</id>
    <published>2019-05-27T14:18:58.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图论中的基本概念"><a href="#图论中的基本概念" class="headerlink" title="图论中的基本概念"></a>图论中的基本概念</h1><p><strong>二分图:</strong><br>一个图中的所有顶点可划分为两个不相交的集合 U 和 V ，使得每一条边都分别连接U、V中的顶点。如果存在这样的划分，则此图为一个二分图。<br><strong>匹配:</strong><br>一个匹配就是一个边的集合，这个边集合中的任意两条边没有公共的顶点。<br><strong>最大匹配:</strong><br>一个图的所有匹配中，所含匹配边数最多的匹配，称为这个图的最大匹配。<br><strong>最大匹配数:</strong><br>最大匹配的匹配边的数目。<br><strong>完美匹配:</strong><br>如果一个图的某个匹配中，所有的顶点都是匹配点，那么它就是一个完美匹配。显然，完美匹配一定是最大匹配（完美匹配的任何一个点都已经匹配，添加一条新的匹配边一定会与已有的匹配边冲突）。但并非每个图都存在完美匹配。<br><strong>最小顶点覆盖数:</strong><br>选取最少的点，使二分图中任意一条边至少有一个端点被选择。最小覆盖要求用最少的点（U集合或V集合的都行）让每条边都至少和其中一个点关联。可以证明：最少的点（即覆盖数）＝最大匹配数<br><strong>最大独立数:</strong><br>选取最多的点，使任意所选两点均不相连。<br><strong>最小路径覆盖数:</strong><br>对于一个 DAG（有向无环图），选取最少条数的路径，使得每个顶点属于且仅属于一条路径，路径长可以为 0（即单个点）。也就是说用尽量少的不相交简单路径覆盖DAG的所有结点。<br><strong>一些性质:</strong><br>定理1：最大匹配数=最小点覆盖数（Konig 定理）<br>定理2：最大匹配数=最大独立数<br>定理3：最小路径覆盖数=顶点数-最大匹配数</p><h1 id="匈牙利算法中的基本概念"><a href="#匈牙利算法中的基本概念" class="headerlink" title="匈牙利算法中的基本概念"></a>匈牙利算法中的基本概念</h1><p><strong>交替路:</strong><br>从一个未匹配的点出发，依次经过非匹配边、匹配边、非匹配边······这样形成的路径叫交替路。<br><strong>增广路:</strong><br>从一个未匹配的点出发，走交替路，如果路过一个未匹配的点（第一个点除外），这条交替路叫增广路。<br>增广路有一个重要特点：非匹配边比匹配边多一条。因此，研究增广路的意义是改进匹配。只要把增广路中的匹配边和非匹配边的身份交换即可。由于中间的匹配节点不存在其他相连的匹配边，所以这样做不会破坏匹配的性质。交换后，图中的匹配边数目比原来多了 1 条。<br>我们可以通过不停地找增广路来增加匹配中的匹配边和匹配点。找不到增广路时，达到最大匹配（这是增广路定理）。匈牙利算法正是这么做的，这也是算法的核心。</p><h1 id="匈牙利匹配算法"><a href="#匈牙利匹配算法" class="headerlink" title="匈牙利匹配算法"></a>匈牙利匹配算法</h1><p>论文:The Hungarian Method for the Assignment Problem<br>论文地址:<a href="https://web.eecs.umich.edu/~pettie/matching/Kuhn-hungarian-assignment.pdf" target="_blank" rel="noopener">https://web.eecs.umich.edu/~pettie/matching/Kuhn-hungarian-assignment.pdf</a> 。<br><strong>重要定理:</strong><br>如果从一个点A出发，没有找到增广路径，那么无论再从别的点出发找到多少增广路径来改变现在的匹配，从点A出发都永远找不到增广路径。<br><strong>匈牙利算法的核心思想:</strong><br>初始时最大匹配为控，然后不断寻找增广路，并扩展增广路。不断重复这一过程直到找不到增广路为止。<br>如果二分图左半边U集合中共有n个点，那么最多找n条增广路径。如果图中共有m条边，那么每找一条增广路径（DFS或BFS）时最多把所有边遍历一遍，所花时间也就是m。所以总时间大概就是O（nm）。<br><strong>使用DFS查找的匈牙利匹配算法流程:</strong><br>从左边U集合找出第一个未匹配点（假设为点1）进行BFS边搜索，寻找一条未匹配边。如果找到一条未匹配边（假设为边1），这个边的另一头是右边V集合中的一个未匹配点（假设为点A），说明寻找成功。更新路径信息，匹配边数+1；<br>再找到左边U集合的第二个未匹配点（假设为点2），进行BFS边搜索。假如搜索到一条边（假设为边2），该边连接的另一个点V集合中前一轮已经匹配的点（点A），那么我们将边2作为点2和点A的未匹配边，然后对放弃的未匹配边（边1）的另一个点（点1）重新进行BFS边搜索（这次搜索跳过已经选择过的边1），寻找另一条未匹配边。假设我们找到了新的一条为匹配边（边3），该边连接点1和点C。<br>对于后面的每一轮，我们都从左边U集合中找出一个未匹配点x，然后进行BFS边搜索，如果搜到一条边，其另一点是V集合中前几轮中已经匹配的点y’，那么我们找到y’以前的未匹配边t，找到该边另一头属于左边U集合的点x’，对x’进行BFS边搜索（跳过前面已经选择的边），继续寻找未匹配边。如果x’BFS搜索到下一条边的另一点也是V集合中前几轮中已经匹配的点y’’，那么继续迭代执行上述过程。直到最后迭代找到的点的所有边都搜索过，且找不到为匹配边为止，此时我们就认为本轮最初选择的未匹配点x和点y’无法配对，我们不再从这个点x开始搜索。</p><h1 id="匈牙利匹配算法举例"><a href="#匈牙利匹配算法举例" class="headerlink" title="匈牙利匹配算法举例"></a>匈牙利匹配算法举例</h1><p>原始二分图中，集合U有点1、2、3、4，集合V中有点5、6、7、8，边有：1-5，1-6，2-5，3-6，3-8，4-7。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1---5</span><br><span class="line"> \ /</span><br><span class="line"> / \</span><br><span class="line">2   6</span><br><span class="line">   /</span><br><span class="line"> /</span><br><span class="line">3   7</span><br><span class="line"> \ /</span><br><span class="line"> / \</span><br><span class="line">4   8</span><br></pre></td></tr></table></figure><p><strong>第一轮:</strong><br>选取集合U中未匹配点1，进行BFS边搜索，找到第一条边1-5，5是集合V中未匹配点，这样我们找到了一条边，将集合U的未匹配点1和集合V的未匹配点5配对，我们用link[5] = 1来表示。<br><strong>第二轮:</strong><br>接着选取集合U中未匹配的点2，进行BFS边搜索，找到第一条边2-5，但关于5这个点前面已经标记了一个配对边1-5，那么我们再对原来的点1继续进行BFS边搜索，发现另一条边1-6，6是集合V中未匹配点，于是将集合U的未匹配点1和集合V的未匹配点6配对，用link[6] = 1表示，此时link[5] = 1不变，但是要注意它此时的含义是点2和点5配对。<br><strong>第三轮:</strong><br>接着选取集合U中未匹配的点3，进行BFS边搜索，找到第一条边3-6，由于link[6] = 1，于是向前找到原来与6配对的点1，对点1再做BFS边搜索，发现边1-5，但点5已经和点2配对了。那么再对点2做BFS边搜索，发现2只有边2-5，搜索到头了只能停止。因此点3不能和点6配对。<br>再找点3的第二条边，找到边3-8，8是集合V中未匹配点，这样我们将集合U的未匹配点3和集合V的未匹配点8配对，我们用link[8] = 1来表示。<br><strong>第四轮:</strong><br>接着选取集合U中未匹配点4，进行BFS边搜索，找到第一条边4-7，7是集合V中未匹配点，这样我们将集合U的未匹配点4和集合V的未匹配点7配对，我们用link[7] = 1来表示。</p><p>这样我们就找到了这个二分图的最大匹配。最大匹配中包含的边是1-6，2-5，3-8，4-7。</p><h1 id="匈牙利匹配算法Python代码实现"><a href="#匈牙利匹配算法Python代码实现" class="headerlink" title="匈牙利匹配算法Python代码实现"></a>匈牙利匹配算法Python代码实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HungarianAlgorithm</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, graph)</span>:</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">这里的队列虽然用list也可以实现,但pop(0)的开销还是很大,因此还是用链式存储结构Deque</span></span><br><span class="line"><span class="string">:param graph: 二分图的矩阵表示形式</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">self.graph = graph</span><br><span class="line">self.length = len(graph)</span><br><span class="line"></span><br><span class="line"><span class="comment"># x为输入的U集合中某个未匹配点，从V集合中寻找另一个未匹配点与其配对</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find</span><span class="params">(self, x)</span>:</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(self.length):</span><br><span class="line"><span class="comment"># V集合中的点从第一个点开始遍历,如果两点之间有边且还没访问过V集合中这个点i</span></span><br><span class="line"><span class="keyword">if</span> self.graph[x][i] == <span class="number">1</span> <span class="keyword">and</span> <span class="keyword">not</span> self.used[i]:</span><br><span class="line"><span class="comment"># 记录匹配边,放入交替路,记录V集合中的点i已访问过</span></span><br><span class="line">self.used[i] = <span class="number">1</span></span><br><span class="line"><span class="comment"># 如果点i之前已经访问过</span></span><br><span class="line"><span class="comment"># 如果V集合中的点i之前没有匹配过,或V集合中的点i之前匹配过,那么i的配对点为输入的x,x的配对点位i</span></span><br><span class="line"><span class="keyword">if</span> self.match[i] == <span class="number">-1</span> <span class="keyword">or</span> self.find(self.match[i]) == <span class="number">1</span>:</span><br><span class="line"><span class="comment"># 那边令V集合的这个点匹配对象更新为x,</span></span><br><span class="line">self.match[i] = x</span><br><span class="line">self.match[x] = i</span><br><span class="line">print(x + <span class="number">1</span>, <span class="string">'-&gt;'</span>, i + <span class="number">1</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hungarian1</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">递归形式的匈牙利匹配算法</span></span><br><span class="line"><span class="string">:return:</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># 记录V集合中点的匹配情况的矩阵,一开始全初始化为-1,表示均未匹配</span></span><br><span class="line">self.match = [<span class="number">-1</span>] * self.length</span><br><span class="line"><span class="comment"># 记录是否访问过某个点(列表的某个元素,即矩阵的行向量)的矩阵,一开始全为False,表示全未访问过</span></span><br><span class="line">self.used = [<span class="literal">False</span>] * self.length</span><br><span class="line">m = <span class="number">0</span></span><br><span class="line"><span class="comment"># 遍历所有U集合中的点(即列表的每个元素,每一个元素都是一个行向量,记录了这个U集合中的点与V集合中的哪些点有边)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(self.length):</span><br><span class="line"><span class="comment"># 如果U集合中第i个点还未匹配</span></span><br><span class="line"><span class="keyword">if</span> self.match[i] == <span class="number">-1</span>:</span><br><span class="line"><span class="comment"># 令记录访问过的点记录的矩阵初始化,注意对U集合中每个未匹配点这个矩阵都要重新初始化一次</span></span><br><span class="line">self.used = [<span class="literal">False</span>] * self.length</span><br><span class="line">print(<span class="string">"开始匹配U集合中第&#123;&#125;个点:"</span>.format(i + <span class="number">1</span>))</span><br><span class="line">m += self.find(i)</span><br><span class="line"><span class="comment"># 返回的是最大匹配的边个数</span></span><br><span class="line"><span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hungarian2</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">循环形式的匈牙利匹配算法</span></span><br><span class="line"><span class="string">:return:</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># 记录V集合中点的匹配情况的矩阵,一开始全初始化为-1,表示均未匹配</span></span><br><span class="line">match = [<span class="number">-1</span>] * self.length</span><br><span class="line"><span class="comment"># 记录是否访问过某个点(列表的某个元素,即矩阵的行向量)的矩阵,一开始全为False,表示全未访问过</span></span><br><span class="line">used = [<span class="number">-1</span>] * self.length</span><br><span class="line"><span class="comment"># 设置一个队列</span></span><br><span class="line">q_list = deque()</span><br><span class="line"><span class="comment"># 记录最大匹配的边个数</span></span><br><span class="line">ans = <span class="number">0</span></span><br><span class="line"><span class="comment"># 代表上一个节点</span></span><br><span class="line">prev = [<span class="number">0</span>] * self.length</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(self.length):</span><br><span class="line"><span class="comment"># 对U集合中第i个点,如果i还没有匹配过,清空队列,i假如队列</span></span><br><span class="line"><span class="keyword">if</span> match[i] == <span class="number">-1</span>:</span><br><span class="line">q_list.clear()</span><br><span class="line">q_list.append(i)</span><br><span class="line"><span class="comment"># 设i为出发点</span></span><br><span class="line">prev[i] = <span class="number">-1</span></span><br><span class="line"><span class="comment"># flag=False表示未找到增广路</span></span><br><span class="line">flag = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 当队列不为空且还未找到增广路时</span></span><br><span class="line"><span class="keyword">while</span> len(q_list) &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> flag:</span><br><span class="line"><span class="comment"># 队列左边出一个元素(即我们进队列的前面的点,最早进的点先出)</span></span><br><span class="line">u = q_list.popleft()</span><br><span class="line"><span class="comment"># 查找V集合中的未匹配点</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(self.length):</span><br><span class="line"><span class="comment"># 如果点U与V集合的点j有边且j的配对点不是i(即还未配对,或配对给其他点)</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> flag <span class="keyword">and</span> self.graph[u][j] == <span class="number">1</span> <span class="keyword">and</span> used[j] != i:</span><br><span class="line"><span class="comment"># 配对</span></span><br><span class="line">used[j] = i</span><br><span class="line"><span class="comment"># 如果u与j已经匹配过</span></span><br><span class="line"><span class="keyword">if</span> match[j] != <span class="number">-1</span>:</span><br><span class="line"><span class="comment"># 把点j也加入队列</span></span><br><span class="line">q_list.append(match[j])</span><br><span class="line"><span class="comment"># 记录点的顺序</span></span><br><span class="line">prev[match[j]] = u</span><br><span class="line"><span class="comment"># 如果u与j没有匹配过,现在就开始匹配,且flag=True表示找到增广路</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">flag = <span class="literal">True</span></span><br><span class="line">d = u</span><br><span class="line">e = j</span><br><span class="line"><span class="comment"># 将原匹配的边去掉加入原来不在匹配中的边</span></span><br><span class="line"><span class="keyword">while</span> (d != <span class="number">-1</span>):</span><br><span class="line">t = match[d]</span><br><span class="line">match[d] = e</span><br><span class="line">match[e] = d</span><br><span class="line">d = prev[d]</span><br><span class="line">e = t</span><br><span class="line">print(<span class="string">'match:'</span>, match)</span><br><span class="line">print(<span class="string">'prev:'</span>, prev)</span><br><span class="line">print(<span class="string">'deque'</span>, q_list)</span><br><span class="line"><span class="comment"># 新增匹配边</span></span><br><span class="line"><span class="keyword">if</span> match[i] != <span class="number">-1</span>:</span><br><span class="line">ans += <span class="number">1</span></span><br><span class="line"><span class="comment"># 返回的是最大匹配的边个数</span></span><br><span class="line"><span class="keyword">return</span> ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 二分图用矩阵形式存储,即有多少行U集合中集有几个点，有多少列V集合中就有几个点</span></span><br><span class="line"><span class="comment"># 两点之间如果有边则对应位置元素值为1(关于对角线对称)</span></span><br><span class="line">graph_1 = [(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">           (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">           (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_hungarian1</span><span class="params">(graph)</span>:</span></span><br><span class="line">h = HungarianAlgorithm(graph)</span><br><span class="line"><span class="comment"># print(h.graph)</span></span><br><span class="line"><span class="comment"># print(h.length)</span></span><br><span class="line">print(<span class="string">"最大匹配边数:&#123;&#125;"</span>.format(h.hungarian1()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_hungarian2</span><span class="params">(graph)</span>:</span></span><br><span class="line">h = HungarianAlgorithm(graph)</span><br><span class="line"><span class="comment"># print(h.graph)</span></span><br><span class="line"><span class="comment"># print(h.length)</span></span><br><span class="line">print(<span class="string">"最大匹配边数:&#123;&#125;"</span>.format(h.hungarian2()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">do_hungarian1(graph_1)</span><br><span class="line">do_hungarian2(graph_1)</span><br></pre></td></tr></table></figure><p>运行结果如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">开始匹配U集合中第<span class="number">1</span>个点:</span><br><span class="line">1 -&gt; 5</span><br><span class="line">开始匹配U集合中第<span class="number">2</span>个点:</span><br><span class="line">1 -&gt; 7</span><br><span class="line">2 -&gt; 5</span><br><span class="line">开始匹配U集合中第<span class="number">3</span>个点:</span><br><span class="line">3 -&gt; 6</span><br><span class="line">开始匹配U集合中第<span class="number">4</span>个点:</span><br><span class="line">4 -&gt; 8</span><br><span class="line">最大匹配边数:<span class="number">4</span></span><br><span class="line">match: [<span class="number">4</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>]</span><br><span class="line">prev: [<span class="number">-1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">deque deque([])</span><br><span class="line">match: [<span class="number">6</span>, <span class="number">4</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>]</span><br><span class="line">prev: [<span class="number">1</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">deque deque([])</span><br><span class="line">match: [<span class="number">6</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">-1</span>]</span><br><span class="line">prev: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">deque deque([<span class="number">1</span>])</span><br><span class="line">match: [<span class="number">6</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>]</span><br><span class="line">prev: [<span class="number">3</span>, <span class="number">2</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">deque deque([<span class="number">0</span>])</span><br><span class="line">最大匹配边数:<span class="number">4</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;图论中的基本概念&quot;&gt;&lt;a href=&quot;#图论中的基本概念&quot; class=&quot;headerlink&quot; title=&quot;图论中的基本概念&quot;&gt;&lt;/a&gt;图论中的基本概念&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;二分图:&lt;/strong&gt;&lt;br&gt;一个图中的所有顶点可划分为两个不相交的集合
      
    
    </summary>
    
    
      <category term="目标追踪" scheme="https://wyg1996.cn/categories/%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AA/"/>
    
    
      <category term="目标追踪" scheme="https://wyg1996.cn/tags/%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AA/"/>
    
  </entry>
  
  <entry>
    <title>卡尔曼滤波原理</title>
    <link href="https://wyg1996.cn/2019/05/26/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%8E%9F%E7%90%86/"/>
    <id>https://wyg1996.cn/2019/05/26/卡尔曼滤波原理/</id>
    <published>2019-05-26T08:34:16.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卡尔曼滤波简介"><a href="#卡尔曼滤波简介" class="headerlink" title="卡尔曼滤波简介"></a>卡尔曼滤波简介</h1><p>论文:A New Approach to Linear Filtering and Prediction Problems（线性滤波与预测问题的新方法），Rudolf Emil Kalman，1960。<br>论文地址:<a href="http://www.cs.unc.edu/~welch/kalman/media/pdf/Kalman1960.pdf" target="_blank" rel="noopener">http://www.cs.unc.edu/~welch/kalman/media/pdf/Kalman1960.pdf</a> 。<br>卡尔曼滤波（Kalman filter）是一种高效率的递归滤波器（自回归滤波器），它能够从一系列的不完全及包含噪声的测量中，估计动态系统的状态。比如我们可以使用第k个时刻的状态信息输入卡尔曼滤波器来预测第k+1个时刻的状态信息，同时，第k+1个时刻的实际状态信息还可以用来更新卡尔曼滤波器的参数，使其在之后时刻的预测中变得更加准确。</p><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="正态分布"><a href="#正态分布" class="headerlink" title="正态分布"></a>正态分布</h2><p>又叫高斯分布。<br>若随机变量X服从一个位置参数为μ、尺度参数为σ的概率分布，且其概率密度函数为<br>$$<br>f(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)<br>$$<br>则这个随机变量X就称为正态随机变量，正态随机变量服从的分布就称为正态分布，记作<br>$$<br>X \sim N\left(\mu, \sigma^{2}\right)<br>$$<br>称随机变量X服从正态分布。<br>当μ=0，σ=1时的正态分布是标准正态分布。一般正态分布可以通过下式转化成标准正态分布:<br>$$<br>X \sim N\left(\mu, \sigma^{2}\right), Y=\frac{X-\mu}{\sigma} \sim N(0,1)<br>$$</p><h2 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h2><p>协方差用来描述两个变量在变化时的线性相关关系，如果一个变量在变大时另一个变量也在变大，即两个变量是同向变化的，此时协方差是正的。如果一个变量在变大时另一个变量在变小，则两个变量是反向变化的，此时协方差是负的。<br>协方差公式:<br>$$<br>\operatorname{Cov}(X, Y)=E\left[\left(X-\mu_{x}\right)\left(Y-\mu_{y}\right)\right]<br>$$</p><h1 id="卡尔曼滤波公式"><a href="#卡尔曼滤波公式" class="headerlink" title="卡尔曼滤波公式"></a>卡尔曼滤波公式</h1><p><strong>卡尔曼滤波模型假设k时刻状态的真实向量xk可以用下面的公式表示：</strong><br>$$<br>x_{k}=A x_{k-1}+B u_{k}+w_{k-1}<br>$$<br>其中xk是系统在k时刻的真实状态向量，大小为nx1。A是状态转移矩阵（与xk-1即系统在k-1时刻的真实状态向量相乘），大小为nxn，矩阵A的值都是不变的常数。uk为k时刻的系统输入，大小为kx1。B是将输入转换为状态的矩阵，大小为nxk，矩阵B的值都是不变的常数。在大多数情况下，上式没有Buk项。<br>随机变量wk-1为过程噪声，假定wk-1符合均值为零，协方差矩阵为Q的多元正态分布，注意协方差矩阵Q的值也都是不变的常数。即:<br>$$<br>w_{k-1} \sim N\left(0, Q\right)<br>$$<br>上式表达的含义是，每时刻的真实向量xk都可以通过一个线性随机方程估计出来。<br><strong>在k时刻，对真实状态向量xk的观测值向量zk满足下式：</strong><br>$$<br>z_{k}=H x_{k}+v_{k}<br>$$<br>其中zk是k时刻的测量值向量，大小为mx1（注意不是nx1），H是状态向量到测量向量的转换矩阵，大小为mxn，矩阵H的值都是不变的常数。xk是k时刻的真实状态向量，大小为nx1。<br>随机变量vk是观测噪声，假定vk符合均值为零，协方差矩阵为R的多元正态分布，注意协方差矩阵R的值也都是不变的常数。即:<br>$$<br>v_{k} \sim N\left(0, R\right)<br>$$<br>上式表达的含义是，任何测量值zk都是信号值与测量噪声的线性组合。<br><strong>总结一下，A、B、H、Q、R都是值不变的矩阵或向量，一旦模型建立好后，它们在之后的迭代过程中是不会变化的。</strong><br><strong>假设初始状态以及每一时刻的噪声{x0, w1, …, wk, v1 … vk}都认为是互相独立的。</strong></p><p><strong>大多数真实世界中的动态系统并不是一个严格的线性模型，系统中存在一定的不确定性，这会导致我们估计的系统状态矩阵xk存在偏差，这个真实值和估计值之间的偏差值我们用过程噪声wk-1来表示，且近似wk-1为高斯分布。另外，观测值往往也包含噪声和干扰，或者观测矩阵H自身存在观测偏差，这个真实值和观测值之间的偏差值用测量噪声vk表示，且近似vk为高斯分布。</strong></p><p><strong>卡尔曼滤波五个方程：时间更新方程组（两个，用于预测）以及测量更新方程组（三个，用于修正）。这两个方程组在滤波器运行的每一个时刻k都会执行。在预测阶段，卡尔曼滤波器使用上一时刻k-1的状态估计值，做出对当前时刻k的状态估计值。在更新阶段，滤波器利用对时刻k的状态观测值优化在预测阶段获得k时刻的预测值，以获得一个更精确的k时刻新估计值。</strong></p><p><strong>预测（两个时间更新方程组）:</strong><br>$$<br>\hat x_{k}^{-}=A \hat x_{k-1}+B u_{k}<br>$$<br>上式左边xk是在时刻k的状态预估计值。xk-1表示k-1时刻的状态估计值。uk为k时刻的系统输入，大小为kx1。B是将输入转换为状态的矩阵，大小为nxk。在大多数情况下，上式没有Buk项。<br><strong>注意上面xk-和xk-1的含义区别：一个是k时刻的状态预估计值，一个是k-1时刻的状态估计值。</strong><br>$$<br>P_{k}^{-}=A P_{k-1} A^{T}+Q<br>$$<br>上式左边Pk是k时刻的预估计误差协方差（度量状态估计值和真实值之间的误差），Pk-1表示的是k-1时刻的估计误差协方差。wk符合均值为零，协方差矩阵为Q的多元正态分布。<br><strong>注意上面Pk-和Pk-1的含义区别：一个是k时刻的预估计误差协方差，一个是k-1时刻的估计误差协方差。</strong><br><strong>更新（三个测量更新方程组）:</strong><br>$$<br>K_{k}=P_{k}^{-} H^{T}\left(H P_{k}^{-} H^{T}+R\right)^{-1}<br>$$<br>$$<br>\hat x_{k}=\hat x_{k}^{-}+K_{k}\left(z_{k}-H \hat x_{k}^{-}\right)<br>$$<br>$$<br>P_{k}=\left(I-K_{k} H\right) P_{k}^{-}<br>$$<br>上面三个方程计算的分别是k时刻的卡尔曼增益Kk，k时刻的状态估计值xk，k时刻的估计误差协方差Pk。zk即k时刻的测量值。H是状态向量到测量向量的转换矩阵。vk符合均值为零，协方差矩阵为R的多元正态分布。I为单位矩阵。<br><strong>迭代过程:</strong><br>在时刻k时我们先计算上面预测的两个方程的值（分别称为k时刻的预估计值和k时刻的预估计误差协方差），有了这两个值就能计算k时刻的卡尔曼增益Kk，再然后得到k时刻的估计值和k时刻的估计误差协方差。这两个值在下一个时刻k+1时计算k+1时刻的预估计值和k+1时刻的预估计误差协方差时会继续用到。</p><h1 id="卡尔曼滤波公式的推导过程"><a href="#卡尔曼滤波公式的推导过程" class="headerlink" title="卡尔曼滤波公式的推导过程"></a>卡尔曼滤波公式的推导过程</h1><p><strong>假设k时刻的真实状态向量xk为:</strong><br>$$<br>x_{k}=A x_{k-1}+B u_{k}+w_{k-1}<br>$$<br>其中xk是系统在k时刻的真实状态向量，大小为nx1。A是状态转移矩阵（与xk-1即系统在k-1时刻的真实状态向量相乘），大小为nxn，矩阵A的值都是不变的常数。uk为k时刻的系统输入，大小为kx1。B是将输入转换为状态的矩阵，大小为nxk，矩阵B的值都是不变的常数。在大多数情况下，上式没有Buk项。<br>随机变量wk-1为过程噪声，假定wk-1符合均值为零，协方差矩阵为Q的多元正态分布，注意协方差矩阵Q的值也都是不变的常数。即:<br>$$<br>w_{k-1} \sim N\left(0, Q\right)<br>$$<br>上式表达的含义是，每时刻的真实向量xk都可以通过一个线性随机方程估计出来。<br><strong>在k时刻，对真实状态向量xk的观测值向量zk满足下式：</strong><br>$$<br>z_{k}=H x_{k}+v_{k}<br>$$<br>其中zk是k时刻的测量值向量，大小为mx1（注意不是nx1），H是状态向量到测量向量的转换矩阵，大小为mxn，矩阵H的值都是不变的常数。xk是k时刻的真实状态向量，大小为nx1。<br>随机变量vk是观测噪声，假定vk符合均值为零，协方差矩阵为R的多元正态分布，注意协方差矩阵R的值也都是不变的常数。即:<br>$$<br>v_{k} \sim N\left(0, R\right)<br>$$<br>上式表达的含义是，任何测量值zk都是信号值与测量噪声的线性组合。<br><strong>总结一下，A、B、H、Q、R都是值不变的矩阵或向量，一旦模型建立好后，它们在之后的迭代过程中是不会变化的。</strong><br><strong>假设初始状态以及每一时刻的噪声{x0, w1, …, wk, v1 … vk}都认为是互相独立的。</strong><br><strong>下面三个变量的含义如下:</strong><br>$$<br>x_{k}，\hat x_{k}^{-}，\hat x_{k}<br>$$<br>上面三个变量分别表示k时刻的状态真实值，k时刻的状态预估计值（先验估计值），k时刻的状态估计值（预估计值再经过调整后的估计值，又叫后验估计值）。<br><strong>又已知:</strong><br>$$<br>\hat x_{k}^{-}=A \hat x_{k-1}+B u_{k}<br>$$<br>上式即卡尔曼滤波五个公式中的预测方程组中的第一个，求k时刻的状态预估计值（先验估计值）。<br>$$<br>\hat x_{k}=\hat x_{k}^{-}+K_{k}\left(z_{k}-H \hat x_{k}^{-}\right)<br>$$<br>上式即卡尔曼滤波五个公式中的更新方程组中的第二个，求得k时刻的状态估计值（预估计值再经过调整后的估计值，又叫后验估计值）。</p><p><strong>卡尔曼增益K表示过程误差与测量误差的比重，k的取值在[0, 1] 。即：</strong><br>$$<br>K=\frac{\text{预测误差}}{\text{预测误差+测量误差}}<br>$$<br>当K=0时，即预测误差为0，系统的状态最优估计值完全取决与预测值；当K=1时，即测量误差为0，系统的状态值完全取决于测量值。K会随着迭代过程而逐步更新。<br><strong>现在我们定义四个量:</strong><br>$$<br>e_{k}^{-}=x_{k}-\hat x_{k}^{-}<br>$$<br>$$<br>e_{k}=x_{k}-\hat x_{k}<br>$$<br>$$<br>P_{k}^{-}=E\left[e_{k}^{-} \ast e_{k}^{-T}\right]<br>$$<br>$$<br>P_{k}=E\left[e_{k} \ast e_{k}^{T}\right]<br>$$<br>其中ek-称为先验状态误差（真实值与预估计值之间的误差），ek称为后验状态误差（真实值与估计值之间的误差）。Pk-为真实值与预估计值之间的协方差，Pk为真实值与估计值之间的协方差。<br><strong>由下面两式:</strong><br>$$<br>z_{k}=H x_{k}+v_{k}<br>$$<br>$$<br>\hat x_{k}=\hat x_{k}^{-}+K_{k}\left(z_{k}-H \hat x_{k}^{-}\right)<br>$$<br><strong>我们可推导出:</strong><br>$$<br>\hat x_{k}=\hat x_{k}^{-}+K_{k}\left(H x_{k}+v_{k}-H \hat x_{k}^{-}\right)<br>$$<br><strong>继续化简，得:</strong><br>$$<br>\hat x_{k}-x_{k}=\hat x_{k}^{-}-x_{k}+K_{k} H\left(x_{k}-\hat x_{k}^{-}\right)+K_{k} v_{k}<br>$$<br><strong>将ek-和ek的表达式代入上式，得:</strong><br>$$<br>e_{k}=(I-K_{k} H)  e_{k}^{-}-K_{k} v_{k}<br>$$<br><strong>Pk可化为:</strong><br>$$<br>P_{k}=E\left[e_{k} \ast e_{k}^{T}\right]=(I-K_{k} H)  P_{k}^{-} (I-K_{k} H)-K_{k} R K_{k}^{T}<br>$$<br>其中I代表单位矩阵，Rk即前面的测量噪声vk在k时刻的协方差矩阵。上面应用了转置矩阵的一个性质:<br>$$<br>(A+B)^{T}=A^{T}+B^{T}<br>$$<br><strong>Pk可继续化为:</strong><br>$$<br>P_{k}=P_{k}^{-}-K_{k} H P_{k}^{-}-P_{k}^{-} H^{T} K^{T}+K_{k}\left(H P_{k}^{-} H^{T}+R\right) K_{k}^{T}<br>$$<br><strong>卡尔曼滤波的估计原则是使真实值与估计值之间的协方差Pk最小，使估计值越来越接近真实值。因此目标函数为:</strong><br>$$<br>J=\sum_{\min } P_{k}<br>$$<br><strong>上面的Pk表达式对卡尔曼增益矩阵K求偏导，并令偏导数为0:</strong><br>$$<br>\frac{\partial P_{k}}{\partial K_{k}}=-2\left(H P_{k}^{-}\right)^{T}+2 K_{k}\left(H P_{k}^{-} H^{T}+R\right)=0<br>$$<br><strong>则当Pk取极小值时卡尔曼增益矩阵K的计算公式如下:</strong><br>$$<br>K_{k}=P_{k}^{-} H^{T}\left(H P_{k}^{-} H^{T}+R\right)^{-1}<br>$$<br><strong>又已知:</strong><br>$$<br>\hat x_{k}-x_{k}=\hat x_{k}^{-}-x_{k}+K_{k} H\left(x_{k}-\hat x_{k}^{-}\right)+K v_{k}<br>$$<br>$$<br>P_{k}=P_{k}^{-}-K_{k} H P_{k}^{-}-P_{k}^{-} H^{T} K_{k}^{T}+K_{k}\left(H P_{k}^{-} H^{T}+R\right) K_{k}^{T}<br>$$<br><strong>推导出真实值与估计值之间的协方差Pk的计算公式如下:</strong><br>$$<br>P_{k}=(I-K_{k} H) P_{k}^{-}<br>$$<br><strong>再由ek-的表达式:</strong><br>$$<br>e_{k}^{-}=x_{k}-\hat x_{k}^{-}<br>$$<br><strong>则ek+1-可化为:</strong><br>$$<br>e_{k+1}^{-}=x_{k+1}-\hat x_{k+1}^{-}=\left(A x_{k}+B u_{k}+w_{k}\right)-\left(A \hat x_{k}+B u_{k}\right)<br>$$<br>$$<br>e_{k+1}^{-}=A\left(x_{k}-\hat x_{k}\right)+w_{k}=A e_{k}+w_{k}<br>$$<br><strong>又已知:</strong><br>$$<br>P_{k}^{-}=E\left[e_{k}^{-} \ast e_{k}^{-T}\right]<br>$$<br>我们来求k时刻的真实值与预测值之间的协方差PK-，上式可化为:<br>$$<br>P_{k+1}^{-}=E\left[e_{k+1}^{-} \ast e_{k+1}^{-} T\right]=E\left[\left(A e_{k}+w_{k}\right)\left(A e_{k}+w_{k}\right)^{T}\right]<br>$$<br>$$<br>P_{k+1}^{-}=E\left[\left(A e_{k}\right)\left(A e_{k}\right)^{T}\right]+E\left[w_{k}\left(w_{k}\right)^{T}\right]<br>$$<br>则k+1时刻的真实值与预测值之间的协方差Pk+1-为:<br>$$<br>P_{k+1}^{-}=A P_{k} A^{T}+Q<br>$$<br>推导完毕。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;卡尔曼滤波简介&quot;&gt;&lt;a href=&quot;#卡尔曼滤波简介&quot; class=&quot;headerlink&quot; title=&quot;卡尔曼滤波简介&quot;&gt;&lt;/a&gt;卡尔曼滤波简介&lt;/h1&gt;&lt;p&gt;论文:A New Approach to Linear Filtering and Predicti
      
    
    </summary>
    
    
      <category term="目标追踪" scheme="https://wyg1996.cn/categories/%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AA/"/>
    
    
      <category term="目标追踪" scheme="https://wyg1996.cn/tags/%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AA/"/>
    
  </entry>
  
  <entry>
    <title>GoogLeNet和Inception v1、v2、v3、v4网络介绍</title>
    <link href="https://wyg1996.cn/2019/05/16/GoogLeNet%E5%92%8CInception-v1%E3%80%81v2%E3%80%81v3%E3%80%81v4%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D/"/>
    <id>https://wyg1996.cn/2019/05/16/GoogLeNet和Inception-v1、v2、v3、v4网络介绍/</id>
    <published>2019-05-16T14:11:04.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CNN神经网络的演化过程"><a href="#CNN神经网络的演化过程" class="headerlink" title="CNN神经网络的演化过程"></a>CNN神经网络的演化过程</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Hubel&amp;Wiesel</span><br><span class="line">     |</span><br><span class="line">Neocognitron</span><br><span class="line">     |</span><br><span class="line"> LeCun1989</span><br><span class="line">     |</span><br><span class="line">   LeNet</span><br><span class="line">     |增加dropout、relu</span><br><span class="line">  AlexNet</span><br><span class="line">     |多种演化方向</span><br><span class="line">网络加深     增强卷积模块                     目标检测/实例分割             增加新功能单元</span><br><span class="line">   |            |                         /              \                  |     </span><br><span class="line">VGG16          NN                      RCNN           Yolo/SSD     Inception V2（增加BN）</span><br><span class="line">   |            |                        |                |                 |</span><br><span class="line">VGG19       GoogLeNet                fast-RCNN         Yolov2          FCN/FCN+CRF</span><br><span class="line">   |            |                        |                |                 |</span><br><span class="line">MSRANet   Inception V3/V4           faster-RCNN        Yolov3             STNet</span><br><span class="line">   \            /                        |                                  |</span><br><span class="line">    前两条路线合并                      mask-RCNN                        CNN+RNN/LSTM</span><br><span class="line">         |</span><br><span class="line">       ResNet</span><br><span class="line">         |</span><br><span class="line">  Inception ResNet</span><br></pre></td></tr></table></figure><p>在GoogLeNet出现之前，对神经网络的修改往往是单纯增加层数和宽度，但是这样导致网络的参数变得非常多，容易出现梯度消失问题，也更加难以训练。</p><h1 id="GoogLeNet原始版本"><a href="#GoogLeNet原始版本" class="headerlink" title="GoogLeNet原始版本"></a>GoogLeNet原始版本</h1><p>GoogLeNet相比于之前的卷积神经网络的最大改进是设计了一个稀疏参数的网络结构，但是能够产生稠密的数据，既能增加神经网络表现，又能保证计算资源的使用效率。<br><strong>具体来说，就是将CNN中常用的卷积（1x1，3x3，5x5）、池化操作（3x3）堆叠在一起（卷积、池化后的尺寸相同，将通道相加），一方面增加了网络的宽度，另一方面也增加了网络对尺度的适应性。</strong><br><strong>GoogLeNet结构如下:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">                        前一层</span><br><span class="line">    /             /                   \                  \</span><br><span class="line">1x1 conv      3x3 conv             5x5 conv        3x3 max pooling</span><br><span class="line">    \             \                   /                  /</span><br><span class="line">                       全连接层</span><br></pre></td></tr></table></figure><p><strong>稀疏参数的网络结构特点:</strong><br>使用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合；<br>之所以卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征图，然后这些特征图就可以直接拼接在一起；<br>3x3的max pooling对提取特征效果也不错，所以也增加pooling结构；<br>越是深处的网络层，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。</p><p>由于5x5的卷积核计算量仍然很大，造成特征图的通道数很多，因此又进行了一些改进。</p><h1 id="GoogLeNet-Inception-V1"><a href="#GoogLeNet-Inception-V1" class="headerlink" title="GoogLeNet Inception V1"></a>GoogLeNet Inception V1</h1><p>论文:Going deeper with convolutions<br>论文地址:<a href="https://arxiv.org/pdf/1409.4842.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1409.4842.pdf</a> 。<br>Inception V1在GoogLeNet基础之上，为了减少5x5卷积的计算量，在3x3conv前、5x5conv前、3x3max pooling后分别加上1x1的卷积核，起到减少总的网络参数数量的作用。<br><strong>Inception V1结构如下:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                        前一层</span><br><span class="line">    /             /                   \                  \</span><br><span class="line">1x1 conv      1x1 conv             1x1 conv        3x3 max pooling</span><br><span class="line">   |             |                     |                  |</span><br><span class="line">   |          3x3 conv             5x5 conv            1x1 conv </span><br><span class="line">    \             \                   /                  /</span><br><span class="line">                      特征图拼接</span><br></pre></td></tr></table></figure><p>假如前一层的输出为100x100x128，经过具有256个输出的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256。其中，卷积层的参数为128x5x5x256。假如上一层输出先经过具有32个输出的1x1卷积层（1x1卷积降低了通道数，且特征图尺寸不变），再经过具有256个输出的5x5卷积层，最终的输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256，参数数量减少为原来的约4分之一。<br><strong>1x1卷积核的作用:</strong><br>1x1卷积核的最大作用是降低输入特征图的通道数。假设输入为6x6x128的特征图，1x1卷积核为1x1x32（32个通道），则输出为6x6x32。即当1x1卷积核的个数小于输入特征图的通道数时，起到降维的作用。<br><strong>Inception V1相比GoogLeNet原始版本进行了如下改进:</strong></p><ul><li>为了减少5x5卷积的计算量，在3x3conv前、5x5conv前、3x3max pooling后分别加上1x1的卷积核，减少了总的网络参数数量；</li><li>网络最后层采用平均池化（average pooling）代替全连接层，该想法来自NIN（Network in Network），事实证明这样可以将准确率提高0.6%。但是，实际在最后还是加了一个全连接层，主要是为了方便对输出进行灵活调整；</li><li>网络中仍然使用Dropout ; </li><li>为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度（辅助分类器）。辅助分类器是将中间某一层的输出用作分类，并按一个较小的权重（0.3）加到最终分类结果中，这样相当于做了模型融合，同时给网络增加了反向传播的梯度信号，也提供了额外的正则化，对于整个网络的训练很有裨益。在实际测试时，这两个额外的softmax会被去掉。</li></ul><p><strong>使用Inception V1结构改进的GoogLeNet网络结构:</strong></p><ul><li>输入:原始输入图像为224x224x3，且都进行了零均值化的预处理操作（图像每个像素减去均值）。</li><li>第一层（卷积层）:使用7x7的卷积核（滑动步长2，padding为3），64通道，输出为112x112x64，卷积后进行ReLU操作，经过3x3的max pooling（步长为2），输出为((112 - 3+1)/2)+1=56，即56x56x64，再进行ReLU操作。</li><li>第二层（卷积层）:使用3x3的卷积核（滑动步长为1，padding为1），192通道，输出为56x56x192，卷积后进行ReLU操作，经过3x3的max pooling（步长为2），输出为((56 - 3+1)/2)+1=28，即28x28x192，再进行ReLU操作</li><li>第三层（Inception 3a层）:分为四个分支，采用不同尺度的卷积核来进行处理。<br>64个1x1的卷积核，然后RuLU，输出28x28x64；<br>96个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x96，然后进行ReLU计算，再进行128个3x3的卷积（padding为1），输出28x28x128；<br>16个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x16，进行ReLU计算后，再进行32个5x5的卷积（padding为2），输出28x28x32；<br>pool层，使用3x3的核（padding为1），输出28x28x192，然后进行32个1x1的卷积，输出28x28x32；<br>将四个结果进行连接，对这四部分输出结果的第三维并联，即64+128+32+32=256，最终输出28x28x256。</li><li>第三层（Inception 3b层）<br>128个1x1的卷积核，然后RuLU，输出28x28x128；<br>128个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x128，进行ReLU，再进行192个3x3的卷积（padding为1），输出28x28x192；<br>32个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x32，进行ReLU计算后，再进行96个5x5的卷积（padding为2），输出28x28x96；<br>pool层，使用3x3的核（padding为1），输出28x28x256，然后进行64个1x1的卷积，输出28x28x64；<br>将四个结果进行连接，对这四部分输出结果的第三维并联，即128+192+96+64=480，最终输出输出为28x28x480。</li><li>第四层（4a,4b,4c,4d,4e）、第五层（5a,5b）……，与3a、3b类似，在此就不再重复叙述。<h1 id="GoogLeNet-Inception-V2"><a href="#GoogLeNet-Inception-V2" class="headerlink" title="GoogLeNet Inception V2"></a>GoogLeNet Inception V2</h1>论文:Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift<br>论文地址:<a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1502.03167.pdf</a> 。</li><li><em>Inception V2结构如下:*</em><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                        前一层</span><br><span class="line">    /             /                   \                  \</span><br><span class="line">1x1 conv      1x1 conv               pool              1x1 conv </span><br><span class="line">   |             |                     |                  |</span><br><span class="line">3x3 conv      3x3 conv             1x1 conv               |</span><br><span class="line">   |             |                     |                  | </span><br><span class="line">3x3 conv         |                     |                  |</span><br><span class="line">    \             \                   /                  /</span><br><span class="line">                      特征图拼接</span><br></pre></td></tr></table></figure></li></ul><p><strong>Inception V2相比Inception V1进行了如下改进:</strong><br>使用Batch Normalization，加快模型训练速度；<br>使用两个3x3的卷积代替5x5的大卷积，降低了参数数量并减轻了过拟合；<br>增大学习速率并加快学习衰减速度以适用BN规范化后的数据；<br>去除Dropout并减轻L2正则化（因BN已起到正则化的作用）；<br>更彻底地对训练样本进行打乱；<br>减少数据增强过程中对数据的光学畸变（因为BN训练更快，每个样本被训练的次数更少，因此更真实的样本对训练更有帮助）。</p><h1 id="GoogLeNet-Inception-V3"><a href="#GoogLeNet-Inception-V3" class="headerlink" title="GoogLeNet Inception V3"></a>GoogLeNet Inception V3</h1><p>论文:Rethinking the Inception Architecture for Computer Vision<br>论文地址:<a href="https://arxiv.org/pdf/1512.00567.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1512.00567.pdf</a> 。<br>Inception V3一个最重要的改进是卷积分解（Factorization），将7x7卷积分解成两个一维的卷积串联（1x7和7x1），3x3卷积分解为两个一维的卷积串联（1x3和3x1），这样既可以加速计算，又可使网络深度进一步增加，增加了网络的非线性（每增加一层都要进行ReLU）。<br>另外，网络输入从224x224变为了299x299。</p><h1 id="GoogLeNet-Inception-V4"><a href="#GoogLeNet-Inception-V4" class="headerlink" title="GoogLeNet Inception V4"></a>GoogLeNet Inception V4</h1><p>论文:Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning<br>论文地址:<a href="https://arxiv.org/pdf/1602.07261.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1602.07261.pdf</a> 。<br>inception v4把原来的inception结构中加入了ResNet中的Residual Blocks结构，把一些层的输出加上前几层的输出，这样中间这几层学习的实际上是残差。<br>另外就是V4把一个先1x1卷积再3x3卷积换成了先3x3卷积再1x1卷积。<br>论文说引入ResNet中的Residual Blocks结构不是用来提高准确度，只是用来提高模型训练收敛速度。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CNN神经网络的演化过程&quot;&gt;&lt;a href=&quot;#CNN神经网络的演化过程&quot; class=&quot;headerlink&quot; title=&quot;CNN神经网络的演化过程&quot;&gt;&lt;/a&gt;CNN神经网络的演化过程&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="深度学习原理推导" scheme="https://wyg1996.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86%E6%8E%A8%E5%AF%BC/"/>
    
    
      <category term="深度学习原理推导" scheme="https://wyg1996.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86%E6%8E%A8%E5%AF%BC/"/>
    
  </entry>
  
  <entry>
    <title>人脸识别网络facenet原理</title>
    <link href="https://wyg1996.cn/2019/05/15/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9Cfacenet%E5%8E%9F%E7%90%86/"/>
    <id>https://wyg1996.cn/2019/05/15/人脸识别网络facenet原理/</id>
    <published>2019-05-15T15:20:21.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="人脸相关任务介绍"><a href="#人脸相关任务介绍" class="headerlink" title="人脸相关任务介绍"></a>人脸相关任务介绍</h1><p><strong>人脸相关任务其实分为两部分:</strong><br>人脸检测和人脸识别。<br><strong>人脸检测:</strong><br>人脸检测就是获取图像中所有人脸的位置，并对人脸进行对齐。由于原始图像中的人脸可能存在姿态、位置上的差异，我们需要在获取人脸位置后，检测人脸中的关键点，根据这些关键点将人脸统一校准，以消除姿势不同带来的误差。这方面代表性的算法是MTCNN算法。<br><strong>人脸识别:</strong><br>输入一张人脸，判断其属于人脸数据集中的哪一个人。这方面的代表算法是facenet。具体来说，就是使用深度卷积网络，将输入的人脸图像转换为一个向量，然后与数据集中各个人脸的向量计算两个向量之间的欧氏距离，对于同一个人的人脸图像，对应的两个向量之间的欧氏距离应该比较小，反之则较大。</p><h1 id="facenet网络结构"><a href="#facenet网络结构" class="headerlink" title="facenet网络结构"></a>facenet网络结构</h1><p><strong>facenet的网络结构:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NN1/NN2/NN3/NN4/NNS1/NNS2（不同的卷积神经网络）-&gt;L2归一化-&gt;嵌入层（Embedding）-&gt;计算三元组损失（Triplet Loss）和各参数梯度，更新权重</span><br></pre></td></tr></table></figure><p>所谓嵌入层（Embedding），可以理解为是一种映射关系，即将特征从原来的特征空间中映射到一个新的特征空间，新的特征就可以称为原来特征的一种嵌入。<br>这里的映射关系是将卷积神经网络末端全连接层输出的特征映射到一个超球面上，也就是使其特征的L2范数归一化，然后再计算三元组损失和各参数梯度，更新权重。<br><strong>各个神经网络的全称和使用该网络作为facenet的卷积神经网络时最终在验证集上的准确率:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NN1 (Zeiler&amp;Fergus 220×220)     87.9% ± 1.9</span><br><span class="line">NN2 (Inception 224×224)         89.4% ± 1.6</span><br><span class="line">NN3 (Inception 160×160)         88.3% ± 1.7</span><br><span class="line">NN4 (Inception 96×96)           82.0% ± 2.3</span><br><span class="line">NNS1 (mini Inception 165×165)   82.4% ± 2.4</span><br><span class="line">NNS2 (tiny Inception 140×116)   51.9% ± 2.9</span><br></pre></td></tr></table></figure><h1 id="嵌入层（Embedding）原理"><a href="#嵌入层（Embedding）原理" class="headerlink" title="嵌入层（Embedding）原理"></a>嵌入层（Embedding）原理</h1><p>Embedding产生的原因主要是因为使用one-hot编码时产生的向量维度很高且非常稀疏。比如我们在做自然语言处理（NLP）中遇到了一个包含2000个词的字典，使用one-hot编码时，每一个词需要用一个2000维的向量来表示，且其中1999维为0。<br>Embedding的主要目的就是对稀疏特征进行降维。看下面这个例子:<br>$$<br>\left[ \begin{array}{cccccc}{1} &amp; {0} &amp; {0} &amp; {0} &amp; {0} &amp; {0} \\ {0} &amp; {1} &amp; {0} &amp; {0} &amp; {0} &amp; {0}\end{array}\right] \left[ \begin{array}{ccc}{w_{11}} &amp; {w_{12}} &amp; {w_{13}} \\ {w_{21}} &amp; {w_{22}} &amp; {w_{23}} \\ {w_{31}} &amp; {w_{32}} &amp; {w_{33}} \\ {w_{41}} &amp; {w_{42}} &amp; {w_{43}} \\ {w_{51}} &amp; {w_{52}} &amp; {w_{53}} \\ {w_{61}} &amp; {w_{62}} &amp; {w_{63}}\end{array}\right]=\left[ \begin{array}{lll}{w_{11}} &amp; {w_{12}} &amp; {w_{13}} \\ {w_{21}} &amp; {w_{22}} &amp; {w_{23}}\end{array}\right]<br>$$<br>左边第一个矩阵是one_hot编码2x6矩阵，将其输入节点数为3的全连接层，就可以得到右边降维后的输出矩阵。原本的6维的one_hot编码向量经过Embedding层被降为3维向量。<br><strong>事实上，Embedding层就是以one hot为输入、中间层节点为字向量维数的全连接层，这个全连接层的参数，就是一个”字向量表”。全连接层的节点数被称为”潜在因子”。</strong><br>由于在深度神经网络的训练过程中这个全连接层权重也会被更新，如果输入为一个词语集合的one_hot编码，我们就可以对齐进行有效的降维，同时降维后的两两嵌入向量各个维度上的取值之间的差值（距离）还表示这两个嵌入向量代表的词在高维空间上的相似度有多少，我们可以类似使用t-SNE这样的降维技术将这些相似性可视化。</p><h1 id="直接使用欧氏距离作为损失函数的缺陷"><a href="#直接使用欧氏距离作为损失函数的缺陷" class="headerlink" title="直接使用欧氏距离作为损失函数的缺陷"></a>直接使用欧氏距离作为损失函数的缺陷</h1><p>如果我们直接以欧氏距离作为损失函数，模型的训练会出现这样的问题：对于人脸来说，每一类就是一个人，然而每一类中会有很多个样本（一个人有很多照片），直接用欧氏距离相当于只考虑了类内距离，未考虑类间距离，但实际上有时候类内距离会比类间距离大。<br>比如我们可以对MNIST数据集（0-9十个数字的图片）进行降维，使得每张图片最后降维2维，这样每一张图片都是直角坐标系上的一个点，我们可以将所有样本点画在一张图上。我们希望的是类内距离尽可能近，而类间距离尽可能远，但在图上我们会发现，类内中两端样本点之间的距离比图中心不同类之间样本点之间的距离更大。</p><h1 id="三元组损失（Triplet-Loss）"><a href="#三元组损失（Triplet-Loss）" class="headerlink" title="三元组损失（Triplet Loss）"></a>三元组损失（Triplet Loss）</h1><p>实际上三元组损失在facenet之前已经有人提出了，但这里我们以facenet中的三元组损失函数来解释。<br>论文:FaceNet: A Unified Embedding for Face Recognition and Clustering<br>论文地址:<a href="https://arxiv.org/pdf/1503.03832.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1503.03832.pdf</a> 。<br>为了解决上面直接用欧氏距离作为损失函数的缺陷，facenet中使用了三元组损失函数。每次在训练数据中抽出三张人脸图像，第一张图像标记为xai，第二张图像标记为xpi，第三张图像标记为xni。xai和xpi对应的是同一个人的图像，而xni是另外一个人的人脸图像。<br><strong>我们用更加正式的名称来称呼上面三张图像。一个输入的三元组包括一对正样本对和一对负样本对。三张图片分别命名为固定图片（Anchor，a）、正样本图片（Positive，b）和负样本图片（Negative，n）。图片a和图片p为一对正样本对，图片a和图片n为一对负样本对。</strong><br>三元组损失要求满足以下不等式:<br>$$<br>||f(x_{i}^{a})-f(x_{i}^{p})||^{2}+\alpha&lt;||f(x_{i}^{a})-f(x_{i}^{n})||^{2}<br>$$<br><strong>即相同人脸间的距离平方至少要比不同人脸间的距离平方小α（取平方主要是为了方便求导）。</strong><br><strong>三元组损失函数为:</strong><br>$$<br>L_{i}=\left[||f(x_{i}^{a})-f(x_{i}^{p})||^{2}+\alpha-||f(x_{i}^{a})-f(x_{i}^{n})||^{2}\right]<br>$$<br><strong>使用三元组损失函数训练人脸模型的过程:</strong><br>最小化三元组损失函数实际上就是最小化同类样本的距离，同时最大化非同类样本的距离。但是我们在学习模型时最小化上面的损失函数时有一定的技巧。如果对于上面的损失函数每次都是随机选择三元组，虽然模型可以正确的收敛，但是并不能达到最好的性能，而且往往要训练很久，这会是一个很大的工作量。因此在实现时，我们在正样本图片（Positive，b）中选择一个最不像正样本的样本（具体来说就是与固定图片a相距最远的相同脸样本），在负样本图片（Negative，n）中选择一个最像正样本的样本（即与固定图片a相距最近的非相同脸样本，最容易被混淆），这样计算出的损失距离就是最大的距离，优化这样的损失函数即可，当采用这种方式算出来的值都能达到要求时，其他样本也能达到要求。<br>采用上述方法选择三元组时也存在一个弊端，即在选取最近和最远的元素时也需要遍历所有的样本，遍历所有的样本也有很大的工作量。对此，可以采用分批查找的方式。因为图片的执行是分批的，我们可以在每批图片处理的时候找出对应的符合条件的正样本图片（Positive，b）和负样本图片（Negative，n）的样本。为了保证该方法选出的数据合理。在生成对应的批图片时保证每个人平均有40张图片并且随机加入反例进去。同时在选取负样本图片（Negative，n）时遵循半难（semi-hard）约束条件:<br>$$<br>||f(x_{i}^{a})+f(x_{i}^{p})||^{2}&lt;||f(x_{i}^{a})-f(x_{i}^{n})||^{2}<br>$$<br><strong>使用三元组损失训练人脸模型通常需要非常大的人脸数据集，才能取得较好的效果。另外模型的收敛速度也较慢。</strong></p><h1 id="中心损失（Center-Loss）"><a href="#中心损失（Center-Loss）" class="headerlink" title="中心损失（Center Loss）"></a>中心损失（Center Loss）</h1><p>我们还可以使用中心损失+softmax交叉熵损失作为总损失函数训练facenet模型，可以明显加快模型收敛速度。<br>论文:CenterLoss - A Discriminative Feature Learning Approach for Deep Face Recognition<br>论文地址:<a href="http://www.eccv2016.org/files/posters/P-3B-20.pdf" target="_blank" rel="noopener">http://www.eccv2016.org/files/posters/P-3B-20.pdf</a> 。（这篇论文原文要收费才可浏览，我们看看这个ppt中的摘要吧）<br>中心损失不直接对距离进行优化，它保留了原有的分类模型，但又为每个类（在人脸模型中，一个类就对应一个人)指定了一个类别中心。同一类图像对应的特征都应该尽量靠近自己的类别中心，不同类的类别中心尽量远离。中心损失可以让训练处的特征具有”内聚性”。<br>与三元组损失函数相比，使用中心损失训练人脸模型不需要使用特别的采样方法，而且利用较少的图像就可以达到与单元组损失相似的效果。<br>设输入的人脸图像为xi，该人脸对应的类别是yi，对每个类别都规定一个类别中心，记作cyi。希望每个人脸图像对应的特征f（xi）都尽可能接近中心cyi。<br><strong>中心损失函数为:</strong><br>$$<br>L_{\text {center}}=\frac{1}{2} \sum_{i} (||f\left(x_{i}\right)-c_{y i}||^{2})<br>$$<br><strong>如何确定每个类别的中心cyi呢？</strong><br>类别yi的最佳中心应该是它对应所有图片的特征的平均值。但每次梯度下降时对所有图片计算cyi的时间代价太高了。我们使用一种近似方法，在初始阶段，先随机确定cyi，接着在每个batch内，对当前batch内的cyi也计算梯度，并使得该梯度更新cyi，此外，还需要加入softmax损失。<br><strong>总损失函数L最后由两部分组成:</strong><br>$$<br>L=L_{s o f t m a x}+\lambda L_{c e n t e r}<br>$$<br>$$<br>L=-\sum_{i=1}^{m} \log \left(\frac{e^{W_{y_{i}}^{T} x_{i}+b_{y_{i}}}}{\sum_{j=1}^{n} e^{W_{j}^{T} x_{i}+b_{j}}}\right)+\frac{\lambda}{2} \sum_{i=1}^{m} ||x_{i}-c_{y_{i}}||^{2}<br>$$<br>其中λ是一个超参数。当权重λ越大时，生成的特征就会具有越明显的”内聚性”（每个类的样本分类后会单独聚集在一团，中心cyi在这一团的中心）。<br>softmax交叉熵损失使类间距离变大，中心损失是计算某一图片与该类别图片embeddings的均值的损失，为了使类间距离变小。<br><strong>使用中心损失训练人脸模型的过程:</strong><br>随机初始化各个中心cyi；不断地取出一个batch进行训练，在每个batch中，使用总的损失函数L，除了对神经网络参数计算梯度更新外，也对cyi进行计算梯度，并更新中心的位置。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;人脸相关任务介绍&quot;&gt;&lt;a href=&quot;#人脸相关任务介绍&quot; class=&quot;headerlink&quot; title=&quot;人脸相关任务介绍&quot;&gt;&lt;/a&gt;人脸相关任务介绍&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;人脸相关任务其实分为两部分:&lt;/strong&gt;&lt;br&gt;人脸检测和人脸识别。&lt;
      
    
    </summary>
    
    
      <category term="人脸检测与识别" scheme="https://wyg1996.cn/categories/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="人脸检测与识别" scheme="https://wyg1996.cn/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>CUDA矩阵计算原理和方法</title>
    <link href="https://wyg1996.cn/2019/05/15/CUDA%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97%E5%8E%9F%E7%90%86%E5%92%8C%E6%96%B9%E6%B3%95/"/>
    <id>https://wyg1996.cn/2019/05/15/CUDA矩阵计算原理和方法/</id>
    <published>2019-05-15T03:13:53.000Z</published>
    <updated>2019-07-22T11:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="主机（host）"><a href="#主机（host）" class="headerlink" title="主机（host）"></a>主机（host）</h2><p>将CPU及系统的内存（内存条）称为主机。</p><h2 id="设备（device）"><a href="#设备（device）" class="headerlink" title="设备（device）"></a>设备（device）</h2><p>将GPU及GPU本身的显示内存称为设备。</p><h2 id="流式处理器（SP）"><a href="#流式处理器（SP）" class="headerlink" title="流式处理器（SP）"></a>流式处理器（SP）</h2><p>流处理器SP（streaming processor,也叫CUDA core）是最基本的处理单元，最后具体的指令和任务都是在SP上处理的。GPU进行并行计算，也就是很多个SP同时做处理。</p><h2 id="流式多处理器（SM）"><a href="#流式多处理器（SM）" class="headerlink" title="流式多处理器（SM）"></a>流式多处理器（SM）</h2><p>多个SP加上其他的一些资源（warp，scheduler，register，shared memory等）组成一个SM（streaming multiprocessor）。也叫GPU大核。SM可以看做GPU的心脏（对比CPU核心），register和sharedmemory是SM的稀缺资源。CUDA将这些资源分配给所有驻留在SM中的threads。因此，这些有限的资源就使每个SM中active warps有非常严格的限制，也就限制了并行能力。<br>每个SM包含的SP数量依据GPU架构而不同，Fermi架构GF100是32个，GF10X是48个，Kepler架构都是192个，Maxwell都是128个。相同架构的GPU包含的SM数量则根据GPU的中高低端来定。在Maxwell架构中，Nvidia已经把SM改叫SMM。在软件逻辑上是所有SP是并行的，但是物理上并不是所有SP都能同时执行计算，因为有些会处于挂起，就绪等其他状态，这与GPU的线程调度有关。<br>GPU中每个sm都设计成支持数以百计的线程并行执行，并且每个GPU都包含了很多的SM，所以GPU支持成百上千的线程并行执行。当一个kernel启动后，thread会被分配到这些SM中执行。大量的thread可能会被分配到不同的SM，同一个block中的threads必然在同一个SM中并行（SIMT）执行。每个thread拥有它自己的程序计数器和状态寄存器，并且用该线程自己的数据执行指令，这就是所谓的Single Instruction Multiple Thread。<br>一个SP可以执行一个thread，但是实际上并不是所有的thread能够在同一时刻执行。Nvidia把32个threads组成一个warp，warp是调度和运行的基本单元。warp中所有threads并行的执行相同的指令。一个warp需要占用一个SM运行，多个warps需要轮流进入SM。由SM的硬件warp scheduler负责调度。目前每个warp包含32个threads（Nvidia保留修改数量的权利）。所以，一个GPU上resident thread最多只有SMxwarp个。 </p><h2 id="线程（Thread）"><a href="#线程（Thread）" class="headerlink" title="线程（Thread）"></a>线程（Thread）</h2><p>一般通过GPU的一个核进行处理。</p><h2 id="线程块（Block）"><a href="#线程块（Block）" class="headerlink" title="线程块（Block）"></a>线程块（Block）</h2><p>由多个线程组成（可以表示成一维，二维，三维）；<br>各block是并行执行的，block间无法通信，也没有执行顺序；<br>线程块的数量限制为不超过65535（硬件限制）。</p><h2 id="线程格（Grid）"><a href="#线程格（Grid）" class="headerlink" title="线程格（Grid）"></a>线程格（Grid）</h2><p>由多个线程块组成（可以表示成一维，二维，三维）。</p><h2 id="线程束（wrap）"><a href="#线程束（wrap）" class="headerlink" title="线程束（wrap）"></a>线程束（wrap）</h2><p>在CUDA架构中，线程束是指一个包含32个线程的集合，这个线程集合被“编织在一起”并且“步调一致”的形式执行。在程序中的每一行，线程束中的每个线程都将在不同数据上执行相同的命令。</p><h2 id="函数修饰符"><a href="#函数修饰符" class="headerlink" title="函数修饰符"></a>函数修饰符</h2><p><strong>在CUDA中，通过函数类型修饰符区分host和device上的函数:</strong><br>__global__：在device上执行，从host中调用（一些特定的GPU也可以从device上调用），返回类型必须是void，不支持可变参数参数，不能成为类成员函数。注意用__global__定义的kernel是异步的，这意味着host不会等待kernel执行完就执行下一步。<br>__device__：在device上执行，单仅可以从device中调用，不可以和__global__同时用。<br>__host__：在host上执行，仅可以从host上调用，一般省略不写，不可以和__global__同时用，但可和__device__，此时函数会在device和host都编译。</p><h1 id="GPU内存的分类"><a href="#GPU内存的分类" class="headerlink" title="GPU内存的分类"></a>GPU内存的分类</h1><h2 id="全局内存（Global-Memory）"><a href="#全局内存（Global-Memory）" class="headerlink" title="全局内存（Global Memory）"></a>全局内存（Global Memory）</h2><p>通俗意义上的设备内存。</p><h2 id="共享内存（Shared-Memory）"><a href="#共享内存（Shared-Memory）" class="headerlink" title="共享内存（Shared Memory）"></a>共享内存（Shared Memory）</h2><p>在设备内存上，以关键字__shared__添加到变量声明中。如__shared__ float cache[10]。对于GPU上启动的每个线程块，CUDA C编译器都将创建该共享变量的一个副本。线程块中的每个线程都共享这块内存，但线程却无法看到也不能修改其他线程块的变量副本。这样使得一个线程块中的多个线程能够在计算上通信和协作。</p><h2 id="常量内存（Constant-Memory）"><a href="#常量内存（Constant-Memory）" class="headerlink" title="常量内存（Constant Memory）"></a>常量内存（Constant Memory）</h2><p>在设备内存上，以关键字__constant__添加到变量声明中。如__constant__ float s[10];。常量内存定义的变量用于保存在核函数执行期间不会发生变化的数据。变量的访问限制为只读。NVIDIA硬件提供了64KB的常量内存。不再需要cudaMalloc()或者cudaFree(),而是在编译时，静态地分配空间。<br>常量内存其实只是全局内存的一种虚拟地址形式，并没有特殊保留的常量内存块。常量内存有两个特性，一个是高速缓存，另一个是它支持将单个值广播到线程束中的每个线程。当常量内存将数据分配或广播到线程束中的每个线程时（注意，实际上硬件会将单次内存读取操作广播到半个线程束），广播能够在单个周期内发生。当所有16个线程都读取相同地址时，这个功能可以极大提高性能，但当所有16个线程分别读取不同的地址时，它实际上会降低性能。如果半个线程束中的所有16个线程需要访问常量内存中的不同数据，那么这个16次不同的读取操作会被串行化，从而需要16倍的时间来发出请求。但如果从全局内存中读取，那么这些请求就会同时发出。这种情况下，从常量内存读取就会慢于从全局内存中读取。<br><strong>注意:</strong><br>当我们需要拷贝数据到常量内存中应该使用cudaMemcpyToSymbol()，而cudaMemcpy()会复制到全局内存。</p><h2 id="纹理内存（Texture-Memory）"><a href="#纹理内存（Texture-Memory）" class="headerlink" title="纹理内存（Texture Memory）"></a>纹理内存（Texture Memory）</h2><p>纹理内存是另一种类型的只读内存，在特定的访问模式中（以下例子并非这种特定的访问模式），纹理内存同样能够提升性能。纹理内存缓存在芯片上，因此在某些情况中，它能够减少对内存的请求并提供更高效的内存带宽。纹理缓存是专门为那些在内存访问模式中存在大量空间局部性(Spatial Locality)的图形应用程序而设计的。在某个计算应用程序中，这意味着一个线程读取的位置可能与邻近线程的读取位置“非常接近”。举个例子，一个2x2矩阵的四个元素在地址上不是连续的，但是在空间位置上是互相相邻的，纹理缓存就是专门为了加速这种访问模式而设计的。如果在这种情况中使用纹理内存而不是全局内存，那么将会获得性能的提升。<br>纹理变量（引用）必须声明为文件作用域内的全局变量，其形式分为一维纹理内存和二维纹理内存。<br><strong>一维纹理内存:</strong><br>用texture&lt;类型&gt;类型声明，如texture<float> texIn。通过cudaBindTexture()绑定到纹理内存中，通过tex1Dfetch()来读取纹理内存中的数据，通过cudaUnbindTexture()取消绑定纹理内存。<br><strong>二维纹理内存</strong><br>用texture&lt;类型,数字&gt;类型声明，如texture&lt;float，2&gt; texIn。通过cudaBindTexture2D()绑定到纹理内存中，通过tex2D()来读取纹理内存中的数据，通过cudaUnbindTexture()取消绑定纹理内存。</float></p><h2 id="固定内存"><a href="#固定内存" class="headerlink" title="固定内存"></a>固定内存</h2><p>在主机内存上，也称为页锁定内存或者不可分页内存，操作系统将不会对这块内存分页并交换到磁盘上，从而确保了该内存始终驻留在物理内存中。因此操作系统能够安全地使某个应用程序访问该内存的物理地址，因为这块内存将不会破坏或者重新定位。<br><strong>优点:</strong><br>固定内存可以提高访问速度。由于GPU知道主机内存的物理地址，因此可以通过DMA（直接内存访问，Direct Memory Access)技术来在GPU和主机之间复制数据。由于DMA在执行复制时无需CPU介入。因此DMA复制过程中使用固定内存是非常重要的。<br><strong>缺点:</strong><br>使用固定内存，将失去虚拟内存的所有功能，系统将更快的耗尽内存。<br><strong>注意:</strong><br>对cudaMemcpy()函数调用中的源内存或者目标内存，才使用固定内存，并且在不再需要使用它们时立即释放。固定内存通过cudaHostAlloc()函数来分配；通过cudaFreeHost()释放。我们只能以异步方式对固定内存进行复制操作。</p><h1 id="CUDA程序计算原理"><a href="#CUDA程序计算原理" class="headerlink" title="CUDA程序计算原理"></a>CUDA程序计算原理</h1><h2 id="CUDA程序执行过程"><a href="#CUDA程序执行过程" class="headerlink" title="CUDA程序执行过程"></a>CUDA程序执行过程</h2><p>分配host内存，并进行数据初始化；<br>分配device内存，并从host将数据拷贝到device上；<br>调用CUDA的核函数在device上完成指定的运算；<br>将device上的运算结果拷贝到host上；<br>释放device和host上分配的内存。</p><h2 id="核函数（kernel）与SM"><a href="#核函数（kernel）与SM" class="headerlink" title="核函数（kernel）与SM"></a>核函数（kernel）与SM</h2><p>kernel核函数是CUDA中一个重要的概念，kernel核函数是在device上线程中并行执行的函数，用__global__符号声明，在调用时需要用&lt;&lt;&lt;grid, block&gt;&gt;&gt;来指定一个kernel函数要执行的线程数量，在CUDA中，每个线程会分配一个唯一的线程号thread ID，这个ID值可以通过核函数的内置变量threadIdx来获得。<br>一个线程需要两个内置的坐标变量（blockIdx，threadIdx）来唯一标识，它们都是dim3类型变量，其中blockIdx指明线程所在grid中的位置，而threaIdx指明线程所在block中的位置。<br><strong>每个线程有自己的私有本地内存（Local Memory），每个线程块有包含共享内存（Shared Memory）,可以被线程块中所有线程共享，其生命周期与线程块一致。此外，所有的线程都可以访问全局内存（Global Memory），还可以访问一些只读内存块：常量内存（Constant Memory）和纹理内存（Texture Memory）。</strong><br><strong>一个kernel核函数在device上执行时实际上启动了很多线程，一个kernel所启动的所有线程称为一个线程格（grid），同一个线程格上的线程共享相同的全局内存空间；一个线程格又分为很多线程块（block），一个线程块里面包含很多线程。</strong><br>一个kernel核函数执行时会启动很多线程，这些线程是逻辑上并行的，但是在物理层上却不一定并行。但是一个GPU中存在很多CUDA核心（即SM），充分利用CUDA核心可以充分发挥GPU的并行计算能力。SM的核心组件包括CUDA核心，共享内存，寄存器等，SM可以并发地执行数百个线程，并发能力就取决于SM所拥有的资源数。<br><strong>当一个kernel核函数被执行时，它的网格块（grid）中的线程块（block）被分配到SM上，一个线程块（block）只能在一个SM上被调度。有时一个kernel核函数的各个线程块（block）被分配多个SM，那么网格块（grid）只是逻辑层，而SM才是执行的物理层。</strong><br>SM采用的是SIMT（Single-Instruction, Multiple-Thread，单指令多线程）架构，基本的执行单元是线程束（wraps），线程束包含32个线程，这些线程同时执行相同的指令，但是每个线程都包含自己的指令地址计数器和寄存器状态，也有自己独立的执行路径。所以尽管线程束（wraps）中的线程同时从同一程序地址执行，但是可能具有不同的行为，比如遇到了分支结构，一些线程可能进入这个分支，但是另外一些有可能不执行，它们只能死等，因为GPU规定线程束（wraps）中所有线程在同一周期执行相同的指令，线程束（wraps）分化会导致性能下降。<br>当线程块（block）被划分到某个SM上时，它将进一步划分为多个线程束（wraps），因为这才是SM的基本执行单元，但是一个SM同时并发的线程束（wraps）数是有限的。这是因为资源限制，SM要为每个线程块分配共享内存，而也要为每个线程束（wraps）中的线程分配独立的寄存器。所以SM的配置会影响其所支持的线程块和线程束并发数量。<br><strong>从逻辑上划分，一个网格块（grid）包含多个线程块（block），一个线程块（block）包含有多个线程（Threads）。但是一个kernel核函数的所有线程在物理层不一定是同时并发的。因此，kernel核函数的网格块（grid）和线程块（block）的配置不同，性能会出现差异。另外，由于SM的基本执行单元是包含32个线程的线程束，所以线程块（block）大小一般要设置为32的倍数。</strong></p><h2 id="核函数（kernel）的调用"><a href="#核函数（kernel）的调用" class="headerlink" title="核函数（kernel）的调用"></a>核函数（kernel）的调用</h2><p><strong>在VS2017的CUDA项目中启动kernel函数时要指定gridsize和blocksize，如:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> dim3 gridsize(2,2);</span><br><span class="line"> dim3 blocksize(4,4);</span><br><span class="line">Kernel &lt;&lt; &lt; gridSize, blocksize &gt;&gt; &gt; (A, B, C);</span><br></pre></td></tr></table></figure><p>这里的grid和block都是2D的。<br><strong>gridsize相当于是一个2x2的block，gridDim.x，gridDim.y，gridDim.z相当于这个dim3的x，y，z方向的维度，这里是2x2x1。序号从0到3，且是从上到下的顺序，即grid中的blockidx序号标注情况为:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0     2</span><br><span class="line">1     3</span><br></pre></td></tr></table></figure><p><strong>blocksize则是指block里面的线程(thread)的情况，blockDim.x，blockDim.y，blockDim.z相当于这个dim3的x，y，z方向的维度，这里是4x4x1.序号是0-15，即block中的threadidx序号标注情况为:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0      4       8      12 </span><br><span class="line">1       5       9       13</span><br><span class="line">2       6       10     14</span><br><span class="line">3       7       11      15</span><br></pre></td></tr></table></figure><p><strong>确定线程的global ID:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">int col = threadIdx.x + blockIdx.x * blockDim.x;</span><br></pre></td></tr></table></figure><p><strong>ThreadID是线性增长的，其目的是用于在硬件和软件上唯一标识每一个线程。CUDA程序中任何一个时刻，每一个线程的ThreadIdx都是特定唯一标识的。Threads的唯一标识ThreadIdx的表达方式随着grid，block的划分维度而不同</strong>。</p><h2 id="线程同步"><a href="#线程同步" class="headerlink" title="线程同步"></a>线程同步</h2><p>线程同步是针对同一个线程块（block）中的所有线程而言的，因为只有同一个线程块（block）中的线程才能在有效的机制中共同访问共享内存（Shared Memory）。由于每一个线程（Thread）的生命周期长度是不相同的，线程（Thread）对共享内存（Shared Memory）的操作可能会导致读写的不一致，因此需要线程的同步，从而保证该block中所有线程同时结束。**</p><h1 id="win10-VS2017-CUDA10-0项目配置"><a href="#win10-VS2017-CUDA10-0项目配置" class="headerlink" title="win10+VS2017+CUDA10.0项目配置"></a>win10+VS2017+CUDA10.0项目配置</h1><p>请先安装VS2017，一定要在安装CUDA前安装。<br>首先从这里下载CUDA10.0:<a href="https://developer.nvidia.com/cuda-10.0-download-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-10.0-download-archive</a> 。按默认选项安装。然后下载CUDNN7.4.2 for CUDA10:<a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-archive</a> 。解压后复制到CUDA安装文件夹里。<br>在安CUDA装过程中，会自动检测本机是否已经安装了配套的VS版本其中之一，如果VS版本和Cuda版本不匹配的话，安装无法进行。<br>CUDA安装完成后在系统变量中应当会有下面两个变量，如果没有请自己添加上:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA_PATH = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0</span><br><span class="line">CUDA_PATH_V10_0 = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0</span><br></pre></td></tr></table></figure><p>我们还要在系统变量中添加一个CUDNN变量:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDNN=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0</span><br></pre></td></tr></table></figure><p>我们还需要在用户变量中添加下列变量:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CUDA_SDK_PATH = C:\ProgramData\NVIDIA Corporation\CUDA Samples\v10.0</span><br><span class="line">CUDA_LIB_PATH = %CUDA_PATH%\lib\x64</span><br><span class="line">CUDA_BIN_PATH = %CUDA_PATH%\bin</span><br><span class="line">CUDA_SDK_BIN_PATH = %CUDA_SDK_PATH%\bin\win64</span><br><span class="line">CUDA_SDK_LIB_PATH = %CUDA_SDK_PATH%\common\lib\x64</span><br></pre></td></tr></table></figure><p>添加完成后打开cmd，使用下列命令测试CUDA是否正常:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nvcc -V //正常显示版本号则说明安装成功</span><br><span class="line">set cuda //可以查看设置的cuda环境变量</span><br><span class="line">cd C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\extras\demo_suite</span><br><span class="line">deviceQuery.exe</span><br><span class="line">bandwidthTest.exe</span><br><span class="line">// 上面两行命令都返回Rsult=PASS则说明通过，返回Rsult=Fail则需要重新安装</span><br></pre></td></tr></table></figure><p>打开VS2017，新建一个CUDA10.0 Runtime项目。新建项目时选择NVIDIA-&gt;CUDA 10.0-&gt;CUDA 10.0 Runtime。<br>在kernel.cu中添加下列代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"cuda_runtime.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"device_launch_parameters.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> deviceCount;</span><br><span class="line">cudaGetDeviceCount(&amp;deviceCount);</span><br><span class="line"><span class="keyword">int</span> dev;</span><br><span class="line"><span class="keyword">for</span> (dev = <span class="number">0</span>; dev &lt; deviceCount; dev++) &#123;</span><br><span class="line">int driver_version(0), runtime_version(0);</span><br><span class="line">cudaDeviceProp deviceProp;</span><br><span class="line">cudaGetDeviceProperties(&amp;deviceProp, dev);</span><br><span class="line"><span class="keyword">if</span> (dev == <span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> (deviceProp.minor = <span class="number">9999</span> &amp;&amp; deviceProp.major == <span class="number">9999</span>)</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\nDevice%d:\"%s\"\n"</span>, dev, deviceProp.name);</span><br><span class="line">cudaDriverGetVersion(&amp;driver_version);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"CUDA驱动版本:                                   %d.%d\n"</span>, driver_version / <span class="number">1000</span>, (driver_version % <span class="number">1000</span>) / <span class="number">10</span>);</span><br><span class="line">cudaRuntimeGetVersion(&amp;runtime_version);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"CUDA运行时版本:                                 %d.%d\n"</span>, runtime_version / <span class="number">1000</span>, (runtime_version % <span class="number">1000</span>) / <span class="number">10</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"设备计算能力:                                   %d.%d\n"</span>, deviceProp.major, deviceProp.minor);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Total amount of Global Memory:                  %u bytes\n"</span>, deviceProp.totalGlobalMem);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Number of SMs:                                  %d\n"</span>, deviceProp.multiProcessorCount);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Total amount of Constant Memory:                %u bytes\n"</span>, deviceProp.totalConstMem);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Total amount of Shared Memory per block:        %u bytes\n"</span>, deviceProp.sharedMemPerBlock);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Total number of registers available per block:  %d\n"</span>, deviceProp.regsPerBlock);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Warp size:                                      %d\n"</span>, deviceProp.warpSize);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Maximum number of threads per SM:               %d\n"</span>, deviceProp.maxThreadsPerMultiProcessor);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Maximum number of threads per block:            %d\n"</span>, deviceProp.maxThreadsPerBlock);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Maximum size of each dimension of a block:      %d x %d x %d\n"</span>, deviceProp.maxThreadsDim[<span class="number">0</span>], deviceProp.maxThreadsDim[<span class="number">1</span>], deviceProp.maxThreadsDim[<span class="number">2</span>]);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Maximum size of each dimension of a grid:       %d x %d x %d\n"</span>, deviceProp.maxGridSize[<span class="number">0</span>], deviceProp.maxGridSize[<span class="number">1</span>], deviceProp.maxGridSize[<span class="number">2</span>]);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Maximum memory pitch:                           %u bytes\n"</span>, deviceProp.memPitch);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Texture alignmemt:                              %u bytes\n"</span>, deviceProp.texturePitchAlignment);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Clock rate:                                     %.2f GHz\n"</span>, deviceProp.clockRate * <span class="number">1e-6</span>f);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Memory Clock rate:                              %.0f MHz\n"</span>, deviceProp.memoryClockRate * <span class="number">1e-3</span>f);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Memory Bus Width:                               %d-bit\n"</span>, deviceProp.memoryBusWidth);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用生成-&gt;重新生成(项目名)，调试-&gt;开始调试，运行结果如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Device0:&quot;GeForce GTX 1070 with Max-Q Design&quot;</span><br><span class="line">CUDA驱动版本:                                   10.1</span><br><span class="line">CUDA运行时版本:                                 10.0</span><br><span class="line">设备计算能力:                                   6.0</span><br><span class="line">Total amount of Global Memory:                  0 bytes</span><br><span class="line">Number of SMs:                                  16</span><br><span class="line">Total amount of Constant Memory:                65536 bytes</span><br><span class="line">Total amount of Shared Memory per block:        49152 bytes</span><br><span class="line">Total number of registers available per block:  65536</span><br><span class="line">Warp size:                                      32</span><br><span class="line">Maximum number of threads per SM:               2048</span><br><span class="line">Maximum number of threads per block:            1024</span><br><span class="line">Maximum size of each dimension of a block:      1024 x 1024 x 64</span><br><span class="line">Maximum size of each dimension of a grid:       2147483647 x 65535 x 65535</span><br><span class="line">Maximum memory pitch:                           2147483647 bytes</span><br><span class="line">Texture alignmemt:                              32 bytes</span><br><span class="line">Clock rate:                                     1.27 GHz</span><br><span class="line">Memory Clock rate:                              4004 MHz</span><br><span class="line">Memory Bus Width:                               256-bit</span><br></pre></td></tr></table></figure><h1 id="CUDA常用函数介绍"><a href="#CUDA常用函数介绍" class="headerlink" title="CUDA常用函数介绍"></a>CUDA常用函数介绍</h1><h2 id="cudaMalloc-函数"><a href="#cudaMalloc-函数" class="headerlink" title="cudaMalloc()函数"></a>cudaMalloc()函数</h2><p>函数原型:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t cudaMalloc(void** devPtr, size_t size);</span><br></pre></td></tr></table></figure><p>这个函数和C语言中的malloc类似，但是该函数是在device上申请一定字节大小的显存，devPtr是指向所分配内存的指针。可以将cudaMalloc()分配的指针传递给在设备/主机上执行的函数，也可以在设备代码中使用cudaMalloc()分配的指针进行设备内存读写操作。注意不可以在主机代码中使用cudaMalloc()分配的指针进行主机内存读写操作（即不能进行解引用）。</p><h2 id="cudaFree-函数"><a href="#cudaFree-函数" class="headerlink" title="cudaFree()函数"></a>cudaFree()函数</h2><p>函数原型:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t cudaFree (void* devPtr);</span><br></pre></td></tr></table></figure><p>与c语言中的free()函数一样，只是此函数释放的是cudaMalloc()分配的内存。</p><h2 id="cudaMemcpy-函数"><a href="#cudaMemcpy-函数" class="headerlink" title="cudaMemcpy()函数"></a>cudaMemcpy()函数</h2><p>函数原型:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t cudaMemcpy (void *dst, const void *src, size_t count, cudaMemcpyKind kind);</span><br></pre></td></tr></table></figure><p>与c语言中的memcpy函数一样，只是此函数可以在主机内存和GPU内存之间互相拷贝数据。cudaMemcpyKind kind表示数据拷贝方向，若kind赋值为cudaMemcpyDeviceToHost表示数据从设备内存拷贝到主机内存。<br>该函数以同步方式执行，即当函数返回时，复制操作就已经完成了，并且在输出缓冲区中包含了复制进去的内容。相应的有个异步方式执行函数cudaMemcpyAsync()。</p><h2 id="cudaMallocManaged-函数"><a href="#cudaMallocManaged-函数" class="headerlink" title="cudaMallocManaged()函数"></a>cudaMallocManaged()函数</h2><p>函数原型:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t cudaMallocManaged(void **devPtr, size_t size, unsigned int flag=0);</span><br></pre></td></tr></table></figure><p>在最初的CUDA编程中，我们往往单独在host和device上进行内存分配，并且要进行将数据从host拷贝到device上，这很容易出错的。CUDA 6.0版本之后引入统一内存（Unified Memory）来避免这种麻烦，简单来说就是使用一个托管内存来共同管理host和device中的内存，并且自动在host和device中进行数据传输。CUDA中使用cudaMallocManaged()函数分配托管内存。<br><strong>注意:</strong><br>kernel核函数的执行是与host异步的，我们要在执行完kernel核函数后用cudaDeviceSynchronize()函数保证device和host同步，这样后面才可以正确访问kernel计算的结果。</p><h1 id="CUDA矩阵乘法实例"><a href="#CUDA矩阵乘法实例" class="headerlink" title="CUDA矩阵乘法实例"></a>CUDA矩阵乘法实例</h1><p>我们要实现两个矩阵的乘法，设输入矩阵为A和B，要得到 C=AxB 。实现思路是每个线程计算C的一个元素值Cij，对于矩阵运算，应该选用grid和block为2-D。<br><strong>计算步骤:</strong><br>分配host内存，并进行数据初始化，分配device内存，并从host将数据拷贝到device上，实际代码中使用cudaMallocManaged()函数进行内存托管；<br>调用CUDA的kernel核函数在device上完成指定的运算；<br>同步device上的运算结果到host上，使用cudaDeviceSynchronize()函数来同步；<br>释放device和host上分配的内存，这步由前面定义的cudaMallocManaged()函数自动管理。<br><strong>完整代码:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"cuda_runtime.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"device_launch_parameters.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印显卡各项信息</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">GetCudaImformation</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> deviceCount;</span><br><span class="line">cudaGetDeviceCount(&amp;deviceCount);</span><br><span class="line"><span class="keyword">int</span> dev;</span><br><span class="line"><span class="keyword">for</span> (dev = <span class="number">0</span>; dev &lt; deviceCount; dev++) &#123;</span><br><span class="line">int driver_version(0), runtime_version(0);</span><br><span class="line">cudaDeviceProp deviceProp;</span><br><span class="line">cudaGetDeviceProperties(&amp;deviceProp, dev);</span><br><span class="line"><span class="keyword">if</span> (dev == <span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> (deviceProp.minor = <span class="number">9999</span> &amp;&amp; deviceProp.major == <span class="number">9999</span>)</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"使用GPU device "</span> &lt;&lt; dev &lt;&lt; <span class="string">": "</span> &lt;&lt; deviceProp.name &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">cudaDriverGetVersion(&amp;driver_version);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"CUDA驱动版本:"</span> &lt;&lt; driver_version / <span class="number">1000</span> &lt;&lt; <span class="string">"."</span> &lt;&lt; (driver_version % <span class="number">1000</span>) / <span class="number">10</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">cudaRuntimeGetVersion(&amp;runtime_version);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"CUDA运行时版本:"</span> &lt;&lt; runtime_version / <span class="number">1000</span> &lt;&lt; <span class="string">"."</span> &lt;&lt; (runtime_version % <span class="number">1000</span>) / <span class="number">10</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"设备计算能力:"</span> &lt;&lt; deviceProp.major &lt;&lt; <span class="string">"."</span> &lt;&lt; deviceProp.minor &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"显卡时钟频率:"</span> &lt;&lt; deviceProp.clockRate * <span class="number">1e-6</span>f &lt;&lt; <span class="string">" GHz"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"内存时钟频率:"</span> &lt;&lt; deviceProp.memoryClockRate * <span class="number">1e-3</span>f &lt;&lt; <span class="string">" MHz"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"内存总线带宽:"</span> &lt;&lt; deviceProp.memoryBusWidth &lt;&lt; <span class="string">" bit"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"总显存大小:"</span> &lt;&lt; deviceProp.totalGlobalMem / (<span class="number">1024.0</span>*<span class="number">1024.0</span>) &lt;&lt; <span class="string">" MB"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"总常量内存大小:"</span> &lt;&lt; deviceProp.totalConstMem / <span class="number">1024.0</span> &lt;&lt; <span class="string">" KB"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"SM数量:"</span> &lt;&lt; deviceProp.multiProcessorCount &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"每个SM最大线程数:"</span> &lt;&lt; deviceProp.maxThreadsPerMultiProcessor &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"每个线程块(block)共享内存大小:"</span> &lt;&lt; deviceProp.sharedMemPerBlock / <span class="number">1024.0</span> &lt;&lt; <span class="string">" KB"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"每个线程块(block)的最大线程数:"</span> &lt;&lt; deviceProp.maxThreadsPerBlock &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"每个线程块(block)的最大可用寄存器数:"</span> &lt;&lt; deviceProp.regsPerBlock &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"线程束(wrap)尺寸:"</span> &lt;&lt; deviceProp.warpSize &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"每个线程块(block)各个维度最大尺寸:"</span> &lt;&lt; deviceProp.maxThreadsDim[<span class="number">0</span>] &lt;&lt; <span class="string">" x "</span> &lt;&lt; deviceProp.maxThreadsDim[<span class="number">1</span>] &lt;&lt; <span class="string">" x "</span> &lt;&lt; deviceProp.maxThreadsDim[<span class="number">2</span>] &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"每个线程格(grid)各个维度最大尺寸"</span> &lt;&lt; deviceProp.maxGridSize[<span class="number">0</span>] &lt;&lt; <span class="string">" x "</span> &lt;&lt; deviceProp.maxGridSize[<span class="number">1</span>] &lt;&lt; <span class="string">" x "</span> &lt;&lt; deviceProp.maxGridSize[<span class="number">2</span>] &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"最大存储间距:"</span> &lt;&lt; deviceProp.memPitch / (<span class="number">1024.0</span>*<span class="number">1024.0</span>) &lt;&lt; <span class="string">" MB"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 矩阵类型,行优先,M(row, col) = *(M.elements + row * M.width + col)</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Matrix</span> &#123;</span></span><br><span class="line"><span class="keyword">int</span> width;</span><br><span class="line"><span class="keyword">int</span> height;</span><br><span class="line"><span class="keyword">float</span> *elements;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取矩阵A的位置为(row, col)元素</span></span><br><span class="line">__<span class="function">device__ <span class="keyword">float</span> <span class="title">getElement</span><span class="params">(Matrix *A, <span class="keyword">int</span> row, <span class="keyword">int</span> col)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> A-&gt;elements[row * A-&gt;width + col];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为矩阵A的位置为(row, col)的元素赋值</span></span><br><span class="line">__<span class="function">device__ <span class="keyword">void</span> <span class="title">setElement</span><span class="params">(Matrix *A, <span class="keyword">int</span> row, <span class="keyword">int</span> col, <span class="keyword">float</span> value)</span> </span>&#123;</span><br><span class="line">A-&gt;elements[row * A-&gt;width + col] = value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 矩阵相乘kernel函数,2-D,每个线程计算一个元素Cij</span></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">matMulKernel</span><span class="params">(Matrix *A, Matrix *B, Matrix *C)</span> </span>&#123;</span><br><span class="line"><span class="keyword">float</span> Cvalue = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">int</span> row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line"><span class="keyword">int</span> col = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; A-&gt;width; ++i) &#123;</span><br><span class="line">Cvalue += getElement(A, row, i) * getElement(B, i, col);</span><br><span class="line">&#125;</span><br><span class="line">setElement(C, row, col, Cvalue);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">GetCudaImformation();</span><br><span class="line"><span class="keyword">int</span> width = <span class="number">1</span> &lt;&lt; <span class="number">10</span>;</span><br><span class="line"><span class="keyword">int</span> height = <span class="number">1</span> &lt;&lt; <span class="number">10</span>;</span><br><span class="line">Matrix *A, *B, *C;</span><br><span class="line"><span class="comment">// 申请托管内存</span></span><br><span class="line">cudaMallocManaged((<span class="keyword">void</span>**)&amp;A, <span class="keyword">sizeof</span>(Matrix));</span><br><span class="line">cudaMallocManaged((<span class="keyword">void</span>**)&amp;B, <span class="keyword">sizeof</span>(Matrix));</span><br><span class="line">cudaMallocManaged((<span class="keyword">void</span>**)&amp;C, <span class="keyword">sizeof</span>(Matrix));</span><br><span class="line"><span class="keyword">int</span> nBytes = width * height * <span class="keyword">sizeof</span>(<span class="keyword">float</span>);</span><br><span class="line">cudaMallocManaged((<span class="keyword">void</span>**)&amp;A-&gt;elements, nBytes);</span><br><span class="line">cudaMallocManaged((<span class="keyword">void</span>**)&amp;B-&gt;elements, nBytes);</span><br><span class="line">cudaMallocManaged((<span class="keyword">void</span>**)&amp;C-&gt;elements, nBytes);</span><br><span class="line"><span class="comment">// 初始化A\B\C矩阵的宽度和高度</span></span><br><span class="line">A-&gt;height = height;</span><br><span class="line">A-&gt;width = width;</span><br><span class="line">B-&gt;height = height;</span><br><span class="line">B-&gt;width = width;</span><br><span class="line">C-&gt;height = height;</span><br><span class="line">C-&gt;width = width;</span><br><span class="line"><span class="comment">// 初始化A矩阵所有元素为1.0,B矩阵所有元素为2.0</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; width * height; ++i) &#123;</span><br><span class="line">A-&gt;elements[i] = <span class="number">1.0</span>;</span><br><span class="line">B-&gt;elements[i] = <span class="number">2.0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 定义kernel的blocksize为(32, 32)，那么grid大小为(32, 32)</span></span><br><span class="line"><span class="function">dim3 <span class="title">blockSize</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">gridSize</span><span class="params">((width + blockSize.x - <span class="number">1</span>) / blockSize.x,</span></span></span><br><span class="line"><span class="function"><span class="params">(height + blockSize.y - <span class="number">1</span>) / blockSize.y)</span></span>;</span><br><span class="line"><span class="comment">// 执行kernel</span></span><br><span class="line">matMulKernel &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt; (A, B, C);</span><br><span class="line"><span class="comment">// 同步device数据保证结果能正确访问</span></span><br><span class="line">cudaDeviceSynchronize();</span><br><span class="line"><span class="comment">// 检查执行结果</span></span><br><span class="line"><span class="keyword">float</span> maxError = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; width * height; ++i)</span><br><span class="line">maxError = fmax(maxError, <span class="built_in">fabs</span>(C-&gt;elements[i] - <span class="number">2</span> * width));</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"最大误差: "</span> &lt;&lt; maxError &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;h2 id=&quot;主机（host）&quot;&gt;&lt;a href=&quot;#主机（host）&quot; class=&quot;headerlink&quot; title=&quot;主
      
    
    </summary>
    
    
      <category term="CUDA编程" scheme="https://wyg1996.cn/categories/CUDA%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="CUDA编程" scheme="https://wyg1996.cn/tags/CUDA%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
</feed>
